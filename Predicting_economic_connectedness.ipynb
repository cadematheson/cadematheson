{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3bbc8b4e-ba35-41f2-a813-5610b078bbb8",
      "metadata": {
        "id": "3bbc8b4e-ba35-41f2-a813-5610b078bbb8"
      },
      "source": [
        "# Homework 2: Model Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d34fa4a-8a02-44f7-b2ca-4601ced77d2b",
      "metadata": {
        "id": "9d34fa4a-8a02-44f7-b2ca-4601ced77d2b"
      },
      "source": [
        "A recently released dataset explored 21B friendships on Facebook to identify characteristics associated with social and economic mobility. A strong indicator for this was the *economic connectedness* of an individual, the percentage of high income connections they had.\n",
        "\n",
        "In this dataset, we have average economic connectedness at the county level as well as a large number of characteristics about the county. We want to construct a model to effectively predict the economic connectedness (`ec_county`) given the other characteristics. An effective model here would begin to show us other important factors in social mobility.\n",
        "\n",
        "Construct a model (including tuning) and interpret your results.\n",
        "\n",
        "Dataset used:\n",
        "\n",
        "`county_level_ec_neighborhood.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44bfbe9e-38b0-4d8c-9cef-b09cd963c0e1",
      "metadata": {
        "id": "44bfbe9e-38b0-4d8c-9cef-b09cd963c0e1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras \n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soc = pd.read_csv(\"county_level_ec_neighborhood.csv\")"
      ],
      "metadata": {
        "id": "L6r4neu_7P9-"
      },
      "id": "L6r4neu_7P9-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soc.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "HSgk1Fjm7Xuk"
      },
      "id": "HSgk1Fjm7Xuk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soc.shape"
      ],
      "metadata": {
        "id": "IE49QmmN7Y7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac4f30c-070d-4f4c-ba6b-0ca8574f7e09"
      },
      "id": "IE49QmmN7Y7F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2299, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soc['ec_county']"
      ],
      "metadata": {
        "id": "LQwZwr3G7wOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885f5bba-f32f-4875-c279-7c079e086fe8"
      },
      "id": "LQwZwr3G7wOg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.72077\n",
              "1       0.74313\n",
              "2       0.41366\n",
              "3       0.63152\n",
              "4       0.72562\n",
              "         ...   \n",
              "3082    0.99321\n",
              "3084    0.96235\n",
              "3086    0.95452\n",
              "3087    0.90667\n",
              "3088    0.97840\n",
              "Name: ec_county, Length: 2299, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = soc.drop(['county_x', 'county_name','ec_county'], axis = 1)\n",
        "\n",
        "y = soc[['ec_county']]"
      ],
      "metadata": {
        "id": "XMYipy338HB4"
      },
      "id": "XMYipy338HB4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "ncX4QNPh-GXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0178694-29eb-446c-e592-e6874abb4b36"
      },
      "id": "ncX4QNPh-GXg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2299, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(np.mean(np.square(y.mean()[0] - y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATTAhZYbhnEp",
        "outputId": "87e6395f-fc7f-476a-842b-c2334ca13799"
      },
      "id": "ATTAhZYbhnEp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ec_county    0.172993\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(np.square(y.mean()[0] - y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsZFpc_MnP_p",
        "outputId": "5141cf49-94e7-4414-b679-dab5b19575af"
      },
      "id": "nsZFpc_MnP_p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ec_county    0.029927\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "ybNuTHrU7pyL"
      },
      "id": "ybNuTHrU7pyL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=24)"
      ],
      "metadata": {
        "id": "obohYVqx76qH"
      },
      "id": "obohYVqx76qH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=24)"
      ],
      "metadata": {
        "id": "z6-ilQTI2Qgz"
      },
      "id": "z6-ilQTI2Qgz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestRegressor(oob_score = True).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xxWWrlZA8plD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf1cfd8-0ae7-425b-86d6-fe58516cf173"
      },
      "id": "xxWWrlZA8plD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-8657cab46371>:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  clf = RandomForestRegressor(oob_score = True).fit(X_train, y_train)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.oob_score_"
      ],
      "metadata": {
        "id": "OGXnunk69C8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e86039-4459-414d-b8b1-61fd6f3fcb3f"
      },
      "id": "OGXnunk69C8s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7948635997332826"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(np.mean(np.square(clf.predict(X_train) - np.array(y_train))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdAoD7vDiM_E",
        "outputId": "74494922-ff93-4c71-c653-c541326db113"
      },
      "id": "HdAoD7vDiM_E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23308819816546308"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_mse = np.mean(np.square(clf.predict(X_val) - np.array(y_val)))\n",
        "print(\"Random Forest Validation MSE:\", rf_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_JGiBsFaAyH",
        "outputId": "0ae4a5a6-72f4-47c4-94e8-d404f99492d1"
      },
      "id": "R_JGiBsFaAyH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest MSE: 0.05518463487357892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.scatter(clf.predict(X_test), y_test)"
      ],
      "metadata": {
        "id": "9pcexN2D-W8y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "646d0052-d824-4091-a70d-c83d3cf76d10"
      },
      "id": "9pcexN2D-W8y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc05329a820>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_train = np.array(X_train)\n",
        "X_train"
      ],
      "metadata": {
        "id": "fV3I7jaN-SCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65b406e-ba68-4800-8627-f9ffe3325356"
      },
      "id": "fV3I7jaN-SCU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.9738461e+04,  3.0172611e+01,  1.6230786e-01, ...,\n",
              "         1.2994273e+02,  3.0054461e-02,  1.0260017e+02],\n",
              "       [ 5.6060023e+04,  2.5552778e+01,  8.5401721e-02, ...,\n",
              "         6.4696571e+01, -2.5847500e-04,  2.6435402e+01],\n",
              "       [ 5.0478566e+04,  2.5004150e+01,  1.3108575e-01, ...,\n",
              "         1.6630031e+02, -2.0277413e-02,  6.5908173e+01],\n",
              "       ...,\n",
              "       [ 7.6296078e+04,  2.6051298e+01,  1.6755566e-01, ...,\n",
              "         6.8538139e+01, -2.8107500e-03,  3.8135670e+01],\n",
              "       [ 9.3622109e+04,  2.9099094e+01,  3.0513936e-01, ...,\n",
              "         1.2738395e+03,  4.5897460e-03,  6.8834375e+02],\n",
              "       [ 6.5680813e+04,  2.3720495e+01,  1.5630737e-01, ...,\n",
              "         2.2377888e+02,  1.5193356e-02,  1.3801863e+02]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "tEzb3Lir-arM"
      },
      "id": "tEzb3Lir-arM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD, Adam"
      ],
      "metadata": {
        "id": "QnbdnZeezfvQ"
      },
      "id": "QnbdnZeezfvQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers.optimizer_v2.optimizer_v2 import learning_rate_schedule\n",
        "layers_list = [1,2,3]\n",
        "nodes_list = [64,128,256]\n",
        "batch_sizes = [20,100,200]\n",
        "lrs = [.01,.001,.0001]\n",
        "dropouts = [.1,.3,.5]\n",
        "activations = ['sigmoid','relu']\n",
        "\n",
        "hps = []\n",
        "val_losses = []\n",
        "count = 0\n",
        "\n",
        "for layers in layers_list:\n",
        "  for dropout in dropouts:\n",
        "    for batch_size in batch_sizes:\n",
        "      for lr in lrs:\n",
        "        for nodes in nodes_list:\n",
        "          for activation in activations:\n",
        "            model = Sequential()\n",
        "            model.add(Dense(nodes, activation=activation, input_shape=(X_train.shape[1],)))\n",
        "            if layers == 1:\n",
        "              model.add(Dense(nodes, activation=activation))\n",
        "            elif layers == 2:\n",
        "              model.add(Dense(nodes, activation=activation))\n",
        "              model.add(Dense(nodes, activation=activation))\n",
        "            elif layers == 3:\n",
        "              model.add(Dense(nodes, activation=activation))\n",
        "              model.add(Dense(nodes, activation=activation))\n",
        "              model.add(Dense(nodes, activation=activation))\n",
        "            model.add(Dense(1, activation='linear'))\n",
        "\n",
        "            # Compile the model\n",
        "            model.compile(loss='mse',\n",
        "                          optimizer=keras.optimizers.Adam(lr=lr),\n",
        "                          metrics=['mse'])\n",
        "\n",
        "            # Train the model\n",
        "            history = model.fit(X_train, y_train,\n",
        "                                batch_size=batch_size,\n",
        "                                epochs=10,\n",
        "                                verbose=0,\n",
        "                                validation_data=(X_val, y_val))\n",
        "            count += 1\n",
        "            print(\"mse:\", history.history['val_loss'][-1])\n",
        "            print(\"dropout:\", dropout, \"batch_size:\", batch_size, \"lr:\", lr)\n",
        "            print(\"nodes:\", nodes, \"activation:\", activation, \"layers:\", layers)\n",
        "            print(\"models fitted:\", count, \"/486\")\n",
        "            print(\"----------------------------------------------\")\n",
        "\n",
        "            hps.append({\"dropout\" : dropout, \n",
        "                        \"batch_size\" : batch_size,\n",
        "                        \"lr\" : lr,\n",
        "                        \"layers\" : layers,\n",
        "                        \"nodes\" : nodes,\n",
        "                        \"activation\" : activation})\n",
        "            val_losses.append(history.history['val_mse'][-1])\n",
        "\n",
        "print(\"The best_hps are:\", hps[np.argmin(val_losses)])"
      ],
      "metadata": {
        "id": "pL7fJwZS-rkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0919e39b-9a65-43e0-f711-eb24aac7bbe3"
      },
      "id": "pL7fJwZS-rkL",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0415 - val_mse: 0.0415\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0350 - val_mse: 0.0350\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0386 - val_mse: 0.0386\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0424 - val_mse: 0.0424\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "mse: 0.03182254359126091\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 1 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 8764992.0000 - mse: 8764992.0000 - val_loss: 2343.4712 - val_mse: 2343.4712\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 2844.4688 - mse: 2844.4688 - val_loss: 1626.8558 - val_mse: 1626.8560\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1358.2689 - mse: 1358.2689 - val_loss: 1528.4828 - val_mse: 1528.4828\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 2418.0952 - mse: 2418.0952 - val_loss: 366.2511 - val_mse: 366.2511\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 468.9027 - mse: 468.9027 - val_loss: 283.9841 - val_mse: 283.9841\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 684.1131 - mse: 684.1131 - val_loss: 342.7037 - val_mse: 342.7037\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 2445.6631 - mse: 2445.6631 - val_loss: 245.5073 - val_mse: 245.5073\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 2164.4109 - mse: 2164.4109 - val_loss: 698.8069 - val_mse: 698.8069\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1892.4717 - mse: 1892.4717 - val_loss: 341.8032 - val_mse: 341.8032\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 4200.2495 - mse: 4200.2495 - val_loss: 398.5035 - val_mse: 398.5035\n",
            "mse: 398.50347900390625\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 2 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.1642 - mse: 0.1642 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0360 - val_mse: 0.0360\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0616 - val_mse: 0.0616\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "mse: 0.032431408762931824\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 3 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 33153058.0000 - mse: 33153058.0000 - val_loss: 1091.0265 - val_mse: 1091.0265\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 732.4048 - mse: 732.4048 - val_loss: 461.7360 - val_mse: 461.7360\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 4300.6455 - mse: 4300.6455 - val_loss: 327.3506 - val_mse: 327.3506\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 530.9529 - mse: 530.9529 - val_loss: 241.7846 - val_mse: 241.7846\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 221.6247 - mse: 221.6247 - val_loss: 197.3272 - val_mse: 197.3272\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 177.8610 - mse: 177.8610 - val_loss: 192.3912 - val_mse: 192.3912\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 145.1258 - mse: 145.1258 - val_loss: 132.9005 - val_mse: 132.9005\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 117.5935 - mse: 117.5935 - val_loss: 113.4019 - val_mse: 113.4019\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 119.7558 - mse: 119.7558 - val_loss: 143.0257 - val_mse: 143.0257\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 156.7887 - mse: 156.7887 - val_loss: 115.4798 - val_mse: 115.4798\n",
            "mse: 115.4797592163086\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 4 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.6512 - mse: 0.6512 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0404 - val_mse: 0.0404\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0455 - val_mse: 0.0455\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0396 - val_mse: 0.0396\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0390 - val_mse: 0.0390\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "mse: 0.03373834490776062\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 5 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 32488248.0000 - mse: 32488248.0000 - val_loss: 22.5580 - val_mse: 22.5580\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 154.2811 - mse: 154.2811 - val_loss: 28.9373 - val_mse: 28.9373\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 28.0911 - mse: 28.0911 - val_loss: 29.2961 - val_mse: 29.2961\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 22.1358 - mse: 22.1358 - val_loss: 12.9097 - val_mse: 12.9097\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 15.9384 - mse: 15.9384 - val_loss: 13.7591 - val_mse: 13.7591\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 12.6148 - mse: 12.6148 - val_loss: 10.6579 - val_mse: 10.6579\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 11.7770 - mse: 11.7770 - val_loss: 6.3324 - val_mse: 6.3324\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 10.0940 - mse: 10.0940 - val_loss: 5.8199 - val_mse: 5.8199\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 11.3353 - mse: 11.3353 - val_loss: 7.0697 - val_mse: 7.0697\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 9.2606 - mse: 9.2606 - val_loss: 4.2875 - val_mse: 4.2875\n",
            "mse: 4.287495136260986\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 6 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.3437 - mse: 0.3437 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0270 - val_mse: 0.0270\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "mse: 0.03282829374074936\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 7 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 6ms/step - loss: 582842.6250 - mse: 582842.6250 - val_loss: 23159.1211 - val_mse: 23159.1211\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 16650.2812 - mse: 16650.2812 - val_loss: 4274.9922 - val_mse: 4274.9922\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 4172.0645 - mse: 4172.0645 - val_loss: 1920.7036 - val_mse: 1920.7036\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1998.3973 - mse: 1998.3973 - val_loss: 3128.9580 - val_mse: 3128.9580\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1587.7324 - mse: 1587.7324 - val_loss: 821.8518 - val_mse: 821.8518\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1283.6483 - mse: 1283.6483 - val_loss: 283.2557 - val_mse: 283.2557\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1815.7391 - mse: 1815.7391 - val_loss: 863.2148 - val_mse: 863.2148\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2142.5071 - mse: 2142.5071 - val_loss: 385.2730 - val_mse: 385.2730\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1026.6188 - mse: 1026.6188 - val_loss: 339.7378 - val_mse: 339.7378\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 5622.4248 - mse: 5622.4248 - val_loss: 691.0714 - val_mse: 691.0714\n",
            "mse: 691.0713500976562\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 8 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0287 - val_mse: 0.0287\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "mse: 0.03471370041370392\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 9 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 1114241.1250 - mse: 1114241.1250 - val_loss: 10539.6250 - val_mse: 10539.6250\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 5813.2822 - mse: 5813.2822 - val_loss: 3075.8030 - val_mse: 3075.8030\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 13010.0654 - mse: 13010.0654 - val_loss: 2066.9775 - val_mse: 2066.9775\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 35738.7891 - mse: 35738.7891 - val_loss: 30619.0840 - val_mse: 30619.0840\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 13377.9492 - mse: 13377.9492 - val_loss: 2897.2026 - val_mse: 2897.2026\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2624.5803 - mse: 2624.5803 - val_loss: 1466.6102 - val_mse: 1466.6102\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1287.3888 - mse: 1287.3888 - val_loss: 1022.9882 - val_mse: 1022.9882\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1885.0775 - mse: 1885.0775 - val_loss: 889.3423 - val_mse: 889.3423\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 11754.1094 - mse: 11754.1094 - val_loss: 482.6707 - val_mse: 482.6707\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 2365.6846 - mse: 2365.6846 - val_loss: 5708.8657 - val_mse: 5708.8657\n",
            "mse: 5708.86572265625\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 10 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0481 - val_mse: 0.0481\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0664 - val_mse: 0.0664\n",
            "mse: 0.06642194837331772\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 11 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 2814251.5000 - mse: 2814252.0000 - val_loss: 1501.2125 - val_mse: 1501.2125\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 5800.7612 - mse: 5800.7612 - val_loss: 2598.4741 - val_mse: 2598.4741\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 57535.4922 - mse: 57535.4922 - val_loss: 4191.5146 - val_mse: 4191.5146\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 4301.0605 - mse: 4301.0605 - val_loss: 562.1905 - val_mse: 562.1905\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 18261.8281 - mse: 18261.8281 - val_loss: 6273.9521 - val_mse: 6273.9521\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 15230.5332 - mse: 15230.5332 - val_loss: 54100.3438 - val_mse: 54100.3438\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 7755.3394 - mse: 7755.3394 - val_loss: 2711.8286 - val_mse: 2711.8286\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1307.0439 - mse: 1307.0439 - val_loss: 94.4253 - val_mse: 94.4253\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 309.1809 - mse: 309.1809 - val_loss: 415.2394 - val_mse: 415.2394\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 246.6370 - mse: 246.6370 - val_loss: 206.4253 - val_mse: 206.4253\n",
            "mse: 206.42529296875\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 12 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 4ms/step - loss: 0.3154 - mse: 0.3154 - val_loss: 0.0872 - val_mse: 0.0872\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0443 - val_mse: 0.0443\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0387 - val_mse: 0.0387\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0356 - val_mse: 0.0356\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "mse: 0.02514525130391121\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 13 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 31000172.0000 - mse: 31000172.0000 - val_loss: 127001.4688 - val_mse: 127001.4688\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 107286.6953 - mse: 107286.6953 - val_loss: 75067.8750 - val_mse: 75067.8750\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 69515.0625 - mse: 69515.0625 - val_loss: 49468.7812 - val_mse: 49468.7812\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 45181.6758 - mse: 45181.6758 - val_loss: 33379.6289 - val_mse: 33379.6289\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 30937.3125 - mse: 30937.3125 - val_loss: 25443.2324 - val_mse: 25443.2324\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 22668.0625 - mse: 22668.0625 - val_loss: 16979.4023 - val_mse: 16979.4023\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 16613.6934 - mse: 16613.6934 - val_loss: 12108.4834 - val_mse: 12108.4834\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 12727.6787 - mse: 12727.6787 - val_loss: 9366.1123 - val_mse: 9366.1123\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 10123.9160 - mse: 10123.9160 - val_loss: 8461.3477 - val_mse: 8461.3477\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 8673.1650 - mse: 8673.1650 - val_loss: 7401.7231 - val_mse: 7401.7231\n",
            "mse: 7401.72314453125\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 14 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 4ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "mse: 0.022201772779226303\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 15 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 4205988.0000 - mse: 4205988.0000 - val_loss: 15889.0537 - val_mse: 15889.0537\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 9452.8623 - mse: 9452.8623 - val_loss: 1546.1437 - val_mse: 1546.1437\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2140.5273 - mse: 2140.5273 - val_loss: 969.4283 - val_mse: 969.4283\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1127.9537 - mse: 1127.9537 - val_loss: 731.1126 - val_mse: 731.1126\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 788.2621 - mse: 788.2621 - val_loss: 728.9149 - val_mse: 728.9149\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 738.7517 - mse: 738.7517 - val_loss: 668.6809 - val_mse: 668.6809\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 653.8251 - mse: 653.8251 - val_loss: 787.6432 - val_mse: 787.6432\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 728.7192 - mse: 728.7192 - val_loss: 547.3398 - val_mse: 547.3398\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 588.3674 - mse: 588.3674 - val_loss: 510.5142 - val_mse: 510.5142\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 502.5084 - mse: 502.5084 - val_loss: 560.2957 - val_mse: 560.2957\n",
            "mse: 560.2957153320312\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 16 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.5926 - mse: 0.5926 - val_loss: 0.0364 - val_mse: 0.0364\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0286 - val_mse: 0.0286\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0261 - val_mse: 0.0261\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "mse: 0.021300548687577248\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 17 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 75825.3984 - mse: 75825.3984 - val_loss: 1523.2853 - val_mse: 1523.2853\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1276.0664 - mse: 1276.0664 - val_loss: 251.6391 - val_mse: 251.6391\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 451.8600 - mse: 451.8600 - val_loss: 177.8973 - val_mse: 177.8973\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 362.3346 - mse: 362.3346 - val_loss: 209.8895 - val_mse: 209.8895\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1685.0797 - mse: 1685.0797 - val_loss: 333.8979 - val_mse: 333.8979\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 936.4738 - mse: 936.4738 - val_loss: 154.9668 - val_mse: 154.9668\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 3127.5972 - mse: 3127.5972 - val_loss: 161.2548 - val_mse: 161.2548\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 9047.1631 - mse: 9047.1631 - val_loss: 357.7540 - val_mse: 357.7540\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 519.0004 - mse: 519.0004 - val_loss: 206.2061 - val_mse: 206.2061\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1518.8530 - mse: 1518.8530 - val_loss: 723.7866 - val_mse: 723.7866\n",
            "mse: 723.7865600585938\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 18 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 11ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0400 - val_mse: 0.0400\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "mse: 0.032343991100788116\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 19 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 77681368.0000 - mse: 77681368.0000 - val_loss: 1190318.1250 - val_mse: 1190318.2500\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2594198.5000 - mse: 2594198.5000 - val_loss: 1142267.0000 - val_mse: 1142267.0000\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 264147.7188 - mse: 264147.7188 - val_loss: 8491.7197 - val_mse: 8491.7197\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 12334.3896 - mse: 12334.3906 - val_loss: 11026.3867 - val_mse: 11026.3867\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 6463.2476 - mse: 6463.2476 - val_loss: 5656.5386 - val_mse: 5656.5386\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 4905.6704 - mse: 4905.6709 - val_loss: 4484.7441 - val_mse: 4484.7441\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 4302.6743 - mse: 4302.6743 - val_loss: 3585.4167 - val_mse: 3585.4167\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 7577.3130 - mse: 7577.3130 - val_loss: 2906.5413 - val_mse: 2906.5413\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 6150.6836 - mse: 6150.6836 - val_loss: 2424.3904 - val_mse: 2424.3904\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2300.3994 - mse: 2300.3994 - val_loss: 1953.9817 - val_mse: 1953.9817\n",
            "mse: 1953.981689453125\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 20 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 0.4779 - mse: 0.4779 - val_loss: 0.1378 - val_mse: 0.1378\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0631 - val_mse: 0.0631\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0362 - val_mse: 0.0362\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0360 - val_mse: 0.0360\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "mse: 0.0321163646876812\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 21 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 88072256.0000 - mse: 88072256.0000 - val_loss: 266997.0000 - val_mse: 266997.0000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 452668.5000 - mse: 452668.5000 - val_loss: 70477.4062 - val_mse: 70477.4062\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 40331.3203 - mse: 40331.3203 - val_loss: 35930.7422 - val_mse: 35930.7422\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4551.9966 - mse: 4551.9966 - val_loss: 2194.5747 - val_mse: 2194.5747\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1727.4176 - mse: 1727.4176 - val_loss: 1512.4388 - val_mse: 1512.4388\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1199.2480 - mse: 1199.2480 - val_loss: 1195.5533 - val_mse: 1195.5533\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 935.1746 - mse: 935.1746 - val_loss: 941.1777 - val_mse: 941.1777\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 792.4852 - mse: 792.4852 - val_loss: 820.4055 - val_mse: 820.4055\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 708.7122 - mse: 708.7122 - val_loss: 664.4080 - val_mse: 664.4080\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 607.7834 - mse: 607.7834 - val_loss: 574.3228 - val_mse: 574.3228\n",
            "mse: 574.32275390625\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 22 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 21ms/step - loss: 2.7876 - mse: 2.7876 - val_loss: 0.5920 - val_mse: 0.5920\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1402 - mse: 0.1402 - val_loss: 0.0398 - val_mse: 0.0398\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0350 - val_mse: 0.0350\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "mse: 0.034328386187553406\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 23 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 234329168.0000 - mse: 234329168.0000 - val_loss: 292645.1250 - val_mse: 292645.1250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 59961.0469 - mse: 59961.0430 - val_loss: 3775.9392 - val_mse: 3775.9387\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 3307.3501 - mse: 3307.3501 - val_loss: 2218.6694 - val_mse: 2218.6694\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1728.5276 - mse: 1728.5276 - val_loss: 809.6025 - val_mse: 809.6025\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 542.4902 - mse: 542.4902 - val_loss: 72.9956 - val_mse: 72.9956\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 130.0143 - mse: 130.0143 - val_loss: 75.8696 - val_mse: 75.8696\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 71.6385 - mse: 71.6385 - val_loss: 54.4455 - val_mse: 54.4455\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 49.8250 - mse: 49.8250 - val_loss: 41.4643 - val_mse: 41.4643\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 37.8794 - mse: 37.8794 - val_loss: 36.1126 - val_mse: 36.1126\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 35.2396 - mse: 35.2396 - val_loss: 34.9968 - val_mse: 34.9968\n",
            "mse: 34.996822357177734\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 24 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 0.1609 - mse: 0.1609 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0262 - val_mse: 0.0262\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "mse: 0.022239312529563904\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 25 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 347300.3750 - mse: 347300.3750 - val_loss: 36146.3750 - val_mse: 36146.3750\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 30115.1504 - mse: 30115.1504 - val_loss: 16986.3164 - val_mse: 16986.3164\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 10450.4736 - mse: 10450.4727 - val_loss: 7548.8999 - val_mse: 7548.8999\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 4935.9771 - mse: 4935.9771 - val_loss: 3491.8533 - val_mse: 3491.8533\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2854.1331 - mse: 2854.1331 - val_loss: 2158.0283 - val_mse: 2158.0283\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 3220.9568 - mse: 3220.9568 - val_loss: 1899.4712 - val_mse: 1899.4712\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 3527.9583 - mse: 3527.9583 - val_loss: 1131.7301 - val_mse: 1131.7301\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 2028.9093 - mse: 2028.9091 - val_loss: 830.0244 - val_mse: 830.0244\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1169.5665 - mse: 1169.5665 - val_loss: 570.0876 - val_mse: 570.0876\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2817.5952 - mse: 2817.5952 - val_loss: 1936.7152 - val_mse: 1936.7152\n",
            "mse: 1936.7152099609375\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 26 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "mse: 0.02280578203499317\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 27 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 2726238.2500 - mse: 2726238.2500 - val_loss: 1116062.2500 - val_mse: 1116062.2500\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 304349.0312 - mse: 304349.0312 - val_loss: 100712.0234 - val_mse: 100712.0234\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 46172.2617 - mse: 46172.2617 - val_loss: 12930.1348 - val_mse: 12930.1348\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 13974.8984 - mse: 13974.8984 - val_loss: 9296.5801 - val_mse: 9296.5801\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 6710.0986 - mse: 6710.0986 - val_loss: 3159.2612 - val_mse: 3159.2612\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 4702.8359 - mse: 4702.8359 - val_loss: 1319.1698 - val_mse: 1319.1698\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 8870.6426 - mse: 8870.6426 - val_loss: 1851.5063 - val_mse: 1851.5063\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 19102.5371 - mse: 19102.5371 - val_loss: 2432.8823 - val_mse: 2432.8823\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 18234.3926 - mse: 18234.3926 - val_loss: 3644.1040 - val_mse: 3644.1040\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 12625.0029 - mse: 12625.0029 - val_loss: 729.7021 - val_mse: 729.7021\n",
            "mse: 729.7021484375\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 28 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.2855 - mse: 0.2855 - val_loss: 0.1251 - val_mse: 0.1251\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0200 - val_mse: 0.0200\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "mse: 0.022011756896972656\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 29 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 6609441.5000 - mse: 6609441.5000 - val_loss: 1312575.1250 - val_mse: 1312575.1250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 550516.8125 - mse: 550516.8125 - val_loss: 140812.2188 - val_mse: 140812.2031\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 103828.2969 - mse: 103828.2969 - val_loss: 1792.3201 - val_mse: 1792.3201\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 15709.4219 - mse: 15709.4219 - val_loss: 3011.7029 - val_mse: 3011.7029\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 3485.6062 - mse: 3485.6062 - val_loss: 2250.9194 - val_mse: 2250.9194\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1167.9602 - mse: 1167.9602 - val_loss: 722.2985 - val_mse: 722.2985\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 817.8188 - mse: 817.8188 - val_loss: 640.9952 - val_mse: 640.9952\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 703.7388 - mse: 703.7388 - val_loss: 467.2868 - val_mse: 467.2868\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 596.3157 - mse: 596.3157 - val_loss: 478.8398 - val_mse: 478.8398\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 608.2839 - mse: 608.2839 - val_loss: 372.8349 - val_mse: 372.8349\n",
            "mse: 372.8349304199219\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 30 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 0.1441 - mse: 0.1441 - val_loss: 0.1011 - val_mse: 0.1011\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0480 - val_mse: 0.0480\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0349 - val_mse: 0.0349\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "mse: 0.03077480010688305\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 31 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 2357215.0000 - mse: 2357215.0000 - val_loss: 939822.5000 - val_mse: 939822.5000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 841462.5000 - mse: 841462.5000 - val_loss: 648299.1250 - val_mse: 648299.1250\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 597697.3750 - mse: 597697.3750 - val_loss: 464090.9062 - val_mse: 464090.9062\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 506890.9062 - mse: 506890.9062 - val_loss: 379422.0312 - val_mse: 379422.0312\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 378116.5625 - mse: 378116.5625 - val_loss: 284957.6250 - val_mse: 284957.6250\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 287611.0312 - mse: 287611.0312 - val_loss: 205331.7969 - val_mse: 205331.7969\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 207848.7812 - mse: 207848.7812 - val_loss: 144484.2500 - val_mse: 144484.2500\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 146306.2656 - mse: 146306.2656 - val_loss: 102483.9766 - val_mse: 102483.9766\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 102844.2422 - mse: 102844.2422 - val_loss: 67431.9375 - val_mse: 67431.9375\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 72544.3203 - mse: 72544.3203 - val_loss: 47148.7148 - val_mse: 47148.7148\n",
            "mse: 47148.71484375\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 32 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 23ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0398 - val_mse: 0.0398\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0362 - val_mse: 0.0362\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "mse: 0.024737562984228134\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 33 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 23ms/step - loss: 3377850.2500 - mse: 3377850.2500 - val_loss: 1168642.1250 - val_mse: 1168642.1250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 433510.4062 - mse: 433510.4062 - val_loss: 256583.4688 - val_mse: 256583.4688\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 186923.3594 - mse: 186923.3750 - val_loss: 130420.6172 - val_mse: 130420.6172\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 118157.2734 - mse: 118157.2734 - val_loss: 93997.0547 - val_mse: 93997.0547\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 85404.4531 - mse: 85404.4531 - val_loss: 66410.4219 - val_mse: 66410.4219\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 61121.8320 - mse: 61121.8320 - val_loss: 48298.7578 - val_mse: 48298.7578\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 43294.8828 - mse: 43294.8789 - val_loss: 33004.9609 - val_mse: 33004.9609\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 25136.5918 - mse: 25136.5918 - val_loss: 19997.9590 - val_mse: 19997.9590\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 16633.2832 - mse: 16633.2832 - val_loss: 12498.4346 - val_mse: 12498.4346\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 10923.2910 - mse: 10923.2910 - val_loss: 8178.1392 - val_mse: 8178.1392\n",
            "mse: 8178.13916015625\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 34 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 0.4015 - mse: 0.4015 - val_loss: 0.0363 - val_mse: 0.0363\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0268 - val_mse: 0.0268\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "mse: 0.023150980472564697\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 35 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 52976480.0000 - mse: 52976484.0000 - val_loss: 3064461.2500 - val_mse: 3064461.2500\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 4156986.7500 - mse: 4156986.7500 - val_loss: 83374.6406 - val_mse: 83374.6406\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 361472.5938 - mse: 361472.5938 - val_loss: 91036.8750 - val_mse: 91036.8750\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 74994.9688 - mse: 74994.9688 - val_loss: 60090.8867 - val_mse: 60090.8867\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 41288.3672 - mse: 41288.3672 - val_loss: 38548.5938 - val_mse: 38548.5938\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 37030.4570 - mse: 37030.4570 - val_loss: 38029.9648 - val_mse: 38029.9609\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 34922.7773 - mse: 34922.7812 - val_loss: 35113.5000 - val_mse: 35113.5000\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 33346.8672 - mse: 33346.8672 - val_loss: 33450.9258 - val_mse: 33450.9258\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 31681.8320 - mse: 31681.8320 - val_loss: 31262.6348 - val_mse: 31262.6348\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 30000.8711 - mse: 30000.8711 - val_loss: 29957.6719 - val_mse: 29957.6719\n",
            "mse: 29957.671875\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 36 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 24ms/step - loss: 0.2056 - mse: 0.2056 - val_loss: 0.1015 - val_mse: 0.1015\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0548 - val_mse: 0.0548\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "mse: 0.032554399222135544\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 37 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 36ms/step - loss: 38309340.0000 - mse: 38309340.0000 - val_loss: 3861991.5000 - val_mse: 3861991.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3045801.2500 - mse: 3045801.2500 - val_loss: 1573246.1250 - val_mse: 1573246.1250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 470589.6562 - mse: 470589.6562 - val_loss: 119440.0000 - val_mse: 119440.0000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 67175.0547 - mse: 67175.0547 - val_loss: 19503.1074 - val_mse: 19503.1074\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 30908.9727 - mse: 30908.9707 - val_loss: 7231.5986 - val_mse: 7231.5986\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12989.5352 - mse: 12989.5352 - val_loss: 5459.2344 - val_mse: 5459.2344\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6384.6162 - mse: 6384.6162 - val_loss: 3932.2588 - val_mse: 3932.2588\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4024.2625 - mse: 4024.2625 - val_loss: 2943.9189 - val_mse: 2943.9189\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2428.5515 - mse: 2428.5515 - val_loss: 2164.6050 - val_mse: 2164.6050\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2028.6526 - mse: 2028.6526 - val_loss: 1755.3477 - val_mse: 1755.3477\n",
            "mse: 1755.34765625\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 38 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 0.8323 - mse: 0.8323 - val_loss: 0.4699 - val_mse: 0.4699\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1797 - mse: 0.1797 - val_loss: 0.1276 - val_mse: 0.1276\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0745 - mse: 0.0745 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0396 - val_mse: 0.0396\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0390 - val_mse: 0.0390\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0344 - val_mse: 0.0344\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.032958563417196274\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 39 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 30ms/step - loss: 221539856.0000 - mse: 221539856.0000 - val_loss: 238258.0156 - val_mse: 238258.0156\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6743288.0000 - mse: 6743288.0000 - val_loss: 129453.4297 - val_mse: 129453.4297\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 916529.5625 - mse: 916529.5625 - val_loss: 206094.5000 - val_mse: 206094.5000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 177464.5469 - mse: 177464.5469 - val_loss: 10678.3447 - val_mse: 10678.3447\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 14019.4395 - mse: 14019.4395 - val_loss: 4008.1865 - val_mse: 4008.1865\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 6010.9912 - mse: 6010.9912 - val_loss: 3702.7319 - val_mse: 3702.7319\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3824.5649 - mse: 3824.5649 - val_loss: 4244.9487 - val_mse: 4244.9487\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2932.6248 - mse: 2932.6248 - val_loss: 2554.3887 - val_mse: 2554.3887\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2559.4155 - mse: 2559.4155 - val_loss: 2584.5334 - val_mse: 2584.5334\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2267.6216 - mse: 2267.6216 - val_loss: 1953.1090 - val_mse: 1953.1090\n",
            "mse: 1953.1090087890625\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 40 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 25ms/step - loss: 5.8419 - mse: 5.8419 - val_loss: 2.2996 - val_mse: 2.2996\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8372 - mse: 0.8372 - val_loss: 0.7233 - val_mse: 0.7233\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2434 - mse: 0.2434 - val_loss: 0.2227 - val_mse: 0.2227\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1131 - mse: 0.1131 - val_loss: 0.0944 - val_mse: 0.0944\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0428 - val_mse: 0.0428\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0382 - val_mse: 0.0382\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "mse: 0.03333338722586632\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 41 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 36ms/step - loss: 809943168.0000 - mse: 809943168.0000 - val_loss: 18682618.0000 - val_mse: 18682618.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 7829665.5000 - mse: 7829664.5000 - val_loss: 128965.6250 - val_mse: 128965.6250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 483241.5938 - mse: 483241.5938 - val_loss: 298436.0000 - val_mse: 298436.0000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 101428.2656 - mse: 101428.2656 - val_loss: 817.5834 - val_mse: 817.5834\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 13126.6660 - mse: 13126.6660 - val_loss: 4873.6543 - val_mse: 4873.6543\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6957.2432 - mse: 6957.2432 - val_loss: 1957.6797 - val_mse: 1957.6797\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2565.5103 - mse: 2565.5103 - val_loss: 1354.3221 - val_mse: 1354.3221\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1132.7135 - mse: 1132.7135 - val_loss: 671.5625 - val_mse: 671.5625\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 601.6492 - mse: 601.6492 - val_loss: 619.3188 - val_mse: 619.3188\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 376.1234 - mse: 376.1234 - val_loss: 331.4975 - val_mse: 331.4975\n",
            "mse: 331.4975280761719\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 42 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 25ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0279 - val_mse: 0.0279\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "mse: 0.020531387999653816\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 43 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 24ms/step - loss: 10158538.0000 - mse: 10158538.0000 - val_loss: 3062159.2500 - val_mse: 3062159.2500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1786868.7500 - mse: 1786868.7500 - val_loss: 1320150.7500 - val_mse: 1320150.7500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 706075.4375 - mse: 706075.3750 - val_loss: 574556.5625 - val_mse: 574556.5625\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 291261.8438 - mse: 291261.8438 - val_loss: 238983.2812 - val_mse: 238983.2812\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 126207.3594 - mse: 126207.3594 - val_loss: 82886.3047 - val_mse: 82886.3047\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 68627.1797 - mse: 68627.1797 - val_loss: 40878.3438 - val_mse: 40878.3438\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 41250.2148 - mse: 41250.2148 - val_loss: 27319.4062 - val_mse: 27319.4062\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 32109.5547 - mse: 32109.5547 - val_loss: 25454.0469 - val_mse: 25454.0469\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 27107.4648 - mse: 27107.4648 - val_loss: 27185.1680 - val_mse: 27185.1680\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 23863.1562 - mse: 23863.1562 - val_loss: 20138.3633 - val_mse: 20138.3633\n",
            "mse: 20138.36328125\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 44 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 0.1127 - mse: 0.1127 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0371 - val_mse: 0.0371\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "mse: 0.022971246391534805\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 45 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 6695149.5000 - mse: 6695149.5000 - val_loss: 1332236.7500 - val_mse: 1332236.7500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1840658.8750 - mse: 1840658.8750 - val_loss: 73876.5547 - val_mse: 73876.5547\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 553907.3125 - mse: 553907.3125 - val_loss: 31520.8398 - val_mse: 31520.8379\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 179540.1250 - mse: 179540.1250 - val_loss: 26584.9219 - val_mse: 26584.9180\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 77016.6875 - mse: 77016.6875 - val_loss: 10470.6982 - val_mse: 10470.6982\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 28859.1621 - mse: 28859.1621 - val_loss: 13139.2100 - val_mse: 13139.2100\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 13387.8564 - mse: 13387.8564 - val_loss: 8351.8770 - val_mse: 8351.8770\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6923.9443 - mse: 6923.9443 - val_loss: 4361.4243 - val_mse: 4361.4243\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4637.3359 - mse: 4637.3359 - val_loss: 4762.9746 - val_mse: 4762.9746\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3576.8384 - mse: 3576.8384 - val_loss: 2719.9954 - val_mse: 2719.9954\n",
            "mse: 2719.995361328125\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 46 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 38ms/step - loss: 0.1456 - mse: 0.1456 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0568 - mse: 0.0568 - val_loss: 0.0268 - val_mse: 0.0268\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "mse: 0.020466700196266174\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 47 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 28ms/step - loss: 13581307.0000 - mse: 13581307.0000 - val_loss: 9745398.0000 - val_mse: 9745398.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 3318654.0000 - mse: 3318654.0000 - val_loss: 1329051.1250 - val_mse: 1329051.1250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1205206.5000 - mse: 1205206.5000 - val_loss: 35626.1328 - val_mse: 35626.1328\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 283579.8125 - mse: 283579.8125 - val_loss: 81424.5469 - val_mse: 81424.5469\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101480.1016 - mse: 101480.1016 - val_loss: 43165.4609 - val_mse: 43165.4609\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 38357.3438 - mse: 38357.3398 - val_loss: 13989.5479 - val_mse: 13989.5479\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 14833.7812 - mse: 14833.7812 - val_loss: 4899.9136 - val_mse: 4899.9136\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7807.8003 - mse: 7807.8003 - val_loss: 3720.6646 - val_mse: 3720.6646\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4669.7515 - mse: 4669.7515 - val_loss: 3689.8115 - val_mse: 3689.8115\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2947.6321 - mse: 2947.6321 - val_loss: 2253.7805 - val_mse: 2253.7805\n",
            "mse: 2253.780517578125\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 48 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 2.5510 - mse: 2.5510 - val_loss: 2.4064 - val_mse: 2.4064\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1887 - mse: 2.1887 - val_loss: 2.0614 - val_mse: 2.0614\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8631 - mse: 1.8631 - val_loss: 1.7502 - val_mse: 1.7502\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5740 - mse: 1.5740 - val_loss: 1.4766 - val_mse: 1.4766\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3200 - mse: 1.3200 - val_loss: 1.2363 - val_mse: 1.2363\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0984 - mse: 1.0984 - val_loss: 1.0301 - val_mse: 1.0301\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9090 - mse: 0.9090 - val_loss: 0.8545 - val_mse: 0.8545\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7476 - mse: 0.7476 - val_loss: 0.7053 - val_mse: 0.7053\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6126 - mse: 0.6126 - val_loss: 0.5790 - val_mse: 0.5790\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4992 - mse: 0.4992 - val_loss: 0.4740 - val_mse: 0.4740\n",
            "mse: 0.47402486205101013\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 49 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 29ms/step - loss: 36185432.0000 - mse: 36185432.0000 - val_loss: 23062300.0000 - val_mse: 23062300.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 16018865.0000 - mse: 16018865.0000 - val_loss: 8717219.0000 - val_mse: 8717219.0000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5296869.5000 - mse: 5296869.5000 - val_loss: 2279687.0000 - val_mse: 2279687.0000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1275476.7500 - mse: 1275476.8750 - val_loss: 556143.5000 - val_mse: 556143.5000\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 535962.9375 - mse: 535963.0000 - val_loss: 459609.7500 - val_mse: 459609.7500\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 583578.4375 - mse: 583578.4375 - val_loss: 484988.3750 - val_mse: 484988.3750\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 557524.1875 - mse: 557524.1875 - val_loss: 425634.4062 - val_mse: 425634.4062\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 480609.6562 - mse: 480609.6562 - val_loss: 379517.7500 - val_mse: 379517.7500\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 430544.3125 - mse: 430544.3125 - val_loss: 353004.9062 - val_mse: 353004.9062\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 399463.5625 - mse: 399463.5625 - val_loss: 326993.8125 - val_mse: 326993.8125\n",
            "mse: 326993.8125\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 50 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 31ms/step - loss: 2.1523 - mse: 2.1523 - val_loss: 1.8014 - val_mse: 1.8014\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4601 - mse: 1.4601 - val_loss: 1.1891 - val_mse: 1.1891\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9328 - mse: 0.9328 - val_loss: 0.7424 - val_mse: 0.7424\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5616 - mse: 0.5616 - val_loss: 0.4423 - val_mse: 0.4423\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3228 - mse: 0.3228 - val_loss: 0.2542 - val_mse: 0.2542\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1803 - mse: 0.1803 - val_loss: 0.1470 - val_mse: 0.1470\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 0.0909 - val_mse: 0.0909\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0644 - val_mse: 0.0644\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0474 - val_mse: 0.0474\n",
            "mse: 0.04739665240049362\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 51 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 28ms/step - loss: 43767688.0000 - mse: 43767688.0000 - val_loss: 16392517.0000 - val_mse: 16392517.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7598197.5000 - mse: 7598197.5000 - val_loss: 581090.2500 - val_mse: 581090.2500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 662238.9375 - mse: 662238.9375 - val_loss: 1542306.0000 - val_mse: 1542306.0000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1514852.0000 - mse: 1514852.0000 - val_loss: 1207841.2500 - val_mse: 1207841.1250\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 635279.1250 - mse: 635279.0000 - val_loss: 258463.7656 - val_mse: 258463.7656\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 258160.0469 - mse: 258160.0469 - val_loss: 227729.6406 - val_mse: 227729.6406\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 253191.1094 - mse: 253191.1094 - val_loss: 157007.3438 - val_mse: 157007.3438\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 166345.0625 - mse: 166345.0781 - val_loss: 145886.6250 - val_mse: 145886.6250\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 147556.6406 - mse: 147556.6406 - val_loss: 121717.7500 - val_mse: 121717.7500\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 121042.2734 - mse: 121042.2734 - val_loss: 93852.3281 - val_mse: 93852.3281\n",
            "mse: 93852.328125\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 52 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 49ms/step - loss: 1.1108 - mse: 1.1108 - val_loss: 0.4497 - val_mse: 0.4497\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1871 - mse: 0.1871 - val_loss: 0.0511 - val_mse: 0.0511\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0706 - val_mse: 0.0706\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0556 - val_mse: 0.0556\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0380 - val_mse: 0.0380\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0401 - val_mse: 0.0401\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0357 - val_mse: 0.0357\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "mse: 0.029448097571730614\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 53 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 31ms/step - loss: 9113592.0000 - mse: 9113592.0000 - val_loss: 4662491.5000 - val_mse: 4662491.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2989170.2500 - mse: 2989170.2500 - val_loss: 67047.9922 - val_mse: 67047.9922\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 792108.1875 - mse: 792108.1875 - val_loss: 388571.0000 - val_mse: 388571.0000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 209379.8125 - mse: 209379.8125 - val_loss: 341682.9062 - val_mse: 341682.9062\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 134220.0781 - mse: 134220.0781 - val_loss: 98858.8281 - val_mse: 98858.8281\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 83167.7344 - mse: 83167.7344 - val_loss: 50302.7344 - val_mse: 50302.7344\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 46406.0195 - mse: 46406.0195 - val_loss: 35302.0391 - val_mse: 35302.0391\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 35801.8906 - mse: 35801.8867 - val_loss: 35899.6680 - val_mse: 35899.6680\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 30935.4180 - mse: 30935.4180 - val_loss: 29065.1309 - val_mse: 29065.1309\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 27778.0273 - mse: 27778.0273 - val_loss: 27941.5039 - val_mse: 27941.5039\n",
            "mse: 27941.50390625\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 54 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0379 - val_mse: 0.0379\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "mse: 0.03266054391860962\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 55 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 2825854.5000 - mse: 2825854.5000 - val_loss: 3488.9773 - val_mse: 3488.9773\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 15752.5186 - mse: 15752.5186 - val_loss: 672.6664 - val_mse: 672.6664\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 420.3189 - mse: 420.3189 - val_loss: 163.8005 - val_mse: 163.8005\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 137.1859 - mse: 137.1859 - val_loss: 69.7530 - val_mse: 69.7530\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 213.8529 - mse: 213.8529 - val_loss: 125.7577 - val_mse: 125.7577\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 212.2746 - mse: 212.2746 - val_loss: 50.5315 - val_mse: 50.5315\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 57.4035 - mse: 57.4035 - val_loss: 56.3595 - val_mse: 56.3595\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 72.2571 - mse: 72.2571 - val_loss: 37.1975 - val_mse: 37.1975\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 51.9070 - mse: 51.9070 - val_loss: 39.2111 - val_mse: 39.2111\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 46.7812 - mse: 46.7812 - val_loss: 30.5192 - val_mse: 30.5192\n",
            "mse: 30.519222259521484\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 56 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.1895 - mse: 0.1895 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0424 - val_mse: 0.0424\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0356 - val_mse: 0.0356\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "mse: 0.03307441994547844\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 57 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 36739780.0000 - mse: 36739780.0000 - val_loss: 4803.0498 - val_mse: 4803.0498\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 8014.1392 - mse: 8014.1392 - val_loss: 3839.8667 - val_mse: 3839.8667\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 926.4773 - mse: 926.4773 - val_loss: 209.9826 - val_mse: 209.9826\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 239.9561 - mse: 239.9561 - val_loss: 157.1235 - val_mse: 157.1235\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 205.2126 - mse: 205.2126 - val_loss: 152.5973 - val_mse: 152.5973\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 175.3054 - mse: 175.3054 - val_loss: 227.1662 - val_mse: 227.1662\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 172.0781 - mse: 172.0781 - val_loss: 175.5471 - val_mse: 175.5471\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 184.2500 - mse: 184.2500 - val_loss: 108.0794 - val_mse: 108.0794\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 153.8847 - mse: 153.8847 - val_loss: 115.4784 - val_mse: 115.4784\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 166.3302 - mse: 166.3302 - val_loss: 104.1599 - val_mse: 104.1599\n",
            "mse: 104.15991973876953\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 58 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.8490 - mse: 0.8490 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0459 - val_mse: 0.0459\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0354 - val_mse: 0.0354\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0439 - val_mse: 0.0439\n",
            "mse: 0.04392917454242706\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 59 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 43797120.0000 - mse: 43797120.0000 - val_loss: 26827.4238 - val_mse: 26827.4238\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1542.3492 - mse: 1542.3492 - val_loss: 65.8782 - val_mse: 65.8782\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 121.6018 - mse: 121.6018 - val_loss: 47.1592 - val_mse: 47.1592\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 62.8541 - mse: 62.8541 - val_loss: 37.5619 - val_mse: 37.5619\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 36.0529 - mse: 36.0529 - val_loss: 40.7094 - val_mse: 40.7094\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 34.2523 - mse: 34.2523 - val_loss: 14.5630 - val_mse: 14.5630\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 32.3125 - mse: 32.3125 - val_loss: 55.2863 - val_mse: 55.2863\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 30.2287 - mse: 30.2287 - val_loss: 8.9124 - val_mse: 8.9124\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 50.5605 - mse: 50.5605 - val_loss: 93.6106 - val_mse: 93.6106\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 21.0655 - mse: 21.0655 - val_loss: 67.7764 - val_mse: 67.7764\n",
            "mse: 67.77642822265625\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 60 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.4830 - mse: 0.4830 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "mse: 0.03220640867948532\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 61 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 4ms/step - loss: 30161154.0000 - mse: 30161154.0000 - val_loss: 364678.7500 - val_mse: 364678.7500\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 155521.2812 - mse: 155521.2812 - val_loss: 58108.3633 - val_mse: 58108.3633\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 36937.8242 - mse: 36937.8242 - val_loss: 16989.8496 - val_mse: 16989.8496\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 14075.2129 - mse: 14075.2129 - val_loss: 4761.0811 - val_mse: 4761.0811\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 10331.0283 - mse: 10331.0283 - val_loss: 2864.9097 - val_mse: 2864.9097\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 6758.1074 - mse: 6758.1074 - val_loss: 2551.0454 - val_mse: 2551.0454\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 3296.9585 - mse: 3296.9585 - val_loss: 1732.5385 - val_mse: 1732.5385\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2857.8645 - mse: 2857.8645 - val_loss: 1945.0946 - val_mse: 1945.0947\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 3720.2803 - mse: 3720.2803 - val_loss: 1373.6431 - val_mse: 1373.6431\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 3266.2737 - mse: 3266.2734 - val_loss: 1291.0055 - val_mse: 1291.0055\n",
            "mse: 1291.0054931640625\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 62 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.1702 - mse: 0.1702 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "mse: 0.026941636577248573\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 63 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 1542222.0000 - mse: 1542222.0000 - val_loss: 3702.8167 - val_mse: 3702.8167\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 34092.2578 - mse: 34092.2578 - val_loss: 1331.5785 - val_mse: 1331.5785\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 4375.7412 - mse: 4375.7412 - val_loss: 578.5132 - val_mse: 578.5132\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1898.7603 - mse: 1898.7603 - val_loss: 1005.8164 - val_mse: 1005.8164\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 6112.2407 - mse: 6112.2407 - val_loss: 6082.4644 - val_mse: 6082.4644\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 9619.8154 - mse: 9619.8154 - val_loss: 885.5533 - val_mse: 885.5533\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2103.2468 - mse: 2103.2468 - val_loss: 345.8999 - val_mse: 345.8999\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1455.9344 - mse: 1455.9344 - val_loss: 409.1400 - val_mse: 409.1400\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 2839.3640 - mse: 2839.3640 - val_loss: 3579.5247 - val_mse: 3579.5247\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1141.8160 - mse: 1141.8160 - val_loss: 233.1750 - val_mse: 233.1750\n",
            "mse: 233.17501831054688\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 64 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0466 - val_mse: 0.0466\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "mse: 0.029902731999754906\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 65 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 2024650.1250 - mse: 2024650.1250 - val_loss: 4073.4014 - val_mse: 4073.4014\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2337.0278 - mse: 2337.0278 - val_loss: 1408.8783 - val_mse: 1408.8783\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 777.0909 - mse: 777.0909 - val_loss: 1688.6187 - val_mse: 1688.6187\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 3976.4331 - mse: 3976.4331 - val_loss: 423.1924 - val_mse: 423.1924\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2501.9092 - mse: 2501.9092 - val_loss: 851.0601 - val_mse: 851.0601\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 25552.7832 - mse: 25552.7832 - val_loss: 11481.0635 - val_mse: 11481.0635\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 9719.9697 - mse: 9719.9697 - val_loss: 598.2070 - val_mse: 598.2070\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1283.1748 - mse: 1283.1748 - val_loss: 590.9644 - val_mse: 590.9644\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 6412.5737 - mse: 6412.5737 - val_loss: 335.7894 - val_mse: 335.7894\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 81517.0781 - mse: 81517.0703 - val_loss: 264580.1875 - val_mse: 264580.1875\n",
            "mse: 264580.1875\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 66 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 8ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0284 - val_mse: 0.0284\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "mse: 0.02192511409521103\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 67 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 11459413.0000 - mse: 11459412.0000 - val_loss: 42315.8867 - val_mse: 42315.8867\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 101971.7266 - mse: 101971.7266 - val_loss: 15420.7881 - val_mse: 15420.7881\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 65897.0547 - mse: 65897.0547 - val_loss: 10127.8486 - val_mse: 10127.8486\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 40840.9375 - mse: 40840.9375 - val_loss: 4978.2197 - val_mse: 4978.2197\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 28958.0234 - mse: 28958.0234 - val_loss: 2094.4624 - val_mse: 2094.4624\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 18708.4629 - mse: 18708.4629 - val_loss: 1369.6759 - val_mse: 1369.6759\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 12807.0039 - mse: 12807.0039 - val_loss: 1463.1031 - val_mse: 1463.1031\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 8715.2070 - mse: 8715.2070 - val_loss: 1479.7828 - val_mse: 1479.7828\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 5993.6216 - mse: 5993.6216 - val_loss: 1531.7800 - val_mse: 1531.7799\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 4290.3535 - mse: 4290.3530 - val_loss: 1230.2067 - val_mse: 1230.2067\n",
            "mse: 1230.2066650390625\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 68 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.3730 - mse: 0.3730 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0279 - val_mse: 0.0279\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "mse: 0.022619353607296944\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 69 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 1016624.9375 - mse: 1016624.9375 - val_loss: 38124.0352 - val_mse: 38124.0352\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 19354.1660 - mse: 19354.1660 - val_loss: 5038.9277 - val_mse: 5038.9277\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 4492.1245 - mse: 4492.1245 - val_loss: 2374.9348 - val_mse: 2374.9348\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2693.4988 - mse: 2693.4988 - val_loss: 1185.1805 - val_mse: 1185.1805\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1794.1105 - mse: 1794.1102 - val_loss: 950.0229 - val_mse: 950.0229\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1643.7351 - mse: 1643.7351 - val_loss: 905.5901 - val_mse: 905.5901\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1246.3218 - mse: 1246.3218 - val_loss: 723.5057 - val_mse: 723.5058\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1291.1731 - mse: 1291.1731 - val_loss: 994.2234 - val_mse: 994.2234\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1036.8058 - mse: 1036.8058 - val_loss: 545.3833 - val_mse: 545.3833\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1114.4930 - mse: 1114.4930 - val_loss: 586.9944 - val_mse: 586.9944\n",
            "mse: 586.994384765625\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 70 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.1519 - mse: 0.1519 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "mse: 0.020289454609155655\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 71 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 461935.0000 - mse: 461935.0000 - val_loss: 16808.9277 - val_mse: 16808.9277\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 10522.7012 - mse: 10522.7012 - val_loss: 2820.1362 - val_mse: 2820.1362\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 5300.1777 - mse: 5300.1777 - val_loss: 760.6324 - val_mse: 760.6324\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2031.2081 - mse: 2031.2081 - val_loss: 406.9069 - val_mse: 406.9069\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 781.3567 - mse: 781.3567 - val_loss: 340.6328 - val_mse: 340.6328\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 549.4609 - mse: 549.4609 - val_loss: 227.0649 - val_mse: 227.0649\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 670.1460 - mse: 670.1460 - val_loss: 454.2905 - val_mse: 454.2905\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 473.6684 - mse: 473.6684 - val_loss: 449.0360 - val_mse: 449.0360\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 13473.7861 - mse: 13473.7861 - val_loss: 221.1613 - val_mse: 221.1613\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2331.9089 - mse: 2331.9089 - val_loss: 404.0533 - val_mse: 404.0533\n",
            "mse: 404.0533447265625\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 72 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 0.4106 - mse: 0.4106 - val_loss: 0.1084 - val_mse: 0.1084\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0464 - val_mse: 0.0464\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "mse: 0.030792860314249992\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 73 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 28807132.0000 - mse: 28807132.0000 - val_loss: 4867004.5000 - val_mse: 4867004.5000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 889737.5625 - mse: 889737.5625 - val_loss: 135843.2969 - val_mse: 135843.2969\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 58386.5469 - mse: 58386.5469 - val_loss: 15908.0234 - val_mse: 15908.0234\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 16813.2598 - mse: 16813.2598 - val_loss: 8263.5342 - val_mse: 8263.5342\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 6558.7466 - mse: 6558.7466 - val_loss: 5326.7222 - val_mse: 5326.7222\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4772.2676 - mse: 4772.2676 - val_loss: 4259.8145 - val_mse: 4259.8145\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 3859.7820 - mse: 3859.7820 - val_loss: 3495.7905 - val_mse: 3495.7905\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 3005.3403 - mse: 3005.3403 - val_loss: 2924.9749 - val_mse: 2924.9749\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2448.0706 - mse: 2448.0706 - val_loss: 2302.1760 - val_mse: 2302.1760\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2070.0598 - mse: 2070.0598 - val_loss: 1929.6448 - val_mse: 1929.6448\n",
            "mse: 1929.644775390625\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 74 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.5074 - mse: 0.5074 - val_loss: 0.1605 - val_mse: 0.1605\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0371 - val_mse: 0.0371\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0355 - val_mse: 0.0355\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0377 - val_mse: 0.0377\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "mse: 0.03376424312591553\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 75 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 97528888.0000 - mse: 97528888.0000 - val_loss: 1024421.8125 - val_mse: 1024421.8125\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 310618.4062 - mse: 310618.4062 - val_loss: 20172.4609 - val_mse: 20172.4609\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 35515.8281 - mse: 35515.8281 - val_loss: 7189.8193 - val_mse: 7189.8193\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 6008.7881 - mse: 6008.7881 - val_loss: 734.1237 - val_mse: 734.1237\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1224.4927 - mse: 1224.4927 - val_loss: 277.8957 - val_mse: 277.8957\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 565.3275 - mse: 565.3275 - val_loss: 189.9631 - val_mse: 189.9631\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 380.4081 - mse: 380.4081 - val_loss: 154.7237 - val_mse: 154.7237\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 321.6638 - mse: 321.6638 - val_loss: 123.5369 - val_mse: 123.5369\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 288.3842 - mse: 288.3842 - val_loss: 121.3437 - val_mse: 121.3437\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 262.4478 - mse: 262.4478 - val_loss: 104.3765 - val_mse: 104.3765\n",
            "mse: 104.37645721435547\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 76 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 3.6334 - mse: 3.6334 - val_loss: 0.6901 - val_mse: 0.6901\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1608 - mse: 0.1608 - val_loss: 0.1091 - val_mse: 0.1091\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0409 - val_mse: 0.0409\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "mse: 0.03220532834529877\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 77 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 296044608.0000 - mse: 296044544.0000 - val_loss: 496245.5312 - val_mse: 496245.5312\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 149328.2031 - mse: 149328.2031 - val_loss: 2474.1841 - val_mse: 2474.1841\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 12089.9814 - mse: 12089.9824 - val_loss: 1830.6494 - val_mse: 1830.6494\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2014.6023 - mse: 2014.6023 - val_loss: 1222.0933 - val_mse: 1222.0934\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1088.0842 - mse: 1088.0842 - val_loss: 915.2404 - val_mse: 915.2404\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 783.6624 - mse: 783.6624 - val_loss: 625.7606 - val_mse: 625.7606\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 542.9614 - mse: 542.9614 - val_loss: 423.3201 - val_mse: 423.3201\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 369.6615 - mse: 369.6615 - val_loss: 277.4452 - val_mse: 277.4452\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 254.7351 - mse: 254.7351 - val_loss: 205.6965 - val_mse: 205.6965\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 197.3922 - mse: 197.3922 - val_loss: 131.1926 - val_mse: 131.1926\n",
            "mse: 131.1925811767578\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 78 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 11ms/step - loss: 0.8118 - mse: 0.8118 - val_loss: 0.0409 - val_mse: 0.0409\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0792 - mse: 0.0792 - val_loss: 0.0371 - val_mse: 0.0371\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0355 - val_mse: 0.0355\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0284 - val_mse: 0.0284\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "mse: 0.025749571621418\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 79 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 896658.0000 - mse: 896657.8750 - val_loss: 196651.8438 - val_mse: 196651.8438\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 92187.9922 - mse: 92187.9922 - val_loss: 29120.7676 - val_mse: 29120.7676\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 16591.1934 - mse: 16591.1934 - val_loss: 8060.2695 - val_mse: 8060.2695\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 6057.3896 - mse: 6057.3896 - val_loss: 2322.6538 - val_mse: 2322.6538\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 3187.6938 - mse: 3187.6938 - val_loss: 1713.4087 - val_mse: 1713.4087\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2146.7788 - mse: 2146.7788 - val_loss: 1383.6971 - val_mse: 1383.6971\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1788.6965 - mse: 1788.6965 - val_loss: 1343.4281 - val_mse: 1343.4281\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1445.2631 - mse: 1445.2631 - val_loss: 1160.2267 - val_mse: 1160.2267\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1219.6322 - mse: 1219.6321 - val_loss: 947.1516 - val_mse: 947.1514\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1234.4547 - mse: 1234.4547 - val_loss: 961.0896 - val_mse: 961.0896\n",
            "mse: 961.089599609375\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 80 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 54ms/step - loss: 0.3180 - mse: 0.3180 - val_loss: 0.0873 - val_mse: 0.0873\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "mse: 0.020880624651908875\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 81 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 3208005.5000 - mse: 3208005.5000 - val_loss: 59709.0859 - val_mse: 59709.0859\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 286423.2188 - mse: 286423.2188 - val_loss: 27573.5508 - val_mse: 27573.5508\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 42107.0000 - mse: 42107.0000 - val_loss: 22384.2441 - val_mse: 22384.2441\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 11412.2949 - mse: 11412.2949 - val_loss: 6120.9160 - val_mse: 6120.9160\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5524.3066 - mse: 5524.3066 - val_loss: 4098.3838 - val_mse: 4098.3838\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 3415.4448 - mse: 3415.4448 - val_loss: 2255.5466 - val_mse: 2255.5466\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1823.0520 - mse: 1823.0520 - val_loss: 1298.4177 - val_mse: 1298.4177\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 986.1932 - mse: 986.1932 - val_loss: 712.7473 - val_mse: 712.7473\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 693.5639 - mse: 693.5639 - val_loss: 506.5355 - val_mse: 506.5355\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 501.5291 - mse: 501.5291 - val_loss: 338.5154 - val_mse: 338.5154\n",
            "mse: 338.5154113769531\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 82 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.1627 - mse: 0.1627 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "mse: 0.021524379029870033\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 83 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 9656207.0000 - mse: 9656207.0000 - val_loss: 340832.4062 - val_mse: 340832.4062\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 736924.0625 - mse: 736924.0625 - val_loss: 525625.0000 - val_mse: 525625.0000\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 154593.7656 - mse: 154593.7656 - val_loss: 97735.4531 - val_mse: 97735.4531\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 35220.6641 - mse: 35220.6641 - val_loss: 9468.4561 - val_mse: 9468.4561\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 10775.4375 - mse: 10775.4375 - val_loss: 6385.5918 - val_mse: 6385.5918\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 4751.1870 - mse: 4751.1870 - val_loss: 4371.2070 - val_mse: 4371.2070\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2886.2129 - mse: 2886.2129 - val_loss: 1727.6417 - val_mse: 1727.6417\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 1617.8668 - mse: 1617.8668 - val_loss: 1126.6488 - val_mse: 1126.6488\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 1378.0039 - mse: 1378.0039 - val_loss: 697.4836 - val_mse: 697.4837\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 746.9850 - mse: 746.9850 - val_loss: 386.2902 - val_mse: 386.2902\n",
            "mse: 386.2901611328125\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 84 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 0.5676 - mse: 0.5676 - val_loss: 0.4319 - val_mse: 0.4319\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3049 - mse: 0.3049 - val_loss: 0.2244 - val_mse: 0.2244\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1493 - mse: 0.1493 - val_loss: 0.1100 - val_mse: 0.1100\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0716 - mse: 0.0716 - val_loss: 0.0593 - val_mse: 0.0593\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0397 - val_mse: 0.0397\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "mse: 0.02993583120405674\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 85 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 31738044.0000 - mse: 31738044.0000 - val_loss: 7522837.5000 - val_mse: 7522837.5000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2148751.0000 - mse: 2148751.0000 - val_loss: 137506.7188 - val_mse: 137506.7188\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 246851.0938 - mse: 246851.0938 - val_loss: 174708.2188 - val_mse: 174708.2188\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 91982.9609 - mse: 91982.9609 - val_loss: 63458.1758 - val_mse: 63458.1680\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 66052.0625 - mse: 66052.0625 - val_loss: 60720.8594 - val_mse: 60720.8594\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 60417.0195 - mse: 60417.0195 - val_loss: 58183.4453 - val_mse: 58183.4453\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 55751.8594 - mse: 55751.8633 - val_loss: 52416.0391 - val_mse: 52416.0391\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 48942.0625 - mse: 48942.0625 - val_loss: 44408.0625 - val_mse: 44408.0625\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 39719.9258 - mse: 39719.9258 - val_loss: 34182.4531 - val_mse: 34182.4531\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 29404.7637 - mse: 29404.7637 - val_loss: 23876.7168 - val_mse: 23876.7168\n",
            "mse: 23876.716796875\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 86 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 0.0769 - mse: 0.0769 - val_loss: 0.0400 - val_mse: 0.0400\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0355 - val_mse: 0.0355\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "mse: 0.02362423576414585\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 87 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 37199616.0000 - mse: 37199616.0000 - val_loss: 6004164.5000 - val_mse: 6004164.5000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1336634.8750 - mse: 1336634.8750 - val_loss: 609754.5625 - val_mse: 609754.5625\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 568073.8750 - mse: 568073.8750 - val_loss: 146610.7656 - val_mse: 146610.7500\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 151696.9062 - mse: 151696.8906 - val_loss: 156298.1094 - val_mse: 156298.1094\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 107371.2344 - mse: 107371.2344 - val_loss: 70128.1562 - val_mse: 70128.1484\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 61898.8398 - mse: 61898.8398 - val_loss: 52606.6562 - val_mse: 52606.6484\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 49690.7266 - mse: 49690.7266 - val_loss: 46457.8477 - val_mse: 46457.8477\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 35327.1641 - mse: 35327.1641 - val_loss: 27786.4629 - val_mse: 27786.4629\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 21889.8203 - mse: 21889.8164 - val_loss: 18825.2734 - val_mse: 18825.2734\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 17522.2617 - mse: 17522.2617 - val_loss: 16648.2461 - val_mse: 16648.2461\n",
            "mse: 16648.24609375\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 88 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0394 - val_mse: 0.0394\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "mse: 0.021031079813838005\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 89 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 1652601.7500 - mse: 1652601.7500 - val_loss: 580887.7500 - val_mse: 580887.7500\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 187839.3125 - mse: 187839.3125 - val_loss: 105693.9453 - val_mse: 105693.9453\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 52205.4414 - mse: 52205.4414 - val_loss: 31202.5859 - val_mse: 31202.5859\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 26653.2031 - mse: 26653.2031 - val_loss: 17743.9219 - val_mse: 17743.9219\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 13866.2412 - mse: 13866.2412 - val_loss: 9171.5381 - val_mse: 9171.5381\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 7720.0522 - mse: 7720.0522 - val_loss: 5665.7676 - val_mse: 5665.7676\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 4811.0273 - mse: 4811.0273 - val_loss: 3918.5825 - val_mse: 3918.5825\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2948.4111 - mse: 2948.4111 - val_loss: 2405.4951 - val_mse: 2405.4951\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1844.0355 - mse: 1844.0355 - val_loss: 1640.9840 - val_mse: 1640.9840\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1269.7422 - mse: 1269.7422 - val_loss: 1084.1019 - val_mse: 1084.1021\n",
            "mse: 1084.1019287109375\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 90 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 0.4175 - mse: 0.4175 - val_loss: 0.1520 - val_mse: 0.1520\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 0.1014 - val_mse: 0.1014\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0644 - mse: 0.0644 - val_loss: 0.0393 - val_mse: 0.0393\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0420 - val_mse: 0.0420\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0350 - val_mse: 0.0350\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "mse: 0.03165708854794502\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 91 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 72313608.0000 - mse: 72313608.0000 - val_loss: 38458984.0000 - val_mse: 38458984.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11946800.0000 - mse: 11946800.0000 - val_loss: 4063861.2500 - val_mse: 4063861.2500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2467121.0000 - mse: 2467121.0000 - val_loss: 366592.0312 - val_mse: 366592.0312\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 795227.7500 - mse: 795227.7500 - val_loss: 10078.5938 - val_mse: 10078.5938\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 311895.2188 - mse: 311895.2188 - val_loss: 35317.1406 - val_mse: 35317.1406\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 127059.5859 - mse: 127059.5859 - val_loss: 62039.3633 - val_mse: 62039.3633\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 56835.3008 - mse: 56835.3008 - val_loss: 48144.2070 - val_mse: 48144.2070\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25547.4473 - mse: 25547.4473 - val_loss: 20676.1797 - val_mse: 20676.1797\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 11629.6709 - mse: 11629.6709 - val_loss: 5463.0635 - val_mse: 5463.0635\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7061.6489 - mse: 7061.6489 - val_loss: 5302.6636 - val_mse: 5302.6636\n",
            "mse: 5302.66357421875\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 92 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 1.0077 - mse: 1.0077 - val_loss: 0.6420 - val_mse: 0.6420\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2274 - mse: 0.2274 - val_loss: 0.1972 - val_mse: 0.1972\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1123 - mse: 0.1123 - val_loss: 0.0371 - val_mse: 0.0371\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0344 - val_mse: 0.0344\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "mse: 0.03231034055352211\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 93 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 22ms/step - loss: 165548512.0000 - mse: 165548512.0000 - val_loss: 20043962.0000 - val_mse: 20043964.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11424660.0000 - mse: 11424660.0000 - val_loss: 5287916.0000 - val_mse: 5287916.5000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1532153.3750 - mse: 1532153.3750 - val_loss: 805874.2500 - val_mse: 805874.2500\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 246324.5469 - mse: 246324.5469 - val_loss: 107881.9922 - val_mse: 107881.9922\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 100760.0469 - mse: 100760.0469 - val_loss: 6462.6167 - val_mse: 6462.6167\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23643.4180 - mse: 23643.4180 - val_loss: 20329.5371 - val_mse: 20329.5371\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 9377.8975 - mse: 9377.8975 - val_loss: 13344.1104 - val_mse: 13344.1104\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7421.6675 - mse: 7421.6670 - val_loss: 3667.7498 - val_mse: 3667.7498\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4651.6421 - mse: 4651.6421 - val_loss: 3137.9119 - val_mse: 3137.9119\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3534.0869 - mse: 3534.0869 - val_loss: 3291.4065 - val_mse: 3291.4065\n",
            "mse: 3291.406494140625\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 94 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 6.6680 - mse: 6.6680 - val_loss: 3.0580 - val_mse: 3.0580\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0136 - mse: 1.0136 - val_loss: 0.8332 - val_mse: 0.8332\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2717 - mse: 0.2717 - val_loss: 0.2708 - val_mse: 0.2708\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1171 - mse: 0.1171 - val_loss: 0.1182 - val_mse: 0.1182\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0464 - val_mse: 0.0464\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0399 - val_mse: 0.0399\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0350 - val_mse: 0.0350\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "mse: 0.033471740782260895\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 95 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 62ms/step - loss: 500589120.0000 - mse: 500589120.0000 - val_loss: 8076280.5000 - val_mse: 8076280.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 1979462.1250 - mse: 1979462.1250 - val_loss: 373159.9375 - val_mse: 373159.9375\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 315945.3750 - mse: 315945.3750 - val_loss: 225777.0625 - val_mse: 225777.0625\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 80317.5625 - mse: 80317.5625 - val_loss: 2222.4395 - val_mse: 2222.4395\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 18174.3633 - mse: 18174.3633 - val_loss: 15046.0381 - val_mse: 15046.0381\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 9398.8477 - mse: 9398.8477 - val_loss: 7073.9233 - val_mse: 7073.9233\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3472.1699 - mse: 3472.1699 - val_loss: 904.7880 - val_mse: 904.7880\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1458.0999 - mse: 1458.0999 - val_loss: 766.5454 - val_mse: 766.5454\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 833.7109 - mse: 833.7109 - val_loss: 695.8024 - val_mse: 695.8024\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 577.7714 - mse: 577.7714 - val_loss: 411.3900 - val_mse: 411.3900\n",
            "mse: 411.38995361328125\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 96 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 1.9531 - mse: 1.9531 - val_loss: 0.7031 - val_mse: 0.7031\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2752 - mse: 0.2752 - val_loss: 0.0380 - val_mse: 0.0380\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0864 - val_mse: 0.0864\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0876 - mse: 0.0876 - val_loss: 0.0616 - val_mse: 0.0616\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0373 - val_mse: 0.0373\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "mse: 0.030764952301979065\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 97 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 135381200.0000 - mse: 135381200.0000 - val_loss: 10295418.0000 - val_mse: 10295418.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29231696.0000 - mse: 29231694.0000 - val_loss: 14417136.0000 - val_mse: 14417136.0000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4316187.5000 - mse: 4316187.5000 - val_loss: 4949670.0000 - val_mse: 4949670.0000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4338686.5000 - mse: 4338686.5000 - val_loss: 846308.1875 - val_mse: 846308.1875\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 674933.5000 - mse: 674933.5000 - val_loss: 1128080.3750 - val_mse: 1128080.3750\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 658618.4375 - mse: 658618.4375 - val_loss: 265181.1250 - val_mse: 265181.1250\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 355671.6250 - mse: 355671.6250 - val_loss: 293722.5625 - val_mse: 293722.5625\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 233050.3750 - mse: 233050.3750 - val_loss: 236710.1719 - val_mse: 236710.1719\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 220193.4688 - mse: 220193.4688 - val_loss: 203817.3438 - val_mse: 203817.3438\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 200518.3125 - mse: 200518.3125 - val_loss: 189209.4844 - val_mse: 189209.4844\n",
            "mse: 189209.484375\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 98 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 24ms/step - loss: 0.3160 - mse: 0.3160 - val_loss: 0.1993 - val_mse: 0.1993\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0805 - mse: 0.0805 - val_loss: 0.1063 - val_mse: 0.1063\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0445 - val_mse: 0.0445\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0361 - val_mse: 0.0361\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0261 - val_mse: 0.0261\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "mse: 0.024978283792734146\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 99 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 10772923.0000 - mse: 10772923.0000 - val_loss: 6074941.5000 - val_mse: 6074941.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3130913.0000 - mse: 3130913.0000 - val_loss: 1650357.2500 - val_mse: 1650357.2500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 804696.9375 - mse: 804696.9375 - val_loss: 107985.0547 - val_mse: 107985.0547\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 307186.7812 - mse: 307186.8125 - val_loss: 291212.6875 - val_mse: 291212.6562\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 119044.5781 - mse: 119044.5781 - val_loss: 6799.2681 - val_mse: 6799.2690\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 39589.1055 - mse: 39589.1055 - val_loss: 36590.9102 - val_mse: 36590.9102\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 15930.9180 - mse: 15930.9180 - val_loss: 8448.4199 - val_mse: 8448.4199\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9160.6143 - mse: 9160.6143 - val_loss: 4285.8550 - val_mse: 4285.8550\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3917.6719 - mse: 3917.6724 - val_loss: 1912.7253 - val_mse: 1912.7253\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1795.8226 - mse: 1795.8226 - val_loss: 1736.6547 - val_mse: 1736.6547\n",
            "mse: 1736.6546630859375\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 100 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 0.2827 - mse: 0.2827 - val_loss: 0.2202 - val_mse: 0.2202\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0952 - mse: 0.0952 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0421 - val_mse: 0.0421\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0197 - val_mse: 0.0197\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0200 - val_mse: 0.0200\n",
            "mse: 0.01998710073530674\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 101 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 41ms/step - loss: 9277750.0000 - mse: 9277751.0000 - val_loss: 4858061.0000 - val_mse: 4858061.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1975413.8750 - mse: 1975413.8750 - val_loss: 1641225.2500 - val_mse: 1641225.2500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 661861.3125 - mse: 661861.3125 - val_loss: 442946.0000 - val_mse: 442946.0000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 206194.5312 - mse: 206194.5312 - val_loss: 81479.4531 - val_mse: 81479.4531\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 71095.2031 - mse: 71095.2031 - val_loss: 7771.5078 - val_mse: 7771.5073\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 26162.9316 - mse: 26162.9316 - val_loss: 31377.0312 - val_mse: 31377.0312\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 12897.7012 - mse: 12897.7012 - val_loss: 1994.7384 - val_mse: 1994.7384\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 5078.9761 - mse: 5078.9761 - val_loss: 4405.9780 - val_mse: 4405.9780\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2473.5588 - mse: 2473.5588 - val_loss: 2257.7954 - val_mse: 2257.7954\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1640.5466 - mse: 1640.5466 - val_loss: 997.8179 - val_mse: 997.8179\n",
            "mse: 997.8179321289062\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 102 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 3.0219 - mse: 3.0219 - val_loss: 2.8738 - val_mse: 2.8738\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6531 - mse: 2.6531 - val_loss: 2.5207 - val_mse: 2.5207\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3188 - mse: 2.3188 - val_loss: 2.2010 - val_mse: 2.2010\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.0178 - mse: 2.0178 - val_loss: 1.9168 - val_mse: 1.9168\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7493 - mse: 1.7493 - val_loss: 1.6612 - val_mse: 1.6612\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5108 - mse: 1.5108 - val_loss: 1.4345 - val_mse: 1.4345\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2986 - mse: 1.2986 - val_loss: 1.2339 - val_mse: 1.2339\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1102 - mse: 1.1102 - val_loss: 1.0531 - val_mse: 1.0531\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9418 - mse: 0.9418 - val_loss: 0.8926 - val_mse: 0.8926\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7933 - mse: 0.7933 - val_loss: 0.7531 - val_mse: 0.7531\n",
            "mse: 0.7531012296676636\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 103 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 62104544.0000 - mse: 62104544.0000 - val_loss: 39758604.0000 - val_mse: 39758600.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 30490916.0000 - mse: 30490916.0000 - val_loss: 16427622.0000 - val_mse: 16427622.0000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 11692221.0000 - mse: 11692221.0000 - val_loss: 4695909.5000 - val_mse: 4695909.5000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3159881.2500 - mse: 3159881.2500 - val_loss: 768843.3125 - val_mse: 768843.3125\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 774528.6250 - mse: 774528.6250 - val_loss: 281115.7188 - val_mse: 281115.7188\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 560734.3750 - mse: 560734.3750 - val_loss: 445679.5938 - val_mse: 445679.5938\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 603985.3750 - mse: 603985.3750 - val_loss: 420506.4688 - val_mse: 420506.4688\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 536792.5000 - mse: 536792.5000 - val_loss: 322622.5312 - val_mse: 322622.5312\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 466918.5625 - mse: 466918.5625 - val_loss: 261568.5156 - val_mse: 261568.5156\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 429814.2812 - mse: 429814.2812 - val_loss: 236976.2969 - val_mse: 236976.2969\n",
            "mse: 236976.296875\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 104 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 24ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0411 - val_mse: 0.0411\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0400 - val_mse: 0.0400\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0267 - val_mse: 0.0267\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "mse: 0.023824652656912804\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 105 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 24ms/step - loss: 27141496.0000 - mse: 27141496.0000 - val_loss: 6087826.5000 - val_mse: 6087826.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1953701.1250 - mse: 1953701.1250 - val_loss: 1268675.2500 - val_mse: 1268675.2500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2216520.0000 - mse: 2216520.0000 - val_loss: 1661254.6250 - val_mse: 1661254.6250\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1125635.3750 - mse: 1125635.3750 - val_loss: 461022.5625 - val_mse: 461022.5625\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 506594.4062 - mse: 506594.4062 - val_loss: 635277.0000 - val_mse: 635277.0625\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 455973.6875 - mse: 455973.6875 - val_loss: 338995.2500 - val_mse: 338995.2500\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 298875.5938 - mse: 298875.5312 - val_loss: 288895.1562 - val_mse: 288895.1562\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 284232.9688 - mse: 284232.9688 - val_loss: 261625.0000 - val_mse: 261625.0000\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 245358.9219 - mse: 245358.9219 - val_loss: 259866.8750 - val_mse: 259866.8750\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 229315.6094 - mse: 229315.6094 - val_loss: 229555.2969 - val_mse: 229555.2969\n",
            "mse: 229555.296875\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 106 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 1.7006 - mse: 1.7006 - val_loss: 0.8839 - val_mse: 0.8839\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4681 - mse: 0.4681 - val_loss: 0.1536 - val_mse: 0.1536\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0496 - val_mse: 0.0496\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0376 - val_mse: 0.0376\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "mse: 0.02518775500357151\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 107 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 42ms/step - loss: 2488384.0000 - mse: 2488384.0000 - val_loss: 770268.5000 - val_mse: 770268.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 445350.0938 - mse: 445350.0938 - val_loss: 294118.1250 - val_mse: 294118.1250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 164405.6875 - mse: 164405.6875 - val_loss: 103508.2578 - val_mse: 103508.2578\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 63270.2969 - mse: 63270.2969 - val_loss: 28440.1738 - val_mse: 28440.1738\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 26244.8555 - mse: 26244.8555 - val_loss: 5309.1797 - val_mse: 5309.1797\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 12027.0059 - mse: 12027.0059 - val_loss: 6061.9131 - val_mse: 6061.9131\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8306.1348 - mse: 8306.1348 - val_loss: 7369.9868 - val_mse: 7369.9868\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6680.0103 - mse: 6680.0103 - val_loss: 4807.7090 - val_mse: 4807.7090\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4922.0273 - mse: 4922.0273 - val_loss: 3474.7217 - val_mse: 3474.7217\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4178.5732 - mse: 4178.5732 - val_loss: 3406.2537 - val_mse: 3406.2537\n",
            "mse: 3406.253662109375\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 108 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0708 - mse: 0.0708 - val_loss: 0.0358 - val_mse: 0.0358\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0351 - val_mse: 0.0351\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0428 - val_mse: 0.0428\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "mse: 0.03125983849167824\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 109 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 6ms/step - loss: 5519996.0000 - mse: 5519996.0000 - val_loss: 2138.6689 - val_mse: 2138.6689\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1042.2365 - mse: 1042.2365 - val_loss: 691.4653 - val_mse: 691.4653\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1834.6379 - mse: 1834.6379 - val_loss: 183.2536 - val_mse: 183.2536\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 585.3127 - mse: 585.3127 - val_loss: 155.3233 - val_mse: 155.3233\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 1277.7389 - mse: 1277.7389 - val_loss: 814.5240 - val_mse: 814.5240\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 466.7126 - mse: 466.7126 - val_loss: 185.0891 - val_mse: 185.0891\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 200.9885 - mse: 200.9885 - val_loss: 185.7969 - val_mse: 185.7969\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 378.1219 - mse: 378.1219 - val_loss: 254.0311 - val_mse: 254.0311\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1510.5760 - mse: 1510.5760 - val_loss: 286.5042 - val_mse: 286.5042\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1680.3875 - mse: 1680.3875 - val_loss: 42.2450 - val_mse: 42.2450\n",
            "mse: 42.2450065612793\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 110 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.1927 - mse: 0.1927 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0417 - val_mse: 0.0417\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0369 - val_mse: 0.0369\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "mse: 0.03391718119382858\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 111 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 46571088.0000 - mse: 46571088.0000 - val_loss: 16450.6250 - val_mse: 16450.6250\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 6552.8467 - mse: 6552.8467 - val_loss: 862.7571 - val_mse: 862.7571\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 609.3839 - mse: 609.3839 - val_loss: 407.9196 - val_mse: 407.9196\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 190.4234 - mse: 190.4234 - val_loss: 50.3772 - val_mse: 50.3772\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 96.4381 - mse: 96.4381 - val_loss: 79.4164 - val_mse: 79.4164\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 94.6719 - mse: 94.6719 - val_loss: 32.7250 - val_mse: 32.7250\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 70.4007 - mse: 70.4007 - val_loss: 34.1203 - val_mse: 34.1203\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 34.1255 - mse: 34.1255 - val_loss: 45.3316 - val_mse: 45.3316\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 159.5062 - mse: 159.5062 - val_loss: 80.5734 - val_mse: 80.5734\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 406.7516 - mse: 406.7516 - val_loss: 60.3863 - val_mse: 60.3863\n",
            "mse: 60.38630676269531\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 112 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.7975 - mse: 0.7975 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0354 - val_mse: 0.0354\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0378 - val_mse: 0.0378\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0476 - val_mse: 0.0476\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0349 - val_mse: 0.0349\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0379 - val_mse: 0.0379\n",
            "mse: 0.037866879254579544\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 113 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 32352728.0000 - mse: 32352730.0000 - val_loss: 1631.6617 - val_mse: 1631.6617\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 988.4981 - mse: 988.4981 - val_loss: 138.9848 - val_mse: 138.9848\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 211.6967 - mse: 211.6967 - val_loss: 49.0296 - val_mse: 49.0296\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 64.7119 - mse: 64.7119 - val_loss: 17.6953 - val_mse: 17.6953\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 28.7563 - mse: 28.7563 - val_loss: 10.5932 - val_mse: 10.5932\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 18.8410 - mse: 18.8410 - val_loss: 30.3358 - val_mse: 30.3358\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 14.7269 - mse: 14.7269 - val_loss: 9.8284 - val_mse: 9.8284\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 16.8300 - mse: 16.8300 - val_loss: 6.9644 - val_mse: 6.9644\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 20.5019 - mse: 20.5019 - val_loss: 12.9209 - val_mse: 12.9209\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 13.3246 - mse: 13.3246 - val_loss: 8.5456 - val_mse: 8.5456\n",
            "mse: 8.545554161071777\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 114 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "mse: 0.02631092257797718\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 115 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 7203749.0000 - mse: 7203749.0000 - val_loss: 74163.4844 - val_mse: 74163.4922\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 24650.5117 - mse: 24650.5117 - val_loss: 9426.8291 - val_mse: 9426.8291\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 7167.4272 - mse: 7167.4272 - val_loss: 5196.0156 - val_mse: 5196.0156\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 3781.2661 - mse: 3781.2661 - val_loss: 2596.6824 - val_mse: 2596.6824\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2947.1716 - mse: 2947.1711 - val_loss: 2040.6058 - val_mse: 2040.6058\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 3132.8564 - mse: 3132.8564 - val_loss: 1378.5420 - val_mse: 1378.5419\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1743.8868 - mse: 1743.8867 - val_loss: 1603.8126 - val_mse: 1603.8126\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 3093.2158 - mse: 3093.2158 - val_loss: 2225.7097 - val_mse: 2225.7097\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 2085.9961 - mse: 2085.9961 - val_loss: 879.5131 - val_mse: 879.5131\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 914.0494 - mse: 914.0494 - val_loss: 1226.1719 - val_mse: 1226.1719\n",
            "mse: 1226.171875\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 116 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0925 - mse: 0.0925 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0268 - val_mse: 0.0268\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0376 - val_mse: 0.0376\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0547 - val_mse: 0.0547\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "mse: 0.031101174652576447\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 117 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 729516.1250 - mse: 729516.1250 - val_loss: 18157.0762 - val_mse: 18157.0762\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 21924.8516 - mse: 21924.8516 - val_loss: 1522.6936 - val_mse: 1522.6936\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 22348.9180 - mse: 22348.9180 - val_loss: 19483.0430 - val_mse: 19483.0430\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 10641.8516 - mse: 10641.8516 - val_loss: 738.9195 - val_mse: 738.9195\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 979.8010 - mse: 979.8010 - val_loss: 412.5051 - val_mse: 412.5051\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 3468.2224 - mse: 3468.2224 - val_loss: 475.4374 - val_mse: 475.4374\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1153.9083 - mse: 1153.9083 - val_loss: 261.9786 - val_mse: 261.9786\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 615.5487 - mse: 615.5487 - val_loss: 1080.3215 - val_mse: 1080.3217\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1475.3608 - mse: 1475.3608 - val_loss: 332.3127 - val_mse: 332.3127\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 686.0917 - mse: 686.0917 - val_loss: 229.7573 - val_mse: 229.7573\n",
            "mse: 229.75733947753906\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 118 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0658 - mse: 0.0658 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0419 - val_mse: 0.0419\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0487 - val_mse: 0.0487\n",
            "mse: 0.04869389906525612\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 119 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 3427783.7500 - mse: 3427783.7500 - val_loss: 7505.6172 - val_mse: 7505.6172\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2193.4231 - mse: 2193.4231 - val_loss: 423.8968 - val_mse: 423.8968\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 3704.5188 - mse: 3704.5183 - val_loss: 1631.8650 - val_mse: 1631.8650\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 529.8476 - mse: 529.8476 - val_loss: 146.9581 - val_mse: 146.9581\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 4990.0444 - mse: 4990.0444 - val_loss: 2225.0229 - val_mse: 2225.0229\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2103.7480 - mse: 2103.7480 - val_loss: 456.0724 - val_mse: 456.0724\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 342.3410 - mse: 342.3410 - val_loss: 776.3402 - val_mse: 776.3402\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 15506.2910 - mse: 15506.2910 - val_loss: 938.8693 - val_mse: 938.8693\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 20858.5664 - mse: 20858.5664 - val_loss: 145.0940 - val_mse: 145.0940\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 579.2842 - mse: 579.2842 - val_loss: 97.6651 - val_mse: 97.6651\n",
            "mse: 97.66508483886719\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 120 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1850 - mse: 0.1850 - val_loss: 0.0429 - val_mse: 0.0429\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0379 - val_mse: 0.0379\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0344 - val_mse: 0.0344\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "mse: 0.024432383477687836\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 121 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 168057.3906 - mse: 168057.3906 - val_loss: 24985.8906 - val_mse: 24985.8867\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 75189.2109 - mse: 75189.2109 - val_loss: 10251.1016 - val_mse: 10251.1016\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 38099.5430 - mse: 38099.5430 - val_loss: 5830.9976 - val_mse: 5830.9976\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 20752.3965 - mse: 20752.3965 - val_loss: 3889.8699 - val_mse: 3889.8699\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 12664.1016 - mse: 12664.1016 - val_loss: 3081.2568 - val_mse: 3081.2568\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 7188.4351 - mse: 7188.4351 - val_loss: 1426.9174 - val_mse: 1426.9174\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 5176.7070 - mse: 5176.7070 - val_loss: 1452.0820 - val_mse: 1452.0818\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 3553.7808 - mse: 3553.7808 - val_loss: 719.8055 - val_mse: 719.8055\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 2766.1963 - mse: 2766.1963 - val_loss: 745.0294 - val_mse: 745.0294\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2330.5327 - mse: 2330.5327 - val_loss: 589.7118 - val_mse: 589.7118\n",
            "mse: 589.7117919921875\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 122 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2837 - mse: 0.2837 - val_loss: 0.0374 - val_mse: 0.0374\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "mse: 0.023286812007427216\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 123 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 4ms/step - loss: 297940.2188 - mse: 297940.2188 - val_loss: 26193.8125 - val_mse: 26193.8125\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 24049.6211 - mse: 24049.6211 - val_loss: 9538.6816 - val_mse: 9538.6826\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 8024.4429 - mse: 8024.4429 - val_loss: 4534.3770 - val_mse: 4534.3770\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2888.8364 - mse: 2888.8364 - val_loss: 2173.6235 - val_mse: 2173.6235\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1702.8735 - mse: 1702.8735 - val_loss: 1307.1628 - val_mse: 1307.1628\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1248.0464 - mse: 1248.0463 - val_loss: 1339.7501 - val_mse: 1339.7501\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1013.6721 - mse: 1013.6721 - val_loss: 784.3234 - val_mse: 784.3234\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 746.9503 - mse: 746.9503 - val_loss: 711.4088 - val_mse: 711.4088\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 751.9431 - mse: 751.9431 - val_loss: 466.3229 - val_mse: 466.3229\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 608.7620 - mse: 608.7620 - val_loss: 615.2989 - val_mse: 615.2989\n",
            "mse: 615.2988891601562\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 124 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 14ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "mse: 0.02156889997422695\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 125 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 1182882.1250 - mse: 1182882.1250 - val_loss: 7519.9805 - val_mse: 7519.9805\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 6288.0112 - mse: 6288.0112 - val_loss: 3079.7708 - val_mse: 3079.7708\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2243.6145 - mse: 2243.6145 - val_loss: 979.6183 - val_mse: 979.6183\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2041.1747 - mse: 2041.1747 - val_loss: 410.7408 - val_mse: 410.7408\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2612.9688 - mse: 2612.9688 - val_loss: 516.1967 - val_mse: 516.1967\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 497.1883 - mse: 497.1883 - val_loss: 380.0285 - val_mse: 380.0285\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 412.8703 - mse: 412.8703 - val_loss: 236.8291 - val_mse: 236.8291\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 346.2973 - mse: 346.2973 - val_loss: 450.1428 - val_mse: 450.1428\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 979.0167 - mse: 979.0167 - val_loss: 245.6851 - val_mse: 245.6851\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 186.1321 - mse: 186.1321 - val_loss: 198.8352 - val_mse: 198.8352\n",
            "mse: 198.83518981933594\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 126 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 0.1924 - mse: 0.1924 - val_loss: 0.1059 - val_mse: 0.1059\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0354 - val_mse: 0.0354\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0354 - val_mse: 0.0354\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "mse: 0.03261922299861908\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 127 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 21ms/step - loss: 58505972.0000 - mse: 58505968.0000 - val_loss: 1553332.0000 - val_mse: 1553332.0000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1308332.5000 - mse: 1308332.5000 - val_loss: 24969.6719 - val_mse: 24969.6719\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 125010.8516 - mse: 125010.8516 - val_loss: 4967.3320 - val_mse: 4967.3320\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 17996.7969 - mse: 17996.7969 - val_loss: 5196.2842 - val_mse: 5196.2837\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 5439.4824 - mse: 5439.4824 - val_loss: 2770.6199 - val_mse: 2770.6199\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 3478.6921 - mse: 3478.6921 - val_loss: 1905.2991 - val_mse: 1905.2993\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 3028.0847 - mse: 3028.0847 - val_loss: 1807.5551 - val_mse: 1807.5551\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 2826.9492 - mse: 2826.9492 - val_loss: 1616.5813 - val_mse: 1616.5813\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2594.4697 - mse: 2594.4695 - val_loss: 1513.2010 - val_mse: 1513.2012\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 2353.0469 - mse: 2353.0469 - val_loss: 1389.3816 - val_mse: 1389.3816\n",
            "mse: 1389.381591796875\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 128 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 0.8006 - mse: 0.8006 - val_loss: 0.1202 - val_mse: 0.1202\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0817 - mse: 0.0817 - val_loss: 0.0454 - val_mse: 0.0454\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0363 - val_mse: 0.0363\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0352 - val_mse: 0.0352\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "mse: 0.03158607706427574\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 129 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 147362576.0000 - mse: 147362576.0000 - val_loss: 8659731.0000 - val_mse: 8659731.0000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1849107.7500 - mse: 1849107.7500 - val_loss: 148745.8750 - val_mse: 148745.8750\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 179231.7031 - mse: 179231.7031 - val_loss: 67538.9844 - val_mse: 67538.9844\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 17268.7520 - mse: 17268.7520 - val_loss: 5805.0210 - val_mse: 5805.0210\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 4292.3809 - mse: 4292.3809 - val_loss: 1152.1091 - val_mse: 1152.1091\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1718.2771 - mse: 1718.2771 - val_loss: 1088.6345 - val_mse: 1088.6345\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1265.2539 - mse: 1265.2539 - val_loss: 965.2106 - val_mse: 965.2106\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1098.4904 - mse: 1098.4904 - val_loss: 950.5771 - val_mse: 950.5771\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 985.1285 - mse: 985.1285 - val_loss: 863.2902 - val_mse: 863.2902\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1003.3600 - mse: 1003.3600 - val_loss: 811.5717 - val_mse: 811.5717\n",
            "mse: 811.5717163085938\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 130 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 3.1851 - mse: 3.1851 - val_loss: 0.5572 - val_mse: 0.5572\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1626 - mse: 0.1626 - val_loss: 0.0959 - val_mse: 0.0959\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0383 - val_mse: 0.0383\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0357 - val_mse: 0.0357\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "mse: 0.03307085484266281\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 131 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 232885264.0000 - mse: 232885264.0000 - val_loss: 1606567.7500 - val_mse: 1606567.7500\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 228846.6875 - mse: 228846.6875 - val_loss: 14062.8535 - val_mse: 14062.8535\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 11506.5449 - mse: 11506.5449 - val_loss: 3213.7861 - val_mse: 3213.7861\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 5315.3110 - mse: 5315.3110 - val_loss: 2237.0242 - val_mse: 2237.0242\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 4604.7549 - mse: 4604.7549 - val_loss: 1386.8544 - val_mse: 1386.8544\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 4449.5063 - mse: 4449.5063 - val_loss: 841.3273 - val_mse: 841.3273\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 1008.2747 - mse: 1008.2747 - val_loss: 427.2892 - val_mse: 427.2892\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 388.1922 - mse: 388.1922 - val_loss: 221.4293 - val_mse: 221.4293\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 314.5890 - mse: 314.5890 - val_loss: 123.6758 - val_mse: 123.6758\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 118.3707 - mse: 118.3707 - val_loss: 82.3593 - val_mse: 82.3593\n",
            "mse: 82.35934448242188\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 132 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "mse: 0.022474385797977448\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 133 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 26769736.0000 - mse: 26769736.0000 - val_loss: 674501.2500 - val_mse: 674501.1875\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2161966.2500 - mse: 2161966.5000 - val_loss: 1098998.5000 - val_mse: 1098998.5000\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 343500.1250 - mse: 343500.1250 - val_loss: 53157.1875 - val_mse: 53157.1875\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 67634.2891 - mse: 67634.2891 - val_loss: 11509.8135 - val_mse: 11509.8135\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 15022.6270 - mse: 15022.6270 - val_loss: 6652.1943 - val_mse: 6652.1943\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7433.3999 - mse: 7433.3999 - val_loss: 6408.6357 - val_mse: 6408.6357\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 5918.3921 - mse: 5918.3921 - val_loss: 5228.8940 - val_mse: 5228.8940\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5438.0654 - mse: 5438.0654 - val_loss: 5003.9297 - val_mse: 5003.9297\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5069.1489 - mse: 5069.1489 - val_loss: 4858.7090 - val_mse: 4858.7095\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 4934.9980 - mse: 4934.9980 - val_loss: 4606.1157 - val_mse: 4606.1157\n",
            "mse: 4606.11572265625\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 134 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 0.1228 - mse: 0.1228 - val_loss: 0.0367 - val_mse: 0.0367\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "mse: 0.024536212906241417\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 135 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 1187837.8750 - mse: 1187837.8750 - val_loss: 437917.1250 - val_mse: 437917.1250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 176887.6875 - mse: 176887.6875 - val_loss: 22712.2930 - val_mse: 22712.2891\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 33101.9766 - mse: 33101.9766 - val_loss: 8092.8867 - val_mse: 8092.8867\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 7454.2373 - mse: 7454.2373 - val_loss: 2475.0295 - val_mse: 2475.0295\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 3962.4656 - mse: 3962.4656 - val_loss: 1880.6606 - val_mse: 1880.6606\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 2059.8977 - mse: 2059.8977 - val_loss: 1338.4181 - val_mse: 1338.4181\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 995.3433 - mse: 995.3433 - val_loss: 637.9249 - val_mse: 637.9249\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 790.3823 - mse: 790.3823 - val_loss: 486.2714 - val_mse: 486.2714\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 566.1156 - mse: 566.1156 - val_loss: 398.4459 - val_mse: 398.4459\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 480.4388 - mse: 480.4388 - val_loss: 544.6309 - val_mse: 544.6309\n",
            "mse: 544.630859375\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 136 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.2307 - mse: 0.2307 - val_loss: 0.0923 - val_mse: 0.0923\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "mse: 0.021848086267709732\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 137 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 11480767.0000 - mse: 11480767.0000 - val_loss: 3078918.2500 - val_mse: 3078918.2500\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 949520.6875 - mse: 949520.6875 - val_loss: 410417.3438 - val_mse: 410417.3438\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 124628.2969 - mse: 124628.2969 - val_loss: 18620.2969 - val_mse: 18620.2969\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 18958.3594 - mse: 18958.3594 - val_loss: 12987.3105 - val_mse: 12987.3105\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 8219.2949 - mse: 8219.2949 - val_loss: 5346.2129 - val_mse: 5346.2129\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 4452.5571 - mse: 4452.5571 - val_loss: 2668.1035 - val_mse: 2668.1035\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 3020.7778 - mse: 3020.7773 - val_loss: 1605.7332 - val_mse: 1605.7332\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1956.6846 - mse: 1956.6846 - val_loss: 907.3757 - val_mse: 907.3757\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1489.5688 - mse: 1489.5690 - val_loss: 640.1916 - val_mse: 640.1916\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1881.7866 - mse: 1881.7866 - val_loss: 635.4196 - val_mse: 635.4196\n",
            "mse: 635.4195556640625\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 138 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 4.1788 - mse: 4.1788 - val_loss: 3.8092 - val_mse: 3.8092\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 3.4058 - mse: 3.4058 - val_loss: 3.0902 - val_mse: 3.0902\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.7405 - mse: 2.7405 - val_loss: 2.4792 - val_mse: 2.4792\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 2.1886 - mse: 2.1886 - val_loss: 1.9819 - val_mse: 1.9819\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.7306 - mse: 1.7306 - val_loss: 1.5559 - val_mse: 1.5559\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.3485 - mse: 1.3485 - val_loss: 1.2119 - val_mse: 1.2119\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0368 - mse: 1.0368 - val_loss: 0.9325 - val_mse: 0.9325\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.7847 - mse: 0.7847 - val_loss: 0.7005 - val_mse: 0.7005\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5784 - mse: 0.5784 - val_loss: 0.5159 - val_mse: 0.5159\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4188 - mse: 0.4188 - val_loss: 0.3738 - val_mse: 0.3738\n",
            "mse: 0.3738303482532501\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 139 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 12ms/step - loss: 10125125.0000 - mse: 10125125.0000 - val_loss: 2333869.2500 - val_mse: 2333869.0000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 713057.3125 - mse: 713057.3125 - val_loss: 159757.5938 - val_mse: 159757.5938\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 157374.5781 - mse: 157374.5781 - val_loss: 134340.9062 - val_mse: 134340.9219\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 71606.8281 - mse: 71606.8281 - val_loss: 66710.4609 - val_mse: 66710.4609\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 51876.7031 - mse: 51876.7031 - val_loss: 53313.4375 - val_mse: 53313.4375\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 40578.6523 - mse: 40578.6523 - val_loss: 42395.0195 - val_mse: 42395.0195\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 31734.7637 - mse: 31734.7637 - val_loss: 31313.0547 - val_mse: 31313.0547\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 22693.0781 - mse: 22693.0781 - val_loss: 19856.2695 - val_mse: 19856.2695\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 15235.1572 - mse: 15235.1572 - val_loss: 13521.3633 - val_mse: 13521.3633\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 11332.5947 - mse: 11332.5947 - val_loss: 10234.6709 - val_mse: 10234.6709\n",
            "mse: 10234.6708984375\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 140 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 2s 25ms/step - loss: 4.1801 - mse: 4.1801 - val_loss: 3.1725 - val_mse: 3.1725\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 2.3774 - mse: 2.3774 - val_loss: 1.7257 - val_mse: 1.7257\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 1.2262 - mse: 1.2262 - val_loss: 0.8568 - val_mse: 0.8568\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.5767 - mse: 0.5767 - val_loss: 0.3982 - val_mse: 0.3982\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2551 - mse: 0.2551 - val_loss: 0.1802 - val_mse: 0.1802\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1114 - mse: 0.1114 - val_loss: 0.0867 - val_mse: 0.0867\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0440 - val_mse: 0.0440\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0412 - val_mse: 0.0412\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0401 - val_mse: 0.0401\n",
            "mse: 0.04005417600274086\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 141 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 49797.4375 - mse: 49797.4375 - val_loss: 10618.6543 - val_mse: 10618.6553\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 9893.6191 - mse: 9893.6191 - val_loss: 4973.1621 - val_mse: 4973.1621\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4129.0513 - mse: 4129.0513 - val_loss: 2402.4890 - val_mse: 2402.4890\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1494.9379 - mse: 1494.9379 - val_loss: 900.8392 - val_mse: 900.8392\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 632.0550 - mse: 632.0550 - val_loss: 516.6367 - val_mse: 516.6367\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 496.7863 - mse: 496.7863 - val_loss: 435.3233 - val_mse: 435.3233\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 442.2656 - mse: 442.2655 - val_loss: 485.2759 - val_mse: 485.2759\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 414.8013 - mse: 414.8013 - val_loss: 419.9158 - val_mse: 419.9158\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 368.8805 - mse: 368.8805 - val_loss: 344.9951 - val_mse: 344.9951\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 372.1079 - mse: 372.1079 - val_loss: 395.0078 - val_mse: 395.0078\n",
            "mse: 395.00775146484375\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 142 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "mse: 0.022276336327195168\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 143 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 22626858.0000 - mse: 22626856.0000 - val_loss: 6267968.0000 - val_mse: 6267968.0000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2186265.7500 - mse: 2186265.7500 - val_loss: 640072.6250 - val_mse: 640072.6250\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 345484.4375 - mse: 345484.4375 - val_loss: 208883.0312 - val_mse: 208883.0312\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 86801.5234 - mse: 86801.5234 - val_loss: 32379.8926 - val_mse: 32379.8926\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 26164.5684 - mse: 26164.5684 - val_loss: 19224.9336 - val_mse: 19224.9336\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 16175.7705 - mse: 16175.7705 - val_loss: 10427.6787 - val_mse: 10427.6787\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 10874.2637 - mse: 10874.2637 - val_loss: 6589.0552 - val_mse: 6589.0552\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 7203.9902 - mse: 7203.9902 - val_loss: 4210.3892 - val_mse: 4210.3892\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 4180.5679 - mse: 4180.5679 - val_loss: 2469.4165 - val_mse: 2469.4165\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2930.6572 - mse: 2930.6572 - val_loss: 1776.3978 - val_mse: 1776.3977\n",
            "mse: 1776.3978271484375\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 144 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 21ms/step - loss: 0.3954 - mse: 0.3954 - val_loss: 0.2931 - val_mse: 0.2931\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1125 - mse: 0.1125 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0515 - val_mse: 0.0515\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0371 - val_mse: 0.0371\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0365 - val_mse: 0.0365\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "mse: 0.03287528082728386\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 145 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 50ms/step - loss: 75360480.0000 - mse: 75360480.0000 - val_loss: 36792892.0000 - val_mse: 36792888.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 13014280.0000 - mse: 13014281.0000 - val_loss: 8021781.5000 - val_mse: 8021781.5000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2564526.2500 - mse: 2564526.2500 - val_loss: 2805632.7500 - val_mse: 2805632.7500\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1005083.6250 - mse: 1005083.6250 - val_loss: 724988.6875 - val_mse: 724988.6875\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 391173.7500 - mse: 391173.7500 - val_loss: 25998.4863 - val_mse: 25998.4863\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 15088.0732 - mse: 15088.0732 - val_loss: 5626.7368 - val_mse: 5626.7368\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6446.4229 - mse: 6446.4229 - val_loss: 4980.4204 - val_mse: 4980.4204\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3599.7041 - mse: 3599.7041 - val_loss: 1885.1526 - val_mse: 1885.1526\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2348.1006 - mse: 2348.1003 - val_loss: 2055.0017 - val_mse: 2055.0017\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1544.0298 - mse: 1544.0298 - val_loss: 1065.5244 - val_mse: 1065.5244\n",
            "mse: 1065.5244140625\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 146 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 0.8533 - mse: 0.8533 - val_loss: 0.5120 - val_mse: 0.5120\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2003 - mse: 0.2003 - val_loss: 0.0870 - val_mse: 0.0870\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0842 - mse: 0.0842 - val_loss: 0.0405 - val_mse: 0.0405\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0370 - val_mse: 0.0370\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0295 - val_mse: 0.0295\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "mse: 0.02886424958705902\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 147 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 25ms/step - loss: 295160512.0000 - mse: 295160512.0000 - val_loss: 398810.9062 - val_mse: 398810.9062\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10721328.0000 - mse: 10721328.0000 - val_loss: 635335.6875 - val_mse: 635335.6875\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2394090.7500 - mse: 2394090.7500 - val_loss: 554612.1875 - val_mse: 554612.1875\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 703101.3750 - mse: 703101.3750 - val_loss: 279730.8750 - val_mse: 279730.8750\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 96120.3828 - mse: 96120.3828 - val_loss: 14475.6230 - val_mse: 14475.6230\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 29538.5703 - mse: 29538.5703 - val_loss: 18023.5645 - val_mse: 18023.5645\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12570.3740 - mse: 12570.3740 - val_loss: 11792.3896 - val_mse: 11792.3896\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6703.8423 - mse: 6703.8423 - val_loss: 6191.8818 - val_mse: 6191.8813\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4341.6230 - mse: 4341.6230 - val_loss: 5133.4819 - val_mse: 5133.4819\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3565.6597 - mse: 3565.6592 - val_loss: 3617.2651 - val_mse: 3617.2651\n",
            "mse: 3617.26513671875\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 148 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 30ms/step - loss: 4.9978 - mse: 4.9978 - val_loss: 1.8426 - val_mse: 1.8426\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6640 - mse: 0.6640 - val_loss: 0.3395 - val_mse: 0.3395\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1608 - mse: 0.1608 - val_loss: 0.0921 - val_mse: 0.0921\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0719 - mse: 0.0719 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "mse: 0.0323665626347065\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 149 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 28ms/step - loss: 673910272.0000 - mse: 673910272.0000 - val_loss: 8162347.0000 - val_mse: 8162347.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2430517.5000 - mse: 2430517.5000 - val_loss: 12305.2539 - val_mse: 12305.2539\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 343490.9688 - mse: 343490.9688 - val_loss: 2670.2388 - val_mse: 2670.2388\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 49253.9727 - mse: 49253.9727 - val_loss: 30641.8086 - val_mse: 30641.8086\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 16689.3203 - mse: 16689.3203 - val_loss: 14508.3203 - val_mse: 14508.3203\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6914.8550 - mse: 6914.8550 - val_loss: 6636.1411 - val_mse: 6636.1411\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2893.4902 - mse: 2893.4902 - val_loss: 2536.6399 - val_mse: 2536.6401\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1421.5839 - mse: 1421.5839 - val_loss: 687.9088 - val_mse: 687.9088\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 723.2789 - mse: 723.2789 - val_loss: 452.0783 - val_mse: 452.0783\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 461.1204 - mse: 461.1204 - val_loss: 370.3207 - val_mse: 370.3207\n",
            "mse: 370.3206787109375\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 150 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0409 - val_mse: 0.0409\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "mse: 0.024070242419838905\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 151 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 37ms/step - loss: 7748176.0000 - mse: 7748176.0000 - val_loss: 591830.1875 - val_mse: 591830.1875\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1435028.5000 - mse: 1435028.5000 - val_loss: 30392.8516 - val_mse: 30392.8516\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 501109.5625 - mse: 501109.5625 - val_loss: 25130.1855 - val_mse: 25130.1855\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 201620.2344 - mse: 201620.2344 - val_loss: 57396.9492 - val_mse: 57396.9492\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 91093.4297 - mse: 91093.4297 - val_loss: 66832.5469 - val_mse: 66832.5469\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 43998.3672 - mse: 43998.3672 - val_loss: 39465.7656 - val_mse: 39465.7617\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 21012.4688 - mse: 21012.4688 - val_loss: 14776.7451 - val_mse: 14776.7451\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 9537.9922 - mse: 9537.9922 - val_loss: 5185.5630 - val_mse: 5185.5630\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5681.4707 - mse: 5681.4707 - val_loss: 4773.4585 - val_mse: 4773.4585\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4201.8892 - mse: 4201.8892 - val_loss: 3031.7285 - val_mse: 3031.7285\n",
            "mse: 3031.728515625\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 152 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 0.5834 - mse: 0.5834 - val_loss: 0.3571 - val_mse: 0.3571\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2015 - mse: 0.2015 - val_loss: 0.0494 - val_mse: 0.0494\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0816 - mse: 0.0816 - val_loss: 0.0446 - val_mse: 0.0446\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0406 - val_mse: 0.0406\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0384 - val_mse: 0.0384\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0279 - val_mse: 0.0279\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0286 - val_mse: 0.0286\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "mse: 0.02517935447394848\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 153 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 25ms/step - loss: 15151857.0000 - mse: 15151857.0000 - val_loss: 6048833.0000 - val_mse: 6048832.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3919409.2500 - mse: 3919409.2500 - val_loss: 3172280.5000 - val_mse: 3172280.5000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1312406.6250 - mse: 1312406.6250 - val_loss: 442606.7500 - val_mse: 442606.7500\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 368570.9375 - mse: 368570.9375 - val_loss: 123272.6719 - val_mse: 123272.6875\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 176995.4375 - mse: 176995.4375 - val_loss: 157187.6875 - val_mse: 157187.6875\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 76776.1875 - mse: 76776.1875 - val_loss: 7601.5137 - val_mse: 7601.5137\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 29292.9824 - mse: 29292.9824 - val_loss: 34615.8906 - val_mse: 34615.8906\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 15693.0449 - mse: 15693.0449 - val_loss: 6697.5327 - val_mse: 6697.5327\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 7225.0820 - mse: 7225.0820 - val_loss: 2353.2131 - val_mse: 2353.2131\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3658.3403 - mse: 3658.3403 - val_loss: 2726.6399 - val_mse: 2726.6399\n",
            "mse: 2726.639892578125\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 154 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 41ms/step - loss: 0.3927 - mse: 0.3927 - val_loss: 0.2617 - val_mse: 0.2617\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1287 - mse: 0.1287 - val_loss: 0.0760 - val_mse: 0.0760\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "mse: 0.021778125315904617\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 155 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 33ms/step - loss: 21881576.0000 - mse: 21881576.0000 - val_loss: 295923.5625 - val_mse: 295923.5625\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4155927.2500 - mse: 4155927.2500 - val_loss: 1696255.1250 - val_mse: 1696255.1250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1194148.8750 - mse: 1194148.8750 - val_loss: 1604012.3750 - val_mse: 1604012.3750\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 593717.8750 - mse: 593717.8750 - val_loss: 579468.6875 - val_mse: 579468.6875\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 300002.9375 - mse: 300002.9375 - val_loss: 187821.2188 - val_mse: 187821.2188\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 131422.9219 - mse: 131422.9219 - val_loss: 96526.8906 - val_mse: 96526.8906\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 60603.2578 - mse: 60603.2578 - val_loss: 53694.1211 - val_mse: 53694.1211\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 25137.2363 - mse: 25137.2363 - val_loss: 10330.2422 - val_mse: 10330.2422\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 11432.6777 - mse: 11432.6777 - val_loss: 7428.6196 - val_mse: 7428.6187\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 4620.2280 - mse: 4620.2280 - val_loss: 2884.3826 - val_mse: 2884.3826\n",
            "mse: 2884.382568359375\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 156 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 0.9122 - mse: 0.9122 - val_loss: 0.8404 - val_mse: 0.8404\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7302 - mse: 0.7302 - val_loss: 0.6743 - val_mse: 0.6743\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5746 - mse: 0.5746 - val_loss: 0.5286 - val_mse: 0.5286\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4434 - mse: 0.4434 - val_loss: 0.4074 - val_mse: 0.4074\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3392 - mse: 0.3392 - val_loss: 0.3137 - val_mse: 0.3137\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2572 - mse: 0.2572 - val_loss: 0.2385 - val_mse: 0.2385\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1937 - mse: 0.1937 - val_loss: 0.1835 - val_mse: 0.1835\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1462 - mse: 0.1462 - val_loss: 0.1415 - val_mse: 0.1415\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0852 - mse: 0.0852 - val_loss: 0.0874 - val_mse: 0.0874\n",
            "mse: 0.08735381066799164\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 1\n",
            "models fitted: 157 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 43159728.0000 - mse: 43159728.0000 - val_loss: 21297764.0000 - val_mse: 21297764.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13682004.0000 - mse: 13682004.0000 - val_loss: 3968638.2500 - val_mse: 3968638.2500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2671231.0000 - mse: 2671231.0000 - val_loss: 663430.5625 - val_mse: 663430.5625\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1452524.5000 - mse: 1452524.5000 - val_loss: 1252852.0000 - val_mse: 1252852.0000\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1649877.6250 - mse: 1649877.6250 - val_loss: 1044920.5000 - val_mse: 1044920.5000\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1274458.8750 - mse: 1274458.8750 - val_loss: 601845.0625 - val_mse: 601845.0000\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1007469.0000 - mse: 1007469.0000 - val_loss: 483867.0312 - val_mse: 483867.0312\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 936005.6875 - mse: 936005.6875 - val_loss: 421757.7188 - val_mse: 421757.7188\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 838670.5625 - mse: 838670.5625 - val_loss: 340842.8438 - val_mse: 340842.8438\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 722310.1875 - mse: 722310.1875 - val_loss: 274416.4688 - val_mse: 274416.4688\n",
            "mse: 274416.46875\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 1\n",
            "models fitted: 158 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 2.0923 - mse: 2.0923 - val_loss: 1.7326 - val_mse: 1.7326\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.3968 - mse: 1.3968 - val_loss: 1.1262 - val_mse: 1.1262\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8762 - mse: 0.8762 - val_loss: 0.6850 - val_mse: 0.6850\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5126 - mse: 0.5126 - val_loss: 0.3955 - val_mse: 0.3955\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2842 - mse: 0.2842 - val_loss: 0.2205 - val_mse: 0.2205\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1541 - mse: 0.1541 - val_loss: 0.1259 - val_mse: 0.1259\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.0792 - val_mse: 0.0792\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0589 - val_mse: 0.0589\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0502 - val_mse: 0.0502\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0467 - val_mse: 0.0467\n",
            "mse: 0.046680059283971786\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 1\n",
            "models fitted: 159 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 2390136.7500 - mse: 2390136.7500 - val_loss: 1029723.8125 - val_mse: 1029723.8125\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1048945.7500 - mse: 1048945.7500 - val_loss: 442621.0000 - val_mse: 442621.0000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 486903.7500 - mse: 486903.7500 - val_loss: 524531.1250 - val_mse: 524531.1250\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 293871.0312 - mse: 293871.0312 - val_loss: 238749.1719 - val_mse: 238749.1719\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 180031.3438 - mse: 180031.3438 - val_loss: 163456.3750 - val_mse: 163456.3750\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 108993.7109 - mse: 108993.7109 - val_loss: 79275.6719 - val_mse: 79275.6719\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 61322.5586 - mse: 61322.5586 - val_loss: 48159.7344 - val_mse: 48159.7344\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 33748.4219 - mse: 33748.4219 - val_loss: 28560.0000 - val_mse: 28560.0000\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 24437.2285 - mse: 24437.2285 - val_loss: 23424.7168 - val_mse: 23424.7168\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 19193.2656 - mse: 19193.2656 - val_loss: 16736.8008 - val_mse: 16736.8008\n",
            "mse: 16736.80078125\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 1\n",
            "models fitted: 160 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 30ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0470 - val_mse: 0.0470\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "mse: 0.020406195893883705\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 1\n",
            "models fitted: 161 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 30ms/step - loss: 7871146.5000 - mse: 7871146.5000 - val_loss: 1513674.7500 - val_mse: 1513674.7500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2372608.7500 - mse: 2372608.7500 - val_loss: 1035548.8750 - val_mse: 1035548.8750\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 465754.5938 - mse: 465754.5938 - val_loss: 617840.5625 - val_mse: 617840.5625\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 451633.5312 - mse: 451633.5312 - val_loss: 156706.4531 - val_mse: 156706.4531\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 190713.4062 - mse: 190713.4062 - val_loss: 142830.1875 - val_mse: 142830.1875\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 94394.6875 - mse: 94394.6875 - val_loss: 68266.1016 - val_mse: 68266.1094\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 50351.3984 - mse: 50351.3984 - val_loss: 37618.5156 - val_mse: 37618.5156\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 28737.5449 - mse: 28737.5430 - val_loss: 24347.0898 - val_mse: 24347.0898\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 17861.8496 - mse: 17861.8496 - val_loss: 15934.0635 - val_mse: 15934.0635\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 11760.5127 - mse: 11760.5127 - val_loss: 11584.5352 - val_mse: 11584.5352\n",
            "mse: 11584.53515625\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 1\n",
            "models fitted: 162 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 9ms/step - loss: 0.0908 - mse: 0.0908 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0351 - val_mse: 0.0351\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0764 - val_mse: 0.0764\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0506 - val_mse: 0.0506\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "mse: 0.03272709622979164\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 163 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 1631882.8750 - mse: 1631882.8750 - val_loss: 799.6246 - val_mse: 799.6246\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1546.9459 - mse: 1546.9459 - val_loss: 220.0931 - val_mse: 220.0931\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1436.2189 - mse: 1436.2189 - val_loss: 1409.0316 - val_mse: 1409.0316\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 11168.3369 - mse: 11168.3369 - val_loss: 410.2642 - val_mse: 410.2641\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 765.1458 - mse: 765.1459 - val_loss: 312.4050 - val_mse: 312.4050\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 270.2293 - mse: 270.2293 - val_loss: 6.4986 - val_mse: 6.4986\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 48.0065 - mse: 48.0065 - val_loss: 73.0556 - val_mse: 73.0556\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 47.2644 - mse: 47.2644 - val_loss: 7.6776 - val_mse: 7.6776\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 34.0571 - mse: 34.0571 - val_loss: 5.4568 - val_mse: 5.4568\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 51.1208 - mse: 51.1208 - val_loss: 28.2931 - val_mse: 28.2931\n",
            "mse: 28.293079376220703\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 164 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1673 - mse: 0.1673 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0428 - val_mse: 0.0428\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0436 - val_mse: 0.0436\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0374 - val_mse: 0.0374\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0344 - val_mse: 0.0344\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0397 - val_mse: 0.0397\n",
            "mse: 0.03967325761914253\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 165 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 33763168.0000 - mse: 33763168.0000 - val_loss: 7238.8955 - val_mse: 7238.8955\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 812.8747 - mse: 812.8747 - val_loss: 100.5407 - val_mse: 100.5407\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 179.7290 - mse: 179.7290 - val_loss: 39.9595 - val_mse: 39.9595\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 166.9756 - mse: 166.9756 - val_loss: 63.5703 - val_mse: 63.5703\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 239.3469 - mse: 239.3469 - val_loss: 59.4226 - val_mse: 59.4226\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 267.6520 - mse: 267.6520 - val_loss: 80.7640 - val_mse: 80.7640\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 217.0809 - mse: 217.0809 - val_loss: 1523.2284 - val_mse: 1523.2284\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 797.9041 - mse: 797.9041 - val_loss: 36.5323 - val_mse: 36.5323\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 321.8238 - mse: 321.8238 - val_loss: 16.1491 - val_mse: 16.1491\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1365.9640 - mse: 1365.9640 - val_loss: 735.1843 - val_mse: 735.1843\n",
            "mse: 735.1842651367188\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 166 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8913 - mse: 0.8913 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 2s 16ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0375 - val_mse: 0.0375\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0354 - val_mse: 0.0354\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 15ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0464 - val_mse: 0.0464\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0536 - val_mse: 0.0536\n",
            "mse: 0.05355134978890419\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 167 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 154697376.0000 - mse: 154697376.0000 - val_loss: 16404.6426 - val_mse: 16404.6426\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 19592.5938 - mse: 19592.5938 - val_loss: 1136.8577 - val_mse: 1136.8577\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 717.4882 - mse: 717.4882 - val_loss: 162.6161 - val_mse: 162.6161\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 140.8157 - mse: 140.8157 - val_loss: 189.7013 - val_mse: 189.7013\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 48.6759 - mse: 48.6759 - val_loss: 90.0999 - val_mse: 90.0999\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 59.7829 - mse: 59.7829 - val_loss: 12.2347 - val_mse: 12.2347\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 64.9195 - mse: 64.9195 - val_loss: 12.7335 - val_mse: 12.7335\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 89.5733 - mse: 89.5733 - val_loss: 56.3538 - val_mse: 56.3539\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 173.5859 - mse: 173.5859 - val_loss: 551.8992 - val_mse: 551.8992\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 130.1427 - mse: 130.1427 - val_loss: 285.3380 - val_mse: 285.3380\n",
            "mse: 285.3380126953125\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 168 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 7ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0295 - val_mse: 0.0295\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0345 - val_mse: 0.0345\n",
            "mse: 0.034520700573921204\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 169 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 2484350.7500 - mse: 2484350.7500 - val_loss: 3007.6741 - val_mse: 3007.6741\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 3897.7168 - mse: 3897.7168 - val_loss: 632.0806 - val_mse: 632.0806\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1337.9191 - mse: 1337.9191 - val_loss: 319.8696 - val_mse: 319.8696\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 950.8538 - mse: 950.8538 - val_loss: 202.5059 - val_mse: 202.5059\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 347.7660 - mse: 347.7660 - val_loss: 164.3725 - val_mse: 164.3725\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 3131.1492 - mse: 3131.1492 - val_loss: 162.2268 - val_mse: 162.2268\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 697.6074 - mse: 697.6074 - val_loss: 120.2973 - val_mse: 120.2973\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1208.3324 - mse: 1208.3324 - val_loss: 152.9078 - val_mse: 152.9078\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 162.5415 - mse: 162.5415 - val_loss: 80.5706 - val_mse: 80.5706\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 158.8302 - mse: 158.8302 - val_loss: 70.5143 - val_mse: 70.5143\n",
            "mse: 70.51432800292969\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 170 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0286 - val_mse: 0.0286\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "mse: 0.031092992052435875\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 171 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 855473.4375 - mse: 855473.4375 - val_loss: 1611.4049 - val_mse: 1611.4049\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 37353.1445 - mse: 37353.1445 - val_loss: 4567.5161 - val_mse: 4567.5161\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 3734.8513 - mse: 3734.8513 - val_loss: 879.6746 - val_mse: 879.6746\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1962.5618 - mse: 1962.5618 - val_loss: 389.9025 - val_mse: 389.9025\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1486.9696 - mse: 1486.9696 - val_loss: 596.2322 - val_mse: 596.2322\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 566.2833 - mse: 566.2833 - val_loss: 141.6028 - val_mse: 141.6028\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1698.6355 - mse: 1698.6355 - val_loss: 132.7477 - val_mse: 132.7477\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1092.1669 - mse: 1092.1669 - val_loss: 545.7929 - val_mse: 545.7929\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2964.5491 - mse: 2964.5491 - val_loss: 3357.7493 - val_mse: 3357.7493\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 499.6607 - mse: 499.6607 - val_loss: 106.9235 - val_mse: 106.9235\n",
            "mse: 106.92346954345703\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 172 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 12ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0471 - val_mse: 0.0471\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0350 - val_mse: 0.0350\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "mse: 0.02540193311870098\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 173 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 10ms/step - loss: 1388481.3750 - mse: 1388481.3750 - val_loss: 300.9806 - val_mse: 300.9806\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 5154.4536 - mse: 5154.4531 - val_loss: 102.4009 - val_mse: 102.4009\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 299.6885 - mse: 299.6885 - val_loss: 52.5982 - val_mse: 52.5982\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 509.8058 - mse: 509.8058 - val_loss: 219.0858 - val_mse: 219.0858\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2087.7649 - mse: 2087.7649 - val_loss: 2307.4983 - val_mse: 2307.4983\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 439.6551 - mse: 439.6551 - val_loss: 39.4131 - val_mse: 39.4131\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 86.2548 - mse: 86.2548 - val_loss: 22.4286 - val_mse: 22.4286\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 102.6224 - mse: 102.6224 - val_loss: 15.9462 - val_mse: 15.9462\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1322.2435 - mse: 1322.2435 - val_loss: 22.6319 - val_mse: 22.6319\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 50.8376 - mse: 50.8376 - val_loss: 15.5915 - val_mse: 15.5915\n",
            "mse: 15.591489791870117\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 174 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 1.7471 - mse: 1.7471 - val_loss: 0.6288 - val_mse: 0.6288\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2415 - mse: 0.2415 - val_loss: 0.0739 - val_mse: 0.0739\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0352 - val_mse: 0.0352\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "mse: 0.03076593391597271\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 175 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 8ms/step - loss: 6453315.5000 - mse: 6453315.5000 - val_loss: 24936.4609 - val_mse: 24936.4609\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 24388.4785 - mse: 24388.4785 - val_loss: 12459.5234 - val_mse: 12459.5234\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 15328.1104 - mse: 15328.1104 - val_loss: 9879.5586 - val_mse: 9879.5596\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 11338.5068 - mse: 11338.5068 - val_loss: 7807.9941 - val_mse: 7807.9941\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 9325.3438 - mse: 9325.3438 - val_loss: 6612.0669 - val_mse: 6612.0669\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 7499.1040 - mse: 7499.1040 - val_loss: 5386.5464 - val_mse: 5386.5464\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 5863.5645 - mse: 5863.5645 - val_loss: 4099.8911 - val_mse: 4099.8911\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 3986.0139 - mse: 3986.0139 - val_loss: 2653.2566 - val_mse: 2653.2566\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2990.0667 - mse: 2990.0667 - val_loss: 2323.3738 - val_mse: 2323.3738\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 2483.5190 - mse: 2483.5190 - val_loss: 1995.2750 - val_mse: 1995.2750\n",
            "mse: 1995.2750244140625\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 176 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 0.2649 - mse: 0.2649 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0287 - val_mse: 0.0287\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "mse: 0.021865608170628548\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 177 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 31844.5059 - mse: 31844.5059 - val_loss: 2636.0833 - val_mse: 2636.0833\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2429.2761 - mse: 2429.2761 - val_loss: 1084.4652 - val_mse: 1084.4652\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1211.1284 - mse: 1211.1284 - val_loss: 406.5060 - val_mse: 406.5060\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 394.0026 - mse: 394.0027 - val_loss: 363.6356 - val_mse: 363.6356\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 434.8079 - mse: 434.8079 - val_loss: 283.7299 - val_mse: 283.7299\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 521.3261 - mse: 521.3261 - val_loss: 370.8349 - val_mse: 370.8349\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 587.0320 - mse: 587.0319 - val_loss: 8092.0244 - val_mse: 8092.0244\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 14378.2617 - mse: 14378.2627 - val_loss: 11113.5664 - val_mse: 11113.5664\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2573.4280 - mse: 2573.4280 - val_loss: 1369.6073 - val_mse: 1369.6073\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2166.5698 - mse: 2166.5698 - val_loss: 358.5775 - val_mse: 358.5775\n",
            "mse: 358.57745361328125\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 178 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0201 - val_mse: 0.0201\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "mse: 0.022642668336629868\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 179 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 1251257.0000 - mse: 1251257.0000 - val_loss: 1773.0413 - val_mse: 1773.0413\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2151.5151 - mse: 2151.5151 - val_loss: 937.6944 - val_mse: 937.6944\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 843.8284 - mse: 843.8284 - val_loss: 370.2811 - val_mse: 370.2811\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1547.1882 - mse: 1547.1882 - val_loss: 286.2461 - val_mse: 286.2461\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 822.4205 - mse: 822.4205 - val_loss: 233.8685 - val_mse: 233.8685\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 324.7109 - mse: 324.7109 - val_loss: 292.1852 - val_mse: 292.1852\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 262.5689 - mse: 262.5689 - val_loss: 174.8482 - val_mse: 174.8482\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 531.7090 - mse: 531.7090 - val_loss: 173.1184 - val_mse: 173.1184\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 378.5947 - mse: 378.5947 - val_loss: 147.0321 - val_mse: 147.0320\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 198.8341 - mse: 198.8341 - val_loss: 152.2375 - val_mse: 152.2375\n",
            "mse: 152.23745727539062\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 180 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 3s 22ms/step - loss: 0.1762 - mse: 0.1762 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0380 - val_mse: 0.0380\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.03299613296985626\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 181 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 18786284.0000 - mse: 18786284.0000 - val_loss: 77240.7734 - val_mse: 77240.7734\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 28875.7500 - mse: 28875.7500 - val_loss: 6893.4326 - val_mse: 6893.4326\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 2899.7361 - mse: 2899.7361 - val_loss: 718.9052 - val_mse: 718.9052\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 492.8854 - mse: 492.8854 - val_loss: 240.1783 - val_mse: 240.1783\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 137.3456 - mse: 137.3456 - val_loss: 65.9198 - val_mse: 65.9198\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 65.3944 - mse: 65.3944 - val_loss: 35.3080 - val_mse: 35.3080\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 43.2338 - mse: 43.2338 - val_loss: 61.3001 - val_mse: 61.3001\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 53.2537 - mse: 53.2537 - val_loss: 38.6880 - val_mse: 38.6880\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 40.7178 - mse: 40.7178 - val_loss: 52.0910 - val_mse: 52.0910\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 35.8849 - mse: 35.8849 - val_loss: 36.7159 - val_mse: 36.7159\n",
            "mse: 36.71592330932617\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 182 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 50ms/step - loss: 0.5825 - mse: 0.5825 - val_loss: 0.1402 - val_mse: 0.1402\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0657 - mse: 0.0657 - val_loss: 0.0450 - val_mse: 0.0450\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0362 - val_mse: 0.0362\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.03301125019788742\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 183 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 26ms/step - loss: 157570272.0000 - mse: 157570272.0000 - val_loss: 1090914.3750 - val_mse: 1090914.3750\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 312745.3750 - mse: 312745.3438 - val_loss: 62908.0273 - val_mse: 62908.0273\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 37991.2891 - mse: 37991.2891 - val_loss: 1243.8383 - val_mse: 1243.8383\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 5303.4624 - mse: 5303.4624 - val_loss: 2806.8538 - val_mse: 2806.8538\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 1475.0455 - mse: 1475.0455 - val_loss: 963.0449 - val_mse: 963.0449\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 823.7592 - mse: 823.7592 - val_loss: 691.7336 - val_mse: 691.7336\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 663.2232 - mse: 663.2232 - val_loss: 500.9087 - val_mse: 500.9087\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 299.8439 - mse: 299.8439 - val_loss: 104.8926 - val_mse: 104.8926\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 148.3230 - mse: 148.3230 - val_loss: 54.5662 - val_mse: 54.5662\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 71.7518 - mse: 71.7518 - val_loss: 37.7850 - val_mse: 37.7850\n",
            "mse: 37.78496551513672\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 184 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 3.4544 - mse: 3.4544 - val_loss: 0.0414 - val_mse: 0.0414\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1742 - mse: 0.1742 - val_loss: 0.0356 - val_mse: 0.0356\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0411 - val_mse: 0.0411\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0345 - val_mse: 0.0345\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "mse: 0.0328950397670269\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 185 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 19ms/step - loss: 479695840.0000 - mse: 479695840.0000 - val_loss: 120683.8516 - val_mse: 120683.8516\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 22735.5195 - mse: 22735.5176 - val_loss: 4083.5942 - val_mse: 4083.5942\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 2101.4536 - mse: 2101.4536 - val_loss: 1446.9174 - val_mse: 1446.9174\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 2151.8967 - mse: 2151.8967 - val_loss: 511.7029 - val_mse: 511.7029\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 462.4033 - mse: 462.4034 - val_loss: 251.8762 - val_mse: 251.8762\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 202.8181 - mse: 202.8181 - val_loss: 188.8583 - val_mse: 188.8583\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 200.7699 - mse: 200.7699 - val_loss: 97.9006 - val_mse: 97.9006\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 174.5764 - mse: 174.5764 - val_loss: 63.9557 - val_mse: 63.9557\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 247.8866 - mse: 247.8866 - val_loss: 111.8127 - val_mse: 111.8127\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 751.1476 - mse: 751.1476 - val_loss: 302.7500 - val_mse: 302.7499\n",
            "mse: 302.7499694824219\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 186 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0394 - val_mse: 0.0394\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "mse: 0.022587532177567482\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 187 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 3015683.7500 - mse: 3015683.7500 - val_loss: 1058772.0000 - val_mse: 1058772.0000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 268294.5312 - mse: 268294.5312 - val_loss: 45878.8750 - val_mse: 45878.8750\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 35687.1797 - mse: 35687.1797 - val_loss: 22387.2988 - val_mse: 22387.2988\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 14274.8135 - mse: 14274.8135 - val_loss: 10431.1582 - val_mse: 10431.1582\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 8596.4355 - mse: 8596.4355 - val_loss: 6961.5596 - val_mse: 6961.5596\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 6209.7212 - mse: 6209.7212 - val_loss: 5262.7734 - val_mse: 5262.7734\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 4793.2822 - mse: 4793.2822 - val_loss: 3914.4231 - val_mse: 3914.4231\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 3754.6899 - mse: 3754.6899 - val_loss: 3593.0732 - val_mse: 3593.0732\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 3134.7236 - mse: 3134.7236 - val_loss: 1759.8717 - val_mse: 1759.8717\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2169.0068 - mse: 2169.0068 - val_loss: 1010.8720 - val_mse: 1010.8720\n",
            "mse: 1010.8720092773438\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 188 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 23ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "mse: 0.021361995488405228\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 189 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 5761503.5000 - mse: 5761503.5000 - val_loss: 115299.1641 - val_mse: 115299.1641\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 439080.3125 - mse: 439080.2500 - val_loss: 103504.8203 - val_mse: 103504.8203\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 60808.1016 - mse: 60808.1016 - val_loss: 36797.5469 - val_mse: 36797.5469\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 19867.8340 - mse: 19867.8340 - val_loss: 14197.0986 - val_mse: 14197.0986\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 9637.8867 - mse: 9637.8867 - val_loss: 6440.6333 - val_mse: 6440.6333\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 3254.6614 - mse: 3254.6614 - val_loss: 1877.3989 - val_mse: 1877.3989\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1687.9840 - mse: 1687.9840 - val_loss: 1439.8721 - val_mse: 1439.8721\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1251.1976 - mse: 1251.1976 - val_loss: 1251.6042 - val_mse: 1251.6041\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1058.3956 - mse: 1058.3956 - val_loss: 1331.0280 - val_mse: 1331.0280\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 839.8445 - mse: 839.8445 - val_loss: 976.2696 - val_mse: 976.2696\n",
            "mse: 976.2695922851562\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 190 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 0.0886 - mse: 0.0886 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "mse: 0.020438609644770622\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 191 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 19ms/step - loss: 5953363.5000 - mse: 5953363.5000 - val_loss: 381072.6875 - val_mse: 381072.6875\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 274663.8125 - mse: 274663.8125 - val_loss: 49611.5547 - val_mse: 49611.5547\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 32644.3594 - mse: 32644.3594 - val_loss: 15113.8916 - val_mse: 15113.8916\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 7680.4419 - mse: 7680.4419 - val_loss: 2653.3557 - val_mse: 2653.3557\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2489.4810 - mse: 2489.4810 - val_loss: 1934.5692 - val_mse: 1934.5692\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 1322.2396 - mse: 1322.2396 - val_loss: 939.4850 - val_mse: 939.4850\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 797.2383 - mse: 797.2383 - val_loss: 577.5473 - val_mse: 577.5473\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 469.3898 - mse: 469.3898 - val_loss: 313.0792 - val_mse: 313.0792\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 239.4830 - mse: 239.4830 - val_loss: 190.6831 - val_mse: 190.6831\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 154.1636 - mse: 154.1636 - val_loss: 155.3290 - val_mse: 155.3290\n",
            "mse: 155.32901000976562\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 192 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 21ms/step - loss: 2.2322 - mse: 2.2322 - val_loss: 1.8873 - val_mse: 1.8873\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1.5526 - mse: 1.5526 - val_loss: 1.2875 - val_mse: 1.2875\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1.0360 - mse: 1.0360 - val_loss: 0.8464 - val_mse: 0.8464\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6642 - mse: 0.6642 - val_loss: 0.5373 - val_mse: 0.5373\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4112 - mse: 0.4112 - val_loss: 0.3294 - val_mse: 0.3294\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2462 - mse: 0.2462 - val_loss: 0.1990 - val_mse: 0.1990\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1458 - mse: 0.1458 - val_loss: 0.1213 - val_mse: 0.1213\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0881 - mse: 0.0881 - val_loss: 0.0776 - val_mse: 0.0776\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0545 - val_mse: 0.0545\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0430 - val_mse: 0.0430\n",
            "mse: 0.04296966642141342\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 193 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 19287750.0000 - mse: 19287750.0000 - val_loss: 2215011.7500 - val_mse: 2215011.7500\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 643877.2500 - mse: 643877.2500 - val_loss: 560713.0000 - val_mse: 560713.0000\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 342147.2188 - mse: 342147.2188 - val_loss: 98532.3516 - val_mse: 98532.3516\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 126329.7188 - mse: 126329.7188 - val_loss: 63106.5664 - val_mse: 63106.5664\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 80205.7344 - mse: 80205.7344 - val_loss: 39071.5664 - val_mse: 39071.5664\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 49715.0547 - mse: 49715.0547 - val_loss: 19230.7070 - val_mse: 19230.7070\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 34397.1914 - mse: 34397.1953 - val_loss: 13458.4561 - val_mse: 13458.4561\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 24689.2461 - mse: 24689.2461 - val_loss: 9353.3828 - val_mse: 9353.3828\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 18782.4355 - mse: 18782.4355 - val_loss: 7270.6724 - val_mse: 7270.6724\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13058.8477 - mse: 13058.8477 - val_loss: 5727.1084 - val_mse: 5727.1084\n",
            "mse: 5727.1083984375\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 194 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 1.4386 - mse: 1.4386 - val_loss: 0.7826 - val_mse: 0.7826\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4190 - mse: 0.4190 - val_loss: 0.1760 - val_mse: 0.1760\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.0410 - val_mse: 0.0410\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "mse: 0.030703676864504814\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 195 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 663833.6875 - mse: 663833.6875 - val_loss: 260349.2656 - val_mse: 260349.2656\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 70422.9375 - mse: 70422.9375 - val_loss: 31976.3730 - val_mse: 31976.3730\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 13073.5029 - mse: 13073.5029 - val_loss: 6370.7607 - val_mse: 6370.7607\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 3182.2827 - mse: 3182.2827 - val_loss: 2259.1357 - val_mse: 2259.1360\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 1521.3397 - mse: 1521.3396 - val_loss: 848.3187 - val_mse: 848.3187\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 1027.9403 - mse: 1027.9403 - val_loss: 753.3378 - val_mse: 753.3378\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 834.7338 - mse: 834.7339 - val_loss: 651.1165 - val_mse: 651.1165\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 733.2745 - mse: 733.2745 - val_loss: 488.0247 - val_mse: 488.0247\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 600.1713 - mse: 600.1713 - val_loss: 405.2783 - val_mse: 405.2783\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 542.6636 - mse: 542.6636 - val_loss: 402.3784 - val_mse: 402.3784\n",
            "mse: 402.37835693359375\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 196 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 2s 59ms/step - loss: 0.5432 - mse: 0.5432 - val_loss: 0.0417 - val_mse: 0.0417\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0286 - val_mse: 0.0286\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0273 - val_mse: 0.0273\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "mse: 0.025731200352311134\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 197 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 21ms/step - loss: 221601.4062 - mse: 221601.4062 - val_loss: 27975.3672 - val_mse: 27975.3672\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 11984.0664 - mse: 11984.0664 - val_loss: 4174.1470 - val_mse: 4174.1470\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2100.6768 - mse: 2100.6768 - val_loss: 1184.4945 - val_mse: 1184.4945\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 810.6943 - mse: 810.6943 - val_loss: 724.2924 - val_mse: 724.2924\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 675.0610 - mse: 675.0610 - val_loss: 612.2436 - val_mse: 612.2436\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 700.2753 - mse: 700.2753 - val_loss: 804.5767 - val_mse: 804.5767\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 572.1386 - mse: 572.1386 - val_loss: 507.2238 - val_mse: 507.2238\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 491.6537 - mse: 491.6537 - val_loss: 635.3925 - val_mse: 635.3925\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 471.7300 - mse: 471.7300 - val_loss: 429.7061 - val_mse: 429.7061\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 426.2976 - mse: 426.2976 - val_loss: 377.0348 - val_mse: 377.0348\n",
            "mse: 377.0348205566406\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 198 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 31ms/step - loss: 0.4961 - mse: 0.4961 - val_loss: 0.2557 - val_mse: 0.2557\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0420 - val_mse: 0.0420\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0471 - val_mse: 0.0471\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.032987695187330246\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 199 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 28ms/step - loss: 43136928.0000 - mse: 43136920.0000 - val_loss: 66576.2188 - val_mse: 66576.2188\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1189182.7500 - mse: 1189182.7500 - val_loss: 656374.2500 - val_mse: 656374.2500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 207258.3125 - mse: 207258.3281 - val_loss: 24328.6777 - val_mse: 24328.6777\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 49863.6797 - mse: 49863.6797 - val_loss: 47370.2344 - val_mse: 47370.2344\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 21421.7012 - mse: 21421.7012 - val_loss: 791.0717 - val_mse: 791.0717\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6434.6577 - mse: 6434.6572 - val_loss: 7331.8545 - val_mse: 7331.8545\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3067.6584 - mse: 3067.6584 - val_loss: 1125.9701 - val_mse: 1125.9701\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1373.6707 - mse: 1373.6707 - val_loss: 407.9816 - val_mse: 407.9816\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 698.8264 - mse: 698.8264 - val_loss: 432.2245 - val_mse: 432.2245\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 476.2928 - mse: 476.2928 - val_loss: 345.6905 - val_mse: 345.6905\n",
            "mse: 345.6905212402344\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 200 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 36ms/step - loss: 1.5797 - mse: 1.5797 - val_loss: 0.3262 - val_mse: 0.3262\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2623 - mse: 0.2623 - val_loss: 0.2178 - val_mse: 0.2178\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 0.0909 - val_mse: 0.0909\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0627 - val_mse: 0.0627\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0385 - val_mse: 0.0385\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0357 - val_mse: 0.0357\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.03304543346166611\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 201 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 40ms/step - loss: 241347360.0000 - mse: 241347360.0000 - val_loss: 2914231.0000 - val_mse: 2914231.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 693350.5625 - mse: 693350.5625 - val_loss: 22199.5684 - val_mse: 22199.5684\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 37720.2891 - mse: 37720.2891 - val_loss: 5033.5327 - val_mse: 5033.5327\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2595.5579 - mse: 2595.5579 - val_loss: 1446.5839 - val_mse: 1446.5839\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1140.5311 - mse: 1140.5311 - val_loss: 1255.7877 - val_mse: 1255.7877\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 823.8527 - mse: 823.8526 - val_loss: 579.0837 - val_mse: 579.0837\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 513.4230 - mse: 513.4230 - val_loss: 285.4781 - val_mse: 285.4781\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 247.7237 - mse: 247.7237 - val_loss: 184.2391 - val_mse: 184.2391\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 179.2198 - mse: 179.2198 - val_loss: 141.0477 - val_mse: 141.0477\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 135.0602 - mse: 135.0602 - val_loss: 102.1827 - val_mse: 102.1827\n",
            "mse: 102.18272399902344\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 202 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 33ms/step - loss: 6.4282 - mse: 6.4282 - val_loss: 0.0562 - val_mse: 0.0562\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7554 - mse: 0.7554 - val_loss: 0.0515 - val_mse: 0.0515\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2641 - mse: 0.2641 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1088 - mse: 0.1088 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0345 - val_mse: 0.0345\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "mse: 0.03338099271059036\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 203 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 29ms/step - loss: 741668480.0000 - mse: 741668480.0000 - val_loss: 6671020.0000 - val_mse: 6671020.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1649607.6250 - mse: 1649607.6250 - val_loss: 168772.4219 - val_mse: 168772.4219\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 138974.2344 - mse: 138974.2344 - val_loss: 85522.0312 - val_mse: 85522.0312\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 66642.5703 - mse: 66642.5703 - val_loss: 50938.4102 - val_mse: 50938.4102\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 33570.6055 - mse: 33570.6055 - val_loss: 1806.4969 - val_mse: 1806.4969\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 8974.1602 - mse: 8974.1602 - val_loss: 7303.6348 - val_mse: 7303.6348\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3192.3650 - mse: 3192.3650 - val_loss: 2330.8254 - val_mse: 2330.8254\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 975.6807 - mse: 975.6807 - val_loss: 876.1585 - val_mse: 876.1585\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1017.9806 - mse: 1017.9805 - val_loss: 295.9656 - val_mse: 295.9656\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 292.4044 - mse: 292.4044 - val_loss: 26.6013 - val_mse: 26.6013\n",
            "mse: 26.6013126373291\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 204 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 24ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "mse: 0.02367883175611496\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 205 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 17063818.0000 - mse: 17063818.0000 - val_loss: 4545159.5000 - val_mse: 4545159.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2484435.0000 - mse: 2484435.2500 - val_loss: 1610837.3750 - val_mse: 1610837.3750\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 802927.8750 - mse: 802927.8750 - val_loss: 602741.2500 - val_mse: 602741.2500\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 278969.4375 - mse: 278969.4375 - val_loss: 116049.4609 - val_mse: 116049.4609\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 121633.1719 - mse: 121633.1719 - val_loss: 53586.2539 - val_mse: 53586.2539\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 71572.6094 - mse: 71572.6094 - val_loss: 49613.2656 - val_mse: 49613.2656\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 43743.6016 - mse: 43743.6016 - val_loss: 26344.8984 - val_mse: 26344.8984\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 19416.1738 - mse: 19416.1738 - val_loss: 14036.1621 - val_mse: 14036.1621\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 12965.9004 - mse: 12965.9004 - val_loss: 11588.7842 - val_mse: 11588.7842\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 9555.4834 - mse: 9555.4834 - val_loss: 8736.9277 - val_mse: 8736.9277\n",
            "mse: 8736.927734375\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 206 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "mse: 0.022215958684682846\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 207 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 42ms/step - loss: 3375198.7500 - mse: 3375198.5000 - val_loss: 4839.2607 - val_mse: 4839.2607\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 526182.5000 - mse: 526182.5000 - val_loss: 289232.5625 - val_mse: 289232.5625\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 170896.2969 - mse: 170896.2969 - val_loss: 216018.4062 - val_mse: 216018.4062\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 75979.6406 - mse: 75979.6406 - val_loss: 45362.0156 - val_mse: 45362.0156\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 27038.3457 - mse: 27038.3457 - val_loss: 11220.7832 - val_mse: 11220.7832\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 11726.7490 - mse: 11726.7490 - val_loss: 4540.5796 - val_mse: 4540.5796\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 5105.7671 - mse: 5105.7671 - val_loss: 2639.1309 - val_mse: 2639.1309\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 2455.5818 - mse: 2455.5818 - val_loss: 1645.8062 - val_mse: 1645.8062\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1241.8925 - mse: 1241.8925 - val_loss: 817.9871 - val_mse: 817.9871\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 822.2885 - mse: 822.2885 - val_loss: 668.6006 - val_mse: 668.6006\n",
            "mse: 668.6005859375\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 208 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 36ms/step - loss: 0.1043 - mse: 0.1043 - val_loss: 0.0742 - val_mse: 0.0742\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0382 - val_mse: 0.0382\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "mse: 0.020688068121671677\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 209 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 31ms/step - loss: 9744668.0000 - mse: 9744667.0000 - val_loss: 4573896.5000 - val_mse: 4573896.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1428987.7500 - mse: 1428987.7500 - val_loss: 1159619.1250 - val_mse: 1159619.0000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 431581.3125 - mse: 431581.3125 - val_loss: 262738.3125 - val_mse: 262738.3125\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100155.1719 - mse: 100155.1719 - val_loss: 43948.4648 - val_mse: 43948.4648\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 33787.5586 - mse: 33787.5586 - val_loss: 9440.6387 - val_mse: 9440.6387\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 12560.3994 - mse: 12560.3994 - val_loss: 7509.7915 - val_mse: 7509.7915\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3146.5635 - mse: 3146.5635 - val_loss: 2086.7456 - val_mse: 2086.7456\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1300.4067 - mse: 1300.4067 - val_loss: 1187.4841 - val_mse: 1187.4841\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 726.2429 - mse: 726.2429 - val_loss: 705.8983 - val_mse: 705.8983\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 505.8892 - mse: 505.8892 - val_loss: 394.5572 - val_mse: 394.5572\n",
            "mse: 394.5571594238281\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 210 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 0.1027 - mse: 0.1027 - val_loss: 0.0651 - val_mse: 0.0651\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0370 - val_mse: 0.0370\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "mse: 0.0313805527985096\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 211 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 28ms/step - loss: 9942212.0000 - mse: 9942212.0000 - val_loss: 3640688.7500 - val_mse: 3640688.7500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1613040.6250 - mse: 1613040.6250 - val_loss: 60786.6328 - val_mse: 60786.6328\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 127613.0156 - mse: 127613.0156 - val_loss: 341791.6875 - val_mse: 341791.6875\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 301800.4688 - mse: 301800.4688 - val_loss: 151720.4844 - val_mse: 151720.4844\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 58373.0469 - mse: 58373.0469 - val_loss: 9228.8916 - val_mse: 9228.8916\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 24997.1543 - mse: 24997.1543 - val_loss: 23248.2090 - val_mse: 23248.2090\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 24921.2676 - mse: 24921.2676 - val_loss: 8613.2178 - val_mse: 8613.2178\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 11353.5107 - mse: 11353.5107 - val_loss: 8780.3438 - val_mse: 8780.3438\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10610.0166 - mse: 10610.0176 - val_loss: 7286.9810 - val_mse: 7286.9810\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7930.9570 - mse: 7930.9570 - val_loss: 4495.8979 - val_mse: 4495.8979\n",
            "mse: 4495.89794921875\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 212 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 35ms/step - loss: 0.6785 - mse: 0.6785 - val_loss: 0.4376 - val_mse: 0.4376\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2738 - mse: 0.2738 - val_loss: 0.1497 - val_mse: 0.1497\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0824 - mse: 0.0824 - val_loss: 0.0473 - val_mse: 0.0473\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "mse: 0.033201664686203\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 213 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 37ms/step - loss: 173424.3906 - mse: 173424.3906 - val_loss: 81760.4609 - val_mse: 81760.4688\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 44318.1836 - mse: 44318.1836 - val_loss: 35796.0078 - val_mse: 35796.0117\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 21478.5000 - mse: 21478.5000 - val_loss: 5359.3926 - val_mse: 5359.3926\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 9300.2031 - mse: 9300.2031 - val_loss: 5560.2729 - val_mse: 5560.2729\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5967.4595 - mse: 5967.4595 - val_loss: 5339.4507 - val_mse: 5339.4507\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5009.9902 - mse: 5009.9902 - val_loss: 4308.0791 - val_mse: 4308.0791\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3915.4658 - mse: 3915.4661 - val_loss: 3420.8503 - val_mse: 3420.8503\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3153.1030 - mse: 3153.1030 - val_loss: 2708.8186 - val_mse: 2708.8186\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2533.4392 - mse: 2533.4392 - val_loss: 2335.8723 - val_mse: 2335.8723\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2160.3252 - mse: 2160.3252 - val_loss: 2103.5588 - val_mse: 2103.5588\n",
            "mse: 2103.558837890625\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 214 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 35ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0268 - val_mse: 0.0268\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "mse: 0.023500243201851845\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 215 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 33ms/step - loss: 3654318.5000 - mse: 3654318.5000 - val_loss: 1154620.1250 - val_mse: 1154620.1250\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 577216.3750 - mse: 577216.3750 - val_loss: 510498.6875 - val_mse: 510498.6875\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 210695.5625 - mse: 210695.5625 - val_loss: 213930.4375 - val_mse: 213930.4375\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 83222.5938 - mse: 83222.5938 - val_loss: 75134.1875 - val_mse: 75134.1875\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 32106.9238 - mse: 32106.9238 - val_loss: 15233.2090 - val_mse: 15233.2090\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 10334.1904 - mse: 10334.1904 - val_loss: 1589.8085 - val_mse: 1589.8085\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3988.9678 - mse: 3988.9678 - val_loss: 744.1141 - val_mse: 744.1141\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 2082.4690 - mse: 2082.4690 - val_loss: 1566.6357 - val_mse: 1566.6357\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1385.5979 - mse: 1385.5979 - val_loss: 942.6292 - val_mse: 942.6292\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 863.9374 - mse: 863.9374 - val_loss: 409.7692 - val_mse: 409.7692\n",
            "mse: 409.7691955566406\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 216 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0355 - val_mse: 0.0355\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0355 - val_mse: 0.0355\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0353 - val_mse: 0.0353\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0393 - val_mse: 0.0393\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0372 - val_mse: 0.0372\n",
            "mse: 0.03724163770675659\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 217 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 7488252.0000 - mse: 7488252.0000 - val_loss: 346.6164 - val_mse: 346.6164\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 5001.4146 - mse: 5001.4146 - val_loss: 533.1251 - val_mse: 533.1251\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1381.2546 - mse: 1381.2546 - val_loss: 217.9712 - val_mse: 217.9712\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 321.0080 - mse: 321.0080 - val_loss: 132.4872 - val_mse: 132.4872\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 238.3499 - mse: 238.3499 - val_loss: 550.7902 - val_mse: 550.7902\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 230.4027 - mse: 230.4027 - val_loss: 193.1711 - val_mse: 193.1711\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 166.8676 - mse: 166.8676 - val_loss: 55.9199 - val_mse: 55.9199\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 150.2793 - mse: 150.2793 - val_loss: 39.8208 - val_mse: 39.8208\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 79.6737 - mse: 79.6737 - val_loss: 85.9829 - val_mse: 85.9829\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 139.0770 - mse: 139.0770 - val_loss: 41.3234 - val_mse: 41.3234\n",
            "mse: 41.32339096069336\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 218 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0387 - val_mse: 0.0387\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0396 - val_mse: 0.0396\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0370 - val_mse: 0.0370\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0368 - val_mse: 0.0368\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0363 - val_mse: 0.0363\n",
            "mse: 0.03631877899169922\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 219 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 14865124.0000 - mse: 14865124.0000 - val_loss: 850.6841 - val_mse: 850.6841\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 720.5955 - mse: 720.5955 - val_loss: 167.4486 - val_mse: 167.4486\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 140.3891 - mse: 140.3891 - val_loss: 60.2027 - val_mse: 60.2027\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 130.5514 - mse: 130.5514 - val_loss: 121.1998 - val_mse: 121.1998\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 90.5039 - mse: 90.5039 - val_loss: 90.0453 - val_mse: 90.0453\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 84.9617 - mse: 84.9617 - val_loss: 268.5325 - val_mse: 268.5325\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 94.3313 - mse: 94.3313 - val_loss: 22.8115 - val_mse: 22.8115\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 37.7745 - mse: 37.7745 - val_loss: 44.5651 - val_mse: 44.5651\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 34.5665 - mse: 34.5665 - val_loss: 142.1937 - val_mse: 142.1937\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 57.1975 - mse: 57.1975 - val_loss: 29.7268 - val_mse: 29.7268\n",
            "mse: 29.726808547973633\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 220 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 12ms/step - loss: 0.6748 - mse: 0.6748 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0389 - val_mse: 0.0389\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0353 - val_mse: 0.0353\n",
            "mse: 0.03531121462583542\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 221 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 73740664.0000 - mse: 73740664.0000 - val_loss: 932.4243 - val_mse: 932.4243\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3484.1873 - mse: 3484.1873 - val_loss: 4433.6089 - val_mse: 4433.6089\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 5227.5347 - mse: 5227.5347 - val_loss: 141.2479 - val_mse: 141.2479\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 547.3765 - mse: 547.3765 - val_loss: 612.9386 - val_mse: 612.9386\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 50354.7812 - mse: 50354.7812 - val_loss: 1768.1991 - val_mse: 1768.1991\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 6388.9790 - mse: 6388.9790 - val_loss: 146.1764 - val_mse: 146.1764\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 225.2835 - mse: 225.2835 - val_loss: 4.1303 - val_mse: 4.1303\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 213.6368 - mse: 213.6368 - val_loss: 5.8709 - val_mse: 5.8709\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 4.9879 - mse: 4.9879 - val_loss: 3.0990 - val_mse: 3.0990\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3.0359 - mse: 3.0359 - val_loss: 2.0185 - val_mse: 2.0185\n",
            "mse: 2.0184717178344727\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 222 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0365 - val_mse: 0.0365\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0273 - val_mse: 0.0273\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0278 - val_mse: 0.0278\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0293 - val_mse: 0.0293\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "mse: 0.026407571509480476\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 223 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 2526143.2500 - mse: 2526143.2500 - val_loss: 14843.9258 - val_mse: 14843.9258\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 13246.0713 - mse: 13246.0713 - val_loss: 3479.5786 - val_mse: 3479.5786\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 10453.5039 - mse: 10453.5039 - val_loss: 462.7549 - val_mse: 462.7549\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 4149.4312 - mse: 4149.4312 - val_loss: 1170.4862 - val_mse: 1170.4862\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 8635.9297 - mse: 8635.9297 - val_loss: 388.0969 - val_mse: 388.0969\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2156.2415 - mse: 2156.2415 - val_loss: 105.8161 - val_mse: 105.8161\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 718.8989 - mse: 718.8989 - val_loss: 145.6158 - val_mse: 145.6158\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 715.8183 - mse: 715.8183 - val_loss: 130.9538 - val_mse: 130.9538\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 515.0914 - mse: 515.0914 - val_loss: 111.9666 - val_mse: 111.9666\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 474.1409 - mse: 474.1409 - val_loss: 148.7963 - val_mse: 148.7963\n",
            "mse: 148.7962646484375\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 224 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 7ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0368 - val_mse: 0.0368\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0373 - val_mse: 0.0373\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "mse: 0.030899612233042717\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 225 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 741240.2500 - mse: 741240.2500 - val_loss: 1382.3690 - val_mse: 1382.3690\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1224.1592 - mse: 1224.1592 - val_loss: 451.7285 - val_mse: 451.7285\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 3313.5259 - mse: 3313.5259 - val_loss: 2544.3237 - val_mse: 2544.3237\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 29229.4004 - mse: 29229.4004 - val_loss: 7595.2173 - val_mse: 7595.2173\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2662.5142 - mse: 2662.5142 - val_loss: 1206.8586 - val_mse: 1206.8586\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 519.4189 - mse: 519.4189 - val_loss: 332.7199 - val_mse: 332.7199\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 308.2911 - mse: 308.2911 - val_loss: 101.8078 - val_mse: 101.8078\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 148.4208 - mse: 148.4208 - val_loss: 101.3817 - val_mse: 101.3817\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 157.5493 - mse: 157.5493 - val_loss: 106.3032 - val_mse: 106.3032\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 238.9722 - mse: 238.9722 - val_loss: 829.8986 - val_mse: 829.8986\n",
            "mse: 829.8985595703125\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 226 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0380 - val_mse: 0.0380\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "mse: 0.03213263303041458\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 227 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 1560886.8750 - mse: 1560886.8750 - val_loss: 4569.8589 - val_mse: 4569.8594\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 20929.9336 - mse: 20929.9336 - val_loss: 15686.2393 - val_mse: 15686.2402\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3517.1062 - mse: 3517.1062 - val_loss: 369.2197 - val_mse: 369.2197\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 145.4442 - mse: 145.4442 - val_loss: 67.8327 - val_mse: 67.8327\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 98.4876 - mse: 98.4876 - val_loss: 67.6781 - val_mse: 67.6781\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 130.7188 - mse: 130.7188 - val_loss: 38.1565 - val_mse: 38.1565\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 229.7290 - mse: 229.7290 - val_loss: 414.8184 - val_mse: 414.8184\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 239.0463 - mse: 239.0463 - val_loss: 107.5096 - val_mse: 107.5096\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 557.2320 - mse: 557.2320 - val_loss: 33.7516 - val_mse: 33.7516\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 522.7264 - mse: 522.7264 - val_loss: 224.6869 - val_mse: 224.6869\n",
            "mse: 224.6868896484375\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 228 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0301 - val_mse: 0.0301\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "mse: 0.02150156907737255\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 229 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 17339904.0000 - mse: 17339904.0000 - val_loss: 76268.2344 - val_mse: 76268.2344\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 63028.1016 - mse: 63028.1016 - val_loss: 29589.5742 - val_mse: 29589.5742\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 31856.9023 - mse: 31856.9023 - val_loss: 12621.5459 - val_mse: 12621.5459\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 14669.2041 - mse: 14669.2041 - val_loss: 5825.6353 - val_mse: 5825.6353\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 7892.4009 - mse: 7892.4019 - val_loss: 3289.4927 - val_mse: 3289.4927\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 4503.7749 - mse: 4503.7749 - val_loss: 2770.0779 - val_mse: 2770.0779\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 3303.5090 - mse: 3303.5090 - val_loss: 2025.6982 - val_mse: 2025.6982\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2556.1831 - mse: 2556.1831 - val_loss: 1735.0651 - val_mse: 1735.0651\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2064.1396 - mse: 2064.1396 - val_loss: 1435.2563 - val_mse: 1435.2563\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 1757.7722 - mse: 1757.7722 - val_loss: 1251.7202 - val_mse: 1251.7202\n",
            "mse: 1251.72021484375\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 230 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2622 - mse: 0.2622 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "mse: 0.022903116419911385\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 231 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 5ms/step - loss: 390348.1562 - mse: 390348.1562 - val_loss: 14428.4453 - val_mse: 14428.4453\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 9888.9336 - mse: 9888.9336 - val_loss: 5491.8916 - val_mse: 5491.8916\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 5158.9634 - mse: 5158.9634 - val_loss: 3370.1843 - val_mse: 3370.1843\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1643.7788 - mse: 1643.7788 - val_loss: 1602.3997 - val_mse: 1602.3997\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1219.0491 - mse: 1219.0491 - val_loss: 2469.0437 - val_mse: 2469.0437\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 905.5274 - mse: 905.5274 - val_loss: 1068.3738 - val_mse: 1068.3738\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 883.8228 - mse: 883.8228 - val_loss: 884.1895 - val_mse: 884.1895\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 682.7953 - mse: 682.7953 - val_loss: 755.3208 - val_mse: 755.3209\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 1218.0322 - mse: 1218.0322 - val_loss: 690.4144 - val_mse: 690.4144\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 823.9163 - mse: 823.9163 - val_loss: 764.7032 - val_mse: 764.7032\n",
            "mse: 764.7032470703125\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 232 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "mse: 0.020460238680243492\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 233 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 10ms/step - loss: 302575.4375 - mse: 302575.4375 - val_loss: 397.0163 - val_mse: 397.0162\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1530.1019 - mse: 1530.1019 - val_loss: 180.9697 - val_mse: 180.9697\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 659.6284 - mse: 659.6284 - val_loss: 202.8306 - val_mse: 202.8306\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 215.6700 - mse: 215.6700 - val_loss: 108.9998 - val_mse: 108.9998\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 242.2875 - mse: 242.2876 - val_loss: 271.9995 - val_mse: 271.9995\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2928.7126 - mse: 2928.7126 - val_loss: 264.1017 - val_mse: 264.1017\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2925.2859 - mse: 2925.2859 - val_loss: 104.9678 - val_mse: 104.9678\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 235.0245 - mse: 235.0245 - val_loss: 64.7572 - val_mse: 64.7572\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 108.6851 - mse: 108.6851 - val_loss: 63.4123 - val_mse: 63.4123\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 164.1026 - mse: 164.1026 - val_loss: 48.2520 - val_mse: 48.2520\n",
            "mse: 48.25199890136719\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 234 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 0.7136 - mse: 0.7136 - val_loss: 0.0476 - val_mse: 0.0476\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "mse: 0.03256667032837868\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 235 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 16809458.0000 - mse: 16809458.0000 - val_loss: 74137.7891 - val_mse: 74137.7891\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 34204.8477 - mse: 34204.8438 - val_loss: 3785.6667 - val_mse: 3785.6667\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 8248.3438 - mse: 8248.3447 - val_loss: 6337.2827 - val_mse: 6337.2827\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1837.2876 - mse: 1837.2876 - val_loss: 887.8995 - val_mse: 887.8995\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 485.7126 - mse: 485.7126 - val_loss: 250.4356 - val_mse: 250.4356\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 198.5458 - mse: 198.5458 - val_loss: 146.2426 - val_mse: 146.2426\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 90.0960 - mse: 90.0960 - val_loss: 79.9652 - val_mse: 79.9652\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 55.2502 - mse: 55.2502 - val_loss: 50.1935 - val_mse: 50.1935\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 43.5558 - mse: 43.5558 - val_loss: 34.6861 - val_mse: 34.6861\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 32.2072 - mse: 32.2072 - val_loss: 26.4225 - val_mse: 26.4225\n",
            "mse: 26.422508239746094\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 236 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.5301 - mse: 0.5301 - val_loss: 0.1747 - val_mse: 0.1747\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0345 - val_mse: 0.0345\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.03300245851278305\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 237 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 19ms/step - loss: 53317320.0000 - mse: 53317320.0000 - val_loss: 8576.9746 - val_mse: 8576.9756\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 24464.8223 - mse: 24464.8203 - val_loss: 640.7241 - val_mse: 640.7241\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 3096.1660 - mse: 3096.1660 - val_loss: 1199.7080 - val_mse: 1199.7080\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 356.7831 - mse: 356.7831 - val_loss: 223.2604 - val_mse: 223.2604\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 143.8059 - mse: 143.8059 - val_loss: 37.1991 - val_mse: 37.1991\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 59.1413 - mse: 59.1413 - val_loss: 44.4363 - val_mse: 44.4363\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 43.5234 - mse: 43.5234 - val_loss: 47.6591 - val_mse: 47.6591\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 29.5062 - mse: 29.5062 - val_loss: 20.2403 - val_mse: 20.2403\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 21.1748 - mse: 21.1748 - val_loss: 16.8525 - val_mse: 16.8525\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 17.7508 - mse: 17.7508 - val_loss: 17.8896 - val_mse: 17.8896\n",
            "mse: 17.88957405090332\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 238 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 2s 23ms/step - loss: 3.1506 - mse: 3.1506 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1544 - mse: 0.1544 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0424 - val_mse: 0.0424\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "mse: 0.032855164259672165\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 239 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 386406752.0000 - mse: 386406752.0000 - val_loss: 247820.9375 - val_mse: 247820.9375\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 50150.9023 - mse: 50150.9023 - val_loss: 8299.4961 - val_mse: 8299.4961\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 4082.4937 - mse: 4082.4937 - val_loss: 1668.8685 - val_mse: 1668.8685\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1119.3557 - mse: 1119.3558 - val_loss: 370.0567 - val_mse: 370.0567\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 448.2891 - mse: 448.2891 - val_loss: 528.2908 - val_mse: 528.2908\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 387.3945 - mse: 387.3945 - val_loss: 234.6633 - val_mse: 234.6633\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 230.4081 - mse: 230.4081 - val_loss: 90.8188 - val_mse: 90.8188\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 116.0490 - mse: 116.0490 - val_loss: 73.0508 - val_mse: 73.0508\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 95.8138 - mse: 95.8138 - val_loss: 73.3054 - val_mse: 73.3054\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 84.1940 - mse: 84.1940 - val_loss: 46.0419 - val_mse: 46.0419\n",
            "mse: 46.04191589355469\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 240 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0408 - val_mse: 0.0408\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0301 - val_mse: 0.0301\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0267 - val_mse: 0.0267\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0279 - val_mse: 0.0279\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "mse: 0.028830960392951965\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 241 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 25ms/step - loss: 969578.5000 - mse: 969578.5000 - val_loss: 240822.3750 - val_mse: 240822.3750\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 70250.2344 - mse: 70250.2344 - val_loss: 5374.1118 - val_mse: 5374.1118\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 10848.6982 - mse: 10848.6982 - val_loss: 4533.1406 - val_mse: 4533.1406\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 3042.8137 - mse: 3042.8137 - val_loss: 1844.5624 - val_mse: 1844.5624\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1818.6962 - mse: 1818.6962 - val_loss: 1194.8798 - val_mse: 1194.8798\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1192.3536 - mse: 1192.3536 - val_loss: 999.5522 - val_mse: 999.5522\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 921.4798 - mse: 921.4798 - val_loss: 729.0687 - val_mse: 729.0687\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 686.8931 - mse: 686.8931 - val_loss: 536.5351 - val_mse: 536.5351\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 564.6940 - mse: 564.6940 - val_loss: 513.3566 - val_mse: 513.3566\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 499.4231 - mse: 499.4231 - val_loss: 372.9520 - val_mse: 372.9520\n",
            "mse: 372.95196533203125\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 242 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 0.1888 - mse: 0.1888 - val_loss: 0.0869 - val_mse: 0.0869\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0407 - val_mse: 0.0407\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "mse: 0.023057667538523674\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 243 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 3487826.5000 - mse: 3487826.5000 - val_loss: 224215.9844 - val_mse: 224215.9844\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 216522.8594 - mse: 216522.8438 - val_loss: 71376.9062 - val_mse: 71376.9062\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 39633.2383 - mse: 39633.2383 - val_loss: 20101.1816 - val_mse: 20101.1816\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 10455.1836 - mse: 10455.1836 - val_loss: 5790.2573 - val_mse: 5790.2573\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 11294.4277 - mse: 11294.4277 - val_loss: 2940.3936 - val_mse: 2940.3936\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 7688.0361 - mse: 7688.0356 - val_loss: 1571.3590 - val_mse: 1571.3590\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 10420.9658 - mse: 10420.9648 - val_loss: 573.8983 - val_mse: 573.8983\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 2404.8301 - mse: 2404.8301 - val_loss: 1431.6090 - val_mse: 1431.6090\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1863.6158 - mse: 1863.6158 - val_loss: 870.5143 - val_mse: 870.5143\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 3289.3384 - mse: 3289.3384 - val_loss: 458.3942 - val_mse: 458.3942\n",
            "mse: 458.3941955566406\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 244 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "mse: 0.0277208611369133\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 245 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 7229635.0000 - mse: 7229635.0000 - val_loss: 1350558.1250 - val_mse: 1350558.1250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 399345.0312 - mse: 399345.0312 - val_loss: 53260.5781 - val_mse: 53260.5781\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 29564.5137 - mse: 29564.5137 - val_loss: 11839.5410 - val_mse: 11839.5410\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 5101.7476 - mse: 5101.7476 - val_loss: 1750.0072 - val_mse: 1750.0072\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 899.1504 - mse: 899.1504 - val_loss: 466.8490 - val_mse: 466.8490\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 216.5108 - mse: 216.5108 - val_loss: 180.6929 - val_mse: 180.6929\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 114.4427 - mse: 114.4427 - val_loss: 139.9447 - val_mse: 139.9447\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 88.5642 - mse: 88.5642 - val_loss: 133.1871 - val_mse: 133.1871\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 72.0153 - mse: 72.0153 - val_loss: 107.2237 - val_mse: 107.2237\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 60.9949 - mse: 60.9949 - val_loss: 101.1336 - val_mse: 101.1336\n",
            "mse: 101.13358306884766\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 246 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 1.1145 - mse: 1.1145 - val_loss: 0.8774 - val_mse: 0.8774\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6632 - mse: 0.6632 - val_loss: 0.5034 - val_mse: 0.5034\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3643 - mse: 0.3643 - val_loss: 0.2710 - val_mse: 0.2710\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1885 - mse: 0.1885 - val_loss: 0.1422 - val_mse: 0.1422\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 0.0778 - val_mse: 0.0778\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0494 - val_mse: 0.0494\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0383 - val_mse: 0.0383\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "mse: 0.03277425840497017\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 247 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 6485904.5000 - mse: 6485905.0000 - val_loss: 60367.8828 - val_mse: 60367.8828\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 376890.8750 - mse: 376890.8750 - val_loss: 91697.3125 - val_mse: 91697.3125\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 66103.8516 - mse: 66103.8516 - val_loss: 66763.9297 - val_mse: 66763.9297\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 47064.2812 - mse: 47064.2812 - val_loss: 34626.2969 - val_mse: 34626.2969\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 40496.3789 - mse: 40496.3789 - val_loss: 33471.4570 - val_mse: 33471.4570\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 36725.7852 - mse: 36725.7852 - val_loss: 30389.9082 - val_mse: 30389.9082\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 34416.6758 - mse: 34416.6758 - val_loss: 28576.9414 - val_mse: 28576.9414\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 32160.3086 - mse: 32160.3086 - val_loss: 26948.7910 - val_mse: 26948.7910\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 30162.5293 - mse: 30162.5293 - val_loss: 25445.4199 - val_mse: 25445.4199\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 28245.0762 - mse: 28245.0762 - val_loss: 24055.8242 - val_mse: 24055.8242\n",
            "mse: 24055.82421875\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 248 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 0.5348 - mse: 0.5348 - val_loss: 0.1817 - val_mse: 0.1817\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0705 - mse: 0.0705 - val_loss: 0.0375 - val_mse: 0.0375\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0379 - val_mse: 0.0379\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0366 - val_mse: 0.0366\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0360 - val_mse: 0.0360\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "mse: 0.03242034837603569\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 249 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 92002984.0000 - mse: 92002984.0000 - val_loss: 21492410.0000 - val_mse: 21492410.0000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 5708524.5000 - mse: 5708524.5000 - val_loss: 416162.9062 - val_mse: 416162.9062\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 821073.5625 - mse: 821073.5625 - val_loss: 317862.5625 - val_mse: 317862.5625\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 180757.5781 - mse: 180757.5781 - val_loss: 184404.3906 - val_mse: 184404.3906\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 130788.8672 - mse: 130788.8672 - val_loss: 120458.6406 - val_mse: 120458.6406\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 104627.3594 - mse: 104627.3594 - val_loss: 105593.3125 - val_mse: 105593.3125\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 90550.3984 - mse: 90550.3984 - val_loss: 96472.5547 - val_mse: 96472.5547\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 79544.3984 - mse: 79544.3828 - val_loss: 83147.3672 - val_mse: 83147.3672\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 69122.4141 - mse: 69122.4141 - val_loss: 72435.1562 - val_mse: 72435.1562\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 59112.1875 - mse: 59112.1914 - val_loss: 58492.1406 - val_mse: 58492.1328\n",
            "mse: 58492.140625\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 250 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 0.5765 - mse: 0.5765 - val_loss: 0.0387 - val_mse: 0.0387\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "mse: 0.024016693234443665\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 251 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 2530404.5000 - mse: 2530404.5000 - val_loss: 255401.5000 - val_mse: 255401.5000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 224821.2031 - mse: 224821.2031 - val_loss: 41228.5469 - val_mse: 41228.5469\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 23829.7773 - mse: 23829.7773 - val_loss: 12270.5566 - val_mse: 12270.5566\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 5100.8257 - mse: 5100.8257 - val_loss: 1650.3379 - val_mse: 1650.3379\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 1675.9835 - mse: 1675.9835 - val_loss: 793.2585 - val_mse: 793.2585\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 919.5896 - mse: 919.5896 - val_loss: 604.8941 - val_mse: 604.8941\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 713.9913 - mse: 713.9913 - val_loss: 456.8011 - val_mse: 456.8011\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 555.1003 - mse: 555.1003 - val_loss: 396.8972 - val_mse: 396.8972\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 562.7496 - mse: 562.7496 - val_loss: 353.0467 - val_mse: 353.0467\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 434.0818 - mse: 434.0818 - val_loss: 304.5390 - val_mse: 304.5390\n",
            "mse: 304.53900146484375\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 252 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 34ms/step - loss: 0.2449 - mse: 0.2449 - val_loss: 0.0410 - val_mse: 0.0410\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0681 - val_mse: 0.0681\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0351 - val_mse: 0.0351\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0369 - val_mse: 0.0369\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "mse: 0.03270544484257698\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 253 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 30ms/step - loss: 14311988.0000 - mse: 14311988.0000 - val_loss: 722835.6250 - val_mse: 722835.6250\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 219480.9688 - mse: 219480.9688 - val_loss: 4088.0466 - val_mse: 4088.0466\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 31797.1641 - mse: 31797.1641 - val_loss: 29753.5391 - val_mse: 29753.5391\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 13363.6855 - mse: 13363.6855 - val_loss: 1327.7443 - val_mse: 1327.7443\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 4430.4043 - mse: 4430.4043 - val_loss: 5652.8110 - val_mse: 5652.8110\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2211.1379 - mse: 2211.1377 - val_loss: 921.1241 - val_mse: 921.1241\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 925.8367 - mse: 925.8367 - val_loss: 436.3171 - val_mse: 436.3171\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 475.0789 - mse: 475.0789 - val_loss: 436.2021 - val_mse: 436.2021\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 301.8575 - mse: 301.8575 - val_loss: 241.1138 - val_mse: 241.1138\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 214.9787 - mse: 214.9787 - val_loss: 206.6509 - val_mse: 206.6509\n",
            "mse: 206.6509246826172\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 254 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 33ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.1575 - val_mse: 0.1575\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1828 - mse: 0.1828 - val_loss: 0.1788 - val_mse: 0.1788\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 0.0686 - val_mse: 0.0686\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0379 - val_mse: 0.0379\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "mse: 0.03271657973527908\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 255 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 28ms/step - loss: 186391168.0000 - mse: 186391168.0000 - val_loss: 67810.6094 - val_mse: 67810.6094\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 595402.0625 - mse: 595402.0625 - val_loss: 417426.1250 - val_mse: 417426.1250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 106648.1797 - mse: 106648.1797 - val_loss: 37676.3047 - val_mse: 37676.3047\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4802.1191 - mse: 4802.1196 - val_loss: 547.0048 - val_mse: 547.0048\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 562.1033 - mse: 562.1033 - val_loss: 591.1909 - val_mse: 591.1909\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 809.4368 - mse: 809.4368 - val_loss: 666.0525 - val_mse: 666.0525\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 845.5339 - mse: 845.5339 - val_loss: 731.1655 - val_mse: 731.1655\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 707.4772 - mse: 707.4772 - val_loss: 226.6727 - val_mse: 226.6727\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 455.0296 - mse: 455.0296 - val_loss: 224.9817 - val_mse: 224.9817\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 186.2933 - mse: 186.2933 - val_loss: 127.2247 - val_mse: 127.2247\n",
            "mse: 127.22466278076172\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 256 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 35ms/step - loss: 7.6455 - mse: 7.6455 - val_loss: 0.0567 - val_mse: 0.0567\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6055 - mse: 0.6055 - val_loss: 0.1080 - val_mse: 0.1080\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2133 - mse: 0.2133 - val_loss: 0.1143 - val_mse: 0.1143\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 0.0601 - val_mse: 0.0601\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0440 - val_mse: 0.0440\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0345 - val_mse: 0.0345\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "mse: 0.03380899131298065\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 257 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 37ms/step - loss: 659966784.0000 - mse: 659966784.0000 - val_loss: 967987.5625 - val_mse: 967987.5625\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 325190.0938 - mse: 325190.0938 - val_loss: 70969.1797 - val_mse: 70969.1797\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 71285.2188 - mse: 71285.2188 - val_loss: 29974.8516 - val_mse: 29974.8555\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 16742.2383 - mse: 16742.2383 - val_loss: 11546.7891 - val_mse: 11546.7891\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3930.0710 - mse: 3930.0710 - val_loss: 1474.0532 - val_mse: 1474.0532\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 1063.2695 - mse: 1063.2695 - val_loss: 272.2420 - val_mse: 272.2420\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 466.7914 - mse: 466.7914 - val_loss: 300.6665 - val_mse: 300.6665\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 289.4906 - mse: 289.4906 - val_loss: 293.8763 - val_mse: 293.8763\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 214.6810 - mse: 214.6810 - val_loss: 147.5341 - val_mse: 147.5341\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 146.3631 - mse: 146.3631 - val_loss: 128.5784 - val_mse: 128.5784\n",
            "mse: 128.57839965820312\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 258 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 38ms/step - loss: 0.0740 - mse: 0.0740 - val_loss: 0.0473 - val_mse: 0.0473\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0409 - val_mse: 0.0409\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0262 - val_mse: 0.0262\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0261 - val_mse: 0.0261\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0262 - val_mse: 0.0262\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "mse: 0.025198649615049362\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 259 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 28ms/step - loss: 3601466.5000 - mse: 3601466.5000 - val_loss: 411277.5938 - val_mse: 411277.5938\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 527594.5000 - mse: 527594.5000 - val_loss: 181244.1250 - val_mse: 181244.1250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 171479.9844 - mse: 171480.0156 - val_loss: 117733.5625 - val_mse: 117733.5625\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 63778.0938 - mse: 63778.0938 - val_loss: 51708.5117 - val_mse: 51708.5117\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 25282.3125 - mse: 25282.3125 - val_loss: 21878.9844 - val_mse: 21878.9844\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 10529.0156 - mse: 10529.0156 - val_loss: 6113.9360 - val_mse: 6113.9360\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4172.9790 - mse: 4172.9790 - val_loss: 1930.7272 - val_mse: 1930.7272\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1979.6407 - mse: 1979.6407 - val_loss: 915.7565 - val_mse: 915.7565\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1151.8132 - mse: 1151.8132 - val_loss: 819.2000 - val_mse: 819.2000\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 801.8084 - mse: 801.8085 - val_loss: 927.6619 - val_mse: 927.6619\n",
            "mse: 927.6619262695312\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 260 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 25ms/step - loss: 1.3298 - mse: 1.3298 - val_loss: 0.3467 - val_mse: 0.3467\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4214 - mse: 0.4214 - val_loss: 0.0846 - val_mse: 0.0846\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0741 - mse: 0.0741 - val_loss: 0.1395 - val_mse: 0.1395\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0344 - val_mse: 0.0344\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0378 - val_mse: 0.0378\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "mse: 0.026437759399414062\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 261 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 25ms/step - loss: 7561766.5000 - mse: 7561766.5000 - val_loss: 41817.1641 - val_mse: 41817.1719\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1298743.1250 - mse: 1298743.1250 - val_loss: 775651.3125 - val_mse: 775651.3125\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 402529.2188 - mse: 402529.2188 - val_loss: 396284.2812 - val_mse: 396284.2812\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 188253.5469 - mse: 188253.5469 - val_loss: 28803.2637 - val_mse: 28803.2637\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 68497.7500 - mse: 68497.7500 - val_loss: 5516.2773 - val_mse: 5516.2773\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 22375.4570 - mse: 22375.4570 - val_loss: 11349.6084 - val_mse: 11349.6084\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8682.3789 - mse: 8682.3789 - val_loss: 6600.1567 - val_mse: 6600.1567\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4124.9009 - mse: 4124.9009 - val_loss: 1954.2294 - val_mse: 1954.2294\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1847.2297 - mse: 1847.2295 - val_loss: 421.2630 - val_mse: 421.2630\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 946.9657 - mse: 946.9657 - val_loss: 309.3587 - val_mse: 309.3587\n",
            "mse: 309.35870361328125\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 262 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 29ms/step - loss: 0.1579 - mse: 0.1579 - val_loss: 0.0606 - val_mse: 0.0606\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "mse: 0.022086741402745247\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 263 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 36ms/step - loss: 15166283.0000 - mse: 15166283.0000 - val_loss: 7181436.0000 - val_mse: 7181436.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2260909.5000 - mse: 2260909.5000 - val_loss: 942292.3125 - val_mse: 942292.3125\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 656592.1250 - mse: 656592.1250 - val_loss: 204547.2969 - val_mse: 204547.2969\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 143572.0781 - mse: 143572.0781 - val_loss: 148381.1875 - val_mse: 148381.1875\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 80615.4688 - mse: 80615.4688 - val_loss: 2984.8599 - val_mse: 2984.8599\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 21472.5137 - mse: 21472.5156 - val_loss: 22976.6680 - val_mse: 22976.6680\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 9547.9443 - mse: 9547.9443 - val_loss: 5968.2339 - val_mse: 5968.2339\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 4799.5840 - mse: 4799.5840 - val_loss: 815.1281 - val_mse: 815.1281\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2055.2754 - mse: 2055.2754 - val_loss: 985.4627 - val_mse: 985.4627\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1030.1746 - mse: 1030.1746 - val_loss: 656.3256 - val_mse: 656.3256\n",
            "mse: 656.3255615234375\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 264 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 31ms/step - loss: 0.3351 - mse: 0.3351 - val_loss: 0.2850 - val_mse: 0.2850\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2199 - mse: 0.2199 - val_loss: 0.1841 - val_mse: 0.1841\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1362 - mse: 0.1362 - val_loss: 0.1150 - val_mse: 0.1150\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0825 - mse: 0.0825 - val_loss: 0.0722 - val_mse: 0.0722\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0490 - val_mse: 0.0490\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0381 - val_mse: 0.0381\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "mse: 0.031700968742370605\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 265 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 23ms/step - loss: 240200464.0000 - mse: 240200464.0000 - val_loss: 195145840.0000 - val_mse: 195145840.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 169800176.0000 - mse: 169800176.0000 - val_loss: 132053920.0000 - val_mse: 132053920.0000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 109960160.0000 - mse: 109960160.0000 - val_loss: 79055296.0000 - val_mse: 79055296.0000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 62326612.0000 - mse: 62326612.0000 - val_loss: 40994256.0000 - val_mse: 40994256.0000\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 30726322.0000 - mse: 30726322.0000 - val_loss: 18123830.0000 - val_mse: 18123830.0000\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 12523338.0000 - mse: 12523338.0000 - val_loss: 5959672.0000 - val_mse: 5959672.0000\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3459144.5000 - mse: 3459144.5000 - val_loss: 959122.0000 - val_mse: 959122.0000\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 416002.5312 - mse: 416002.5312 - val_loss: 29846.7734 - val_mse: 29846.7734\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 95016.5078 - mse: 95016.5156 - val_loss: 158003.5781 - val_mse: 158003.5781\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 163235.1094 - mse: 163235.1094 - val_loss: 125865.6953 - val_mse: 125865.6953\n",
            "mse: 125865.6953125\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 266 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 100ms/step - loss: 0.4103 - mse: 0.4103 - val_loss: 0.2467 - val_mse: 0.2467\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1423 - mse: 0.1423 - val_loss: 0.0730 - val_mse: 0.0730\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "mse: 0.03085266426205635\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 267 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 39ms/step - loss: 83703656.0000 - mse: 83703656.0000 - val_loss: 34144364.0000 - val_mse: 34144364.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 16506842.0000 - mse: 16506842.0000 - val_loss: 1800999.1250 - val_mse: 1800999.1250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 632109.9375 - mse: 632109.9375 - val_loss: 1427842.7500 - val_mse: 1427842.7500\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1844981.2500 - mse: 1844981.2500 - val_loss: 1452398.8750 - val_mse: 1452398.8750\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 702032.4375 - mse: 702032.4375 - val_loss: 84258.7344 - val_mse: 84258.7344\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 47233.4414 - mse: 47233.4492 - val_loss: 86706.2500 - val_mse: 86706.2500\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 112440.5078 - mse: 112440.5078 - val_loss: 59156.1328 - val_mse: 59156.1328\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 37802.3594 - mse: 37802.3594 - val_loss: 11828.7275 - val_mse: 11828.7275\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 18920.8848 - mse: 18920.8848 - val_loss: 21915.7168 - val_mse: 21915.7168\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 17799.9648 - mse: 17799.9648 - val_loss: 11595.9082 - val_mse: 11595.9092\n",
            "mse: 11595.908203125\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 268 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 55ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0636 - val_mse: 0.0636\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0374 - val_mse: 0.0374\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0284 - val_mse: 0.0284\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0276 - val_mse: 0.0276\n",
            "mse: 0.027622798457741737\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 269 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 34ms/step - loss: 2322227.0000 - mse: 2322227.0000 - val_loss: 121513.2031 - val_mse: 121513.2031\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 426200.5625 - mse: 426200.5625 - val_loss: 65965.4375 - val_mse: 65965.4375\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 167644.8438 - mse: 167644.8438 - val_loss: 82907.8281 - val_mse: 82907.8281\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 81284.6172 - mse: 81284.6172 - val_loss: 79849.7422 - val_mse: 79849.7422\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 32223.0527 - mse: 32223.0527 - val_loss: 7592.7529 - val_mse: 7592.7529\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6364.2402 - mse: 6364.2402 - val_loss: 5103.6650 - val_mse: 5103.6650\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3912.0020 - mse: 3912.0020 - val_loss: 1098.5289 - val_mse: 1098.5289\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1554.3719 - mse: 1554.3721 - val_loss: 1453.1827 - val_mse: 1453.1827\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 858.5612 - mse: 858.5612 - val_loss: 733.2488 - val_mse: 733.2489\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 573.9547 - mse: 573.9547 - val_loss: 408.1094 - val_mse: 408.1094\n",
            "mse: 408.1094055175781\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 270 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1117 - mse: 0.1117 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0356 - val_mse: 0.0356\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "mse: 0.032119058072566986\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 271 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 6827969.0000 - mse: 6827969.0000 - val_loss: 4170.6646 - val_mse: 4170.6646\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 862.9668 - mse: 862.9668 - val_loss: 190.5586 - val_mse: 190.5586\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 238.8885 - mse: 238.8885 - val_loss: 127.9266 - val_mse: 127.9266\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1068.1267 - mse: 1068.1267 - val_loss: 282.5511 - val_mse: 282.5511\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 362.4407 - mse: 362.4407 - val_loss: 72.9934 - val_mse: 72.9934\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 204.4276 - mse: 204.4276 - val_loss: 366.6433 - val_mse: 366.6433\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 150.8113 - mse: 150.8113 - val_loss: 70.8274 - val_mse: 70.8274\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 202.6613 - mse: 202.6613 - val_loss: 211.0030 - val_mse: 211.0030\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 358.8799 - mse: 358.8799 - val_loss: 197.7644 - val_mse: 197.7644\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 138.5891 - mse: 138.5891 - val_loss: 38.3449 - val_mse: 38.3449\n",
            "mse: 38.34486389160156\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 272 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1364 - mse: 0.1364 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0355 - val_mse: 0.0355\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0381 - val_mse: 0.0381\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0400 - val_mse: 0.0400\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0477 - val_mse: 0.0477\n",
            "mse: 0.04765409231185913\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 273 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 16509809.0000 - mse: 16509809.0000 - val_loss: 213.7704 - val_mse: 213.7704\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1522.4099 - mse: 1522.4099 - val_loss: 176.6631 - val_mse: 176.6631\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1628.3999 - mse: 1628.3999 - val_loss: 69.4513 - val_mse: 69.4513\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 112.3289 - mse: 112.3289 - val_loss: 79.1423 - val_mse: 79.1423\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 71.0105 - mse: 71.0105 - val_loss: 26.3525 - val_mse: 26.3525\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 93.6975 - mse: 93.6975 - val_loss: 49.9169 - val_mse: 49.9169\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 95.2828 - mse: 95.2828 - val_loss: 31.5582 - val_mse: 31.5582\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 31.6397 - mse: 31.6397 - val_loss: 13.4149 - val_mse: 13.4149\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 75.9116 - mse: 75.9116 - val_loss: 20.9600 - val_mse: 20.9600\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 38.0275 - mse: 38.0275 - val_loss: 26.5208 - val_mse: 26.5208\n",
            "mse: 26.520793914794922\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 274 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6485 - mse: 0.6485 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0424 - val_mse: 0.0424\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0397 - val_mse: 0.0397\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0349 - val_mse: 0.0349\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0397 - val_mse: 0.0397\n",
            "mse: 0.0396888330578804\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 275 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 26283200.0000 - mse: 26283200.0000 - val_loss: 95.2633 - val_mse: 95.2633\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 29.7059 - mse: 29.7059 - val_loss: 11.8047 - val_mse: 11.8047\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 20.2211 - mse: 20.2211 - val_loss: 11.0713 - val_mse: 11.0713\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 11.0710 - mse: 11.0710 - val_loss: 8.7480 - val_mse: 8.7480\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 13.2950 - mse: 13.2950 - val_loss: 7.9717 - val_mse: 7.9717\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 23.6634 - mse: 23.6634 - val_loss: 21.6730 - val_mse: 21.6730\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 19.0256 - mse: 19.0256 - val_loss: 12.3507 - val_mse: 12.3507\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 28.8420 - mse: 28.8420 - val_loss: 5.3764 - val_mse: 5.3764\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 11.0376 - mse: 11.0376 - val_loss: 14.7492 - val_mse: 14.7492\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 15.2901 - mse: 15.2901 - val_loss: 12.3291 - val_mse: 12.3291\n",
            "mse: 12.329071998596191\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 276 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2430 - mse: 0.2430 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "mse: 0.026361864060163498\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 277 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 346084.2188 - mse: 346084.1875 - val_loss: 5477.1904 - val_mse: 5477.1904\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3072.7830 - mse: 3072.7830 - val_loss: 920.5524 - val_mse: 920.5524\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1126.7428 - mse: 1126.7428 - val_loss: 1646.7250 - val_mse: 1646.7250\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 548.0607 - mse: 548.0607 - val_loss: 282.3333 - val_mse: 282.3333\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 500.8133 - mse: 500.8133 - val_loss: 178.4085 - val_mse: 178.4085\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 348.4041 - mse: 348.4041 - val_loss: 148.4322 - val_mse: 148.4322\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 269.9606 - mse: 269.9606 - val_loss: 163.1064 - val_mse: 163.1064\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 177.1139 - mse: 177.1139 - val_loss: 128.3870 - val_mse: 128.3870\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 491.6401 - mse: 491.6401 - val_loss: 560.6437 - val_mse: 560.6437\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 840.6563 - mse: 840.6563 - val_loss: 804.9277 - val_mse: 804.9277\n",
            "mse: 804.927734375\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 278 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2325 - mse: 0.2325 - val_loss: 0.0279 - val_mse: 0.0279\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0267 - val_mse: 0.0267\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0270 - val_mse: 0.0270\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0301 - val_mse: 0.0301\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0287 - val_mse: 0.0287\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "mse: 0.029650481417775154\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 279 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 684816.8125 - mse: 684816.8125 - val_loss: 2090.3179 - val_mse: 2090.3179\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 20807.9668 - mse: 20807.9668 - val_loss: 19830.9160 - val_mse: 19830.9160\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 5870.6738 - mse: 5870.6738 - val_loss: 8133.0356 - val_mse: 8133.0356\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2809.4131 - mse: 2809.4131 - val_loss: 17210.7168 - val_mse: 17210.7168\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2744.4644 - mse: 2744.4646 - val_loss: 631.8224 - val_mse: 631.8224\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 612.3975 - mse: 612.3975 - val_loss: 696.7036 - val_mse: 696.7036\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 828.8078 - mse: 828.8078 - val_loss: 2026.7638 - val_mse: 2026.7638\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2993.9417 - mse: 2993.9417 - val_loss: 2310.3909 - val_mse: 2310.3909\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1166.4111 - mse: 1166.4111 - val_loss: 481.1328 - val_mse: 481.1328\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 647.6811 - mse: 647.6811 - val_loss: 370.5049 - val_mse: 370.5049\n",
            "mse: 370.5048828125\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 280 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2051 - mse: 0.2051 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0279 - val_mse: 0.0279\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "mse: 0.029596682637929916\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 281 /162\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "98/98 [==============================] - 2s 10ms/step - loss: 2102757.0000 - mse: 2102757.0000 - val_loss: 1120.0219 - val_mse: 1120.0219\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 19086.6230 - mse: 19086.6211 - val_loss: 173.3357 - val_mse: 173.3357\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 615.2236 - mse: 615.2236 - val_loss: 206.1069 - val_mse: 206.1069\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 417.7761 - mse: 417.7761 - val_loss: 111.5263 - val_mse: 111.5263\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 229.0314 - mse: 229.0314 - val_loss: 222.8138 - val_mse: 222.8138\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 160.0153 - mse: 160.0153 - val_loss: 230.1119 - val_mse: 230.1119\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 201.2087 - mse: 201.2087 - val_loss: 65.4098 - val_mse: 65.4098\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 244.2836 - mse: 244.2836 - val_loss: 53.4277 - val_mse: 53.4277\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 545.8854 - mse: 545.8854 - val_loss: 440.3445 - val_mse: 440.3446\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 598.5980 - mse: 598.5980 - val_loss: 693.9068 - val_mse: 693.9067\n",
            "mse: 693.9067993164062\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 282 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.5206 - mse: 0.5206 - val_loss: 0.0868 - val_mse: 0.0868\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0344 - val_mse: 0.0344\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "mse: 0.029880177229642868\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 283 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 8ms/step - loss: 4305105.5000 - mse: 4305105.5000 - val_loss: 161187.4375 - val_mse: 161187.4375\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 109231.2109 - mse: 109231.2109 - val_loss: 73957.7422 - val_mse: 73957.7422\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 39709.9922 - mse: 39709.9922 - val_loss: 12485.6416 - val_mse: 12485.6416\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 10861.8721 - mse: 10861.8721 - val_loss: 6261.4219 - val_mse: 6261.4219\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 6593.7949 - mse: 6593.7954 - val_loss: 3985.1260 - val_mse: 3985.1260\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 4681.7627 - mse: 4681.7627 - val_loss: 3127.7786 - val_mse: 3127.7786\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 3600.1931 - mse: 3600.1931 - val_loss: 2382.4631 - val_mse: 2382.4631\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2813.3462 - mse: 2813.3462 - val_loss: 1718.4174 - val_mse: 1718.4174\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2119.3176 - mse: 2119.3174 - val_loss: 1542.9271 - val_mse: 1542.9271\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1721.6698 - mse: 1721.6698 - val_loss: 1035.1183 - val_mse: 1035.1183\n",
            "mse: 1035.1182861328125\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 284 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.1358 - mse: 0.1358 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0301 - val_mse: 0.0301\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0287 - val_mse: 0.0287\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "mse: 0.027211623266339302\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 285 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 9ms/step - loss: 16308.9775 - mse: 16308.9775 - val_loss: 3309.8235 - val_mse: 3309.8235\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 869.8380 - mse: 869.8380 - val_loss: 302.9636 - val_mse: 302.9636\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 655.2912 - mse: 655.2911 - val_loss: 201.2051 - val_mse: 201.2051\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 360.0129 - mse: 360.0129 - val_loss: 890.2659 - val_mse: 890.2659\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 259.8490 - mse: 259.8490 - val_loss: 120.7398 - val_mse: 120.7397\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 183.4297 - mse: 183.4297 - val_loss: 115.4382 - val_mse: 115.4382\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 251.8590 - mse: 251.8590 - val_loss: 237.6010 - val_mse: 237.6010\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 258.7036 - mse: 258.7036 - val_loss: 291.5143 - val_mse: 291.5143\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 586.9424 - mse: 586.9424 - val_loss: 116.8954 - val_mse: 116.8954\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2386.1531 - mse: 2386.1531 - val_loss: 133.3199 - val_mse: 133.3199\n",
            "mse: 133.3199005126953\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 286 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "mse: 0.020805425941944122\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 287 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 1354477.1250 - mse: 1354477.1250 - val_loss: 1341.1753 - val_mse: 1341.1753\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 892.8080 - mse: 892.8080 - val_loss: 400.4681 - val_mse: 400.4681\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 561.9115 - mse: 561.9115 - val_loss: 363.3843 - val_mse: 363.3843\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 406.3293 - mse: 406.3293 - val_loss: 233.8145 - val_mse: 233.8145\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 304.0048 - mse: 304.0048 - val_loss: 178.5387 - val_mse: 178.5387\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 166.0302 - mse: 166.0302 - val_loss: 118.5289 - val_mse: 118.5289\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 138.9578 - mse: 138.9578 - val_loss: 103.9688 - val_mse: 103.9688\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 102.2240 - mse: 102.2240 - val_loss: 83.0820 - val_mse: 83.0820\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 81.0226 - mse: 81.0226 - val_loss: 77.9849 - val_mse: 77.9849\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 65.9274 - mse: 65.9274 - val_loss: 67.3868 - val_mse: 67.3868\n",
            "mse: 67.38679504394531\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 288 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 1.0963 - mse: 1.0963 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0466 - val_mse: 0.0466\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "mse: 0.03305884450674057\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 289 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 32057078.0000 - mse: 32057078.0000 - val_loss: 281467.1875 - val_mse: 281467.1875\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 56597.0039 - mse: 56597.0039 - val_loss: 13659.8926 - val_mse: 13659.8926\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 5615.9575 - mse: 5615.9575 - val_loss: 3500.4766 - val_mse: 3500.4766\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1660.0420 - mse: 1660.0420 - val_loss: 1755.8394 - val_mse: 1755.8394\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 929.7292 - mse: 929.7292 - val_loss: 1275.1447 - val_mse: 1275.1447\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 810.0554 - mse: 810.0554 - val_loss: 1210.2679 - val_mse: 1210.2679\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 683.6823 - mse: 683.6823 - val_loss: 1102.3140 - val_mse: 1102.3140\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 612.4332 - mse: 612.4332 - val_loss: 781.6079 - val_mse: 781.6079\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 469.5560 - mse: 469.5560 - val_loss: 621.7308 - val_mse: 621.7308\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 441.4183 - mse: 441.4183 - val_loss: 479.8593 - val_mse: 479.8593\n",
            "mse: 479.8592834472656\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 290 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.5381 - mse: 0.5381 - val_loss: 0.1666 - val_mse: 0.1666\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0627 - mse: 0.0627 - val_loss: 0.0438 - val_mse: 0.0438\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "mse: 0.03285291790962219\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 291 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 48024468.0000 - mse: 48024468.0000 - val_loss: 5433.0898 - val_mse: 5433.0898\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 11053.0459 - mse: 11053.0459 - val_loss: 1110.6685 - val_mse: 1110.6685\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 456.4180 - mse: 456.4180 - val_loss: 216.1350 - val_mse: 216.1350\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 72.0981 - mse: 72.0981 - val_loss: 24.1289 - val_mse: 24.1289\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 24.3298 - mse: 24.3298 - val_loss: 15.0565 - val_mse: 15.0565\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 14.1921 - mse: 14.1921 - val_loss: 11.2920 - val_mse: 11.2920\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 10.5102 - mse: 10.5102 - val_loss: 8.9536 - val_mse: 8.9536\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 8.9125 - mse: 8.9125 - val_loss: 7.5033 - val_mse: 7.5033\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 7.9449 - mse: 7.9449 - val_loss: 6.7313 - val_mse: 6.7313\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 7.2278 - mse: 7.2278 - val_loss: 6.1713 - val_mse: 6.1713\n",
            "mse: 6.171303749084473\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 292 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 4.1831 - mse: 4.1831 - val_loss: 0.1012 - val_mse: 0.1012\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.1424 - mse: 0.1424 - val_loss: 0.0560 - val_mse: 0.0560\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "mse: 0.03275801241397858\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 293 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 28ms/step - loss: 523602944.0000 - mse: 523602944.0000 - val_loss: 93617.8672 - val_mse: 93617.8672\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 16183.7383 - mse: 16183.7383 - val_loss: 2678.0598 - val_mse: 2678.0598\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 2361.8955 - mse: 2361.8955 - val_loss: 1051.3914 - val_mse: 1051.3914\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 851.7091 - mse: 851.7091 - val_loss: 846.1718 - val_mse: 846.1718\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 2243.6277 - mse: 2243.6277 - val_loss: 2423.0583 - val_mse: 2423.0581\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 16912.1602 - mse: 16912.1602 - val_loss: 15742.8555 - val_mse: 15742.8555\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 4266.5542 - mse: 4266.5542 - val_loss: 1224.8448 - val_mse: 1224.8448\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 796.9680 - mse: 796.9680 - val_loss: 274.2339 - val_mse: 274.2339\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 2735.0088 - mse: 2735.0088 - val_loss: 129.6551 - val_mse: 129.6551\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 1214.8939 - mse: 1214.8939 - val_loss: 172.4998 - val_mse: 172.4998\n",
            "mse: 172.4998321533203\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 294 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 1.2887 - mse: 1.2887 - val_loss: 0.0549 - val_mse: 0.0549\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 0.0350 - val_mse: 0.0350\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0364 - val_mse: 0.0364\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0301 - val_mse: 0.0301\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0291 - val_mse: 0.0291\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0286 - val_mse: 0.0286\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0278 - val_mse: 0.0278\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0268 - val_mse: 0.0268\n",
            "mse: 0.02677619829773903\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 295 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 4s 61ms/step - loss: 2836790.2500 - mse: 2836790.2500 - val_loss: 271256.2500 - val_mse: 271256.2188\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 110546.1484 - mse: 110546.1484 - val_loss: 54246.3125 - val_mse: 54246.3125\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 27627.8848 - mse: 27627.8848 - val_loss: 16574.9316 - val_mse: 16574.9316\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 15518.2158 - mse: 15518.2148 - val_loss: 15179.0967 - val_mse: 15179.0967\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 12577.6357 - mse: 12577.6357 - val_loss: 11521.0762 - val_mse: 11521.0762\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 10576.8242 - mse: 10576.8242 - val_loss: 9806.0928 - val_mse: 9806.0928\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 7654.4243 - mse: 7654.4243 - val_loss: 4938.8184 - val_mse: 4938.8184\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 3851.9622 - mse: 3851.9619 - val_loss: 2661.3936 - val_mse: 2661.3936\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 1928.2858 - mse: 1928.2858 - val_loss: 842.8438 - val_mse: 842.8438\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 948.8649 - mse: 948.8649 - val_loss: 651.7341 - val_mse: 651.7341\n",
            "mse: 651.734130859375\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 296 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "mse: 0.02256765030324459\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 297 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 2s 57ms/step - loss: 4671464.0000 - mse: 4671464.0000 - val_loss: 1092104.1250 - val_mse: 1092104.1250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 404561.4062 - mse: 404561.3438 - val_loss: 152509.5156 - val_mse: 152509.5156\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 47003.4570 - mse: 47003.4570 - val_loss: 9528.2051 - val_mse: 9528.2051\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 6845.0991 - mse: 6845.0991 - val_loss: 531.2074 - val_mse: 531.2074\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1571.5416 - mse: 1571.5417 - val_loss: 413.4311 - val_mse: 413.4311\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 583.2474 - mse: 583.2474 - val_loss: 452.7260 - val_mse: 452.7260\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 646.6172 - mse: 646.6172 - val_loss: 326.6223 - val_mse: 326.6223\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 556.9744 - mse: 556.9744 - val_loss: 315.8100 - val_mse: 315.8100\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 534.1272 - mse: 534.1272 - val_loss: 287.8194 - val_mse: 287.8194\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 376.0835 - mse: 376.0835 - val_loss: 283.7755 - val_mse: 283.7755\n",
            "mse: 283.7754821777344\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 298 /162\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 2s 32ms/step - loss: 0.1485 - mse: 0.1485 - val_loss: 0.0719 - val_mse: 0.0719\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0276 - val_mse: 0.0276\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "mse: 0.022216875106096268\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 299 /162\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 3s 36ms/step - loss: 4332258.5000 - mse: 4332258.5000 - val_loss: 502290.8750 - val_mse: 502290.8750\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 159835.5469 - mse: 159835.5469 - val_loss: 3191.6257 - val_mse: 3191.6257\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 16104.9414 - mse: 16104.9414 - val_loss: 3801.3669 - val_mse: 3801.3669\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 3897.2131 - mse: 3897.2131 - val_loss: 1053.4963 - val_mse: 1053.4963\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 1846.9465 - mse: 1846.9465 - val_loss: 1144.9659 - val_mse: 1144.9659\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 944.7702 - mse: 944.7702 - val_loss: 556.5914 - val_mse: 556.5914\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 678.9191 - mse: 678.9191 - val_loss: 450.9731 - val_mse: 450.9731\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 542.8015 - mse: 542.8015 - val_loss: 346.6929 - val_mse: 346.6929\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 295.3318 - mse: 295.3318 - val_loss: 237.1519 - val_mse: 237.1519\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 227.7764 - mse: 227.7764 - val_loss: 183.9104 - val_mse: 183.9104\n",
            "mse: 183.91036987304688\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 300 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 2s 42ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "mse: 0.030158836394548416\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 301 /162\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 3s 35ms/step - loss: 4669022.5000 - mse: 4669022.5000 - val_loss: 1457880.1250 - val_mse: 1457880.1250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1027892.1875 - mse: 1027892.1875 - val_loss: 697311.3125 - val_mse: 697311.3125\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 514619.0625 - mse: 514619.0625 - val_loss: 404262.2500 - val_mse: 404262.2500\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 351393.1562 - mse: 351393.1250 - val_loss: 316610.0625 - val_mse: 316610.0625\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 263986.1250 - mse: 263986.1250 - val_loss: 236702.2812 - val_mse: 236702.2812\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 191792.8906 - mse: 191792.8906 - val_loss: 160783.8438 - val_mse: 160783.8438\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 130116.8750 - mse: 130116.8750 - val_loss: 102085.8906 - val_mse: 102085.8906\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 84052.6172 - mse: 84052.6172 - val_loss: 71207.9688 - val_mse: 71207.9688\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 60264.5469 - mse: 60264.5469 - val_loss: 54431.9961 - val_mse: 54431.9961\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 46912.7812 - mse: 46912.7812 - val_loss: 44323.7812 - val_mse: 44323.7812\n",
            "mse: 44323.78125\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 302 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 0.0792 - mse: 0.0792 - val_loss: 0.0366 - val_mse: 0.0366\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0295 - val_mse: 0.0295\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0268 - val_mse: 0.0268\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "mse: 0.026314513757824898\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 303 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 297731.4375 - mse: 297731.4375 - val_loss: 21212.2109 - val_mse: 21212.2109\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 64222.8125 - mse: 64222.8125 - val_loss: 22261.2891 - val_mse: 22261.2891\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 32679.7012 - mse: 32679.7012 - val_loss: 7083.0205 - val_mse: 7083.0205\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 14210.0059 - mse: 14210.0059 - val_loss: 2989.7266 - val_mse: 2989.7268\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 6423.8853 - mse: 6423.8853 - val_loss: 1674.5739 - val_mse: 1674.5739\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 3387.6033 - mse: 3387.6033 - val_loss: 869.0657 - val_mse: 869.0657\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1458.9703 - mse: 1458.9703 - val_loss: 586.0444 - val_mse: 586.0444\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 922.5662 - mse: 922.5662 - val_loss: 474.7638 - val_mse: 474.7638\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 671.3558 - mse: 671.3558 - val_loss: 460.6372 - val_mse: 460.6372\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 547.2570 - mse: 547.2570 - val_loss: 414.1270 - val_mse: 414.1270\n",
            "mse: 414.1269836425781\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 304 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 19ms/step - loss: 0.2180 - mse: 0.2180 - val_loss: 0.0809 - val_mse: 0.0809\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0419 - val_mse: 0.0419\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "mse: 0.024241605773568153\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 305 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 27ms/step - loss: 11561724.0000 - mse: 11561725.0000 - val_loss: 1171468.1250 - val_mse: 1171468.1250\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 513283.6562 - mse: 513283.6562 - val_loss: 45441.3203 - val_mse: 45441.3203\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 90943.0703 - mse: 90943.0703 - val_loss: 48557.5312 - val_mse: 48557.5312\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 16721.3945 - mse: 16721.3945 - val_loss: 3875.8196 - val_mse: 3875.8196\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 3626.2839 - mse: 3626.2839 - val_loss: 1385.8196 - val_mse: 1385.8196\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 1230.5079 - mse: 1230.5079 - val_loss: 839.6915 - val_mse: 839.6915\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 760.4459 - mse: 760.4459 - val_loss: 605.9286 - val_mse: 605.9286\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 576.4435 - mse: 576.4435 - val_loss: 550.6211 - val_mse: 550.6211\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 507.4572 - mse: 507.4572 - val_loss: 492.8115 - val_mse: 492.8115\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 404.6412 - mse: 404.6412 - val_loss: 440.8758 - val_mse: 440.8758\n",
            "mse: 440.8758239746094\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 306 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 0.2377 - mse: 0.2377 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0859 - val_mse: 0.0859\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0376 - val_mse: 0.0376\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0353 - val_mse: 0.0353\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "mse: 0.032399460673332214\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 307 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 16796976.0000 - mse: 16796976.0000 - val_loss: 501833.6562 - val_mse: 501833.6562\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 588204.5625 - mse: 588204.5625 - val_loss: 26205.5703 - val_mse: 26205.5703\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 30614.3008 - mse: 30614.3027 - val_loss: 2346.8486 - val_mse: 2346.8486\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10240.3291 - mse: 10240.3291 - val_loss: 3418.0508 - val_mse: 3418.0508\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4311.2173 - mse: 4311.2173 - val_loss: 4467.4473 - val_mse: 4467.4473\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2484.6787 - mse: 2484.6787 - val_loss: 2039.0543 - val_mse: 2039.0543\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1580.8807 - mse: 1580.8807 - val_loss: 1136.5216 - val_mse: 1136.5216\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1187.6259 - mse: 1187.6259 - val_loss: 994.4770 - val_mse: 994.4770\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 992.0732 - mse: 992.0732 - val_loss: 877.9272 - val_mse: 877.9272\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 861.6304 - mse: 861.6304 - val_loss: 812.2103 - val_mse: 812.2103\n",
            "mse: 812.2103271484375\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 308 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 1.4362 - mse: 1.4362 - val_loss: 0.1407 - val_mse: 0.1407\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2102 - mse: 0.2102 - val_loss: 0.0974 - val_mse: 0.0974\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0891 - mse: 0.0891 - val_loss: 0.0490 - val_mse: 0.0490\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0475 - val_mse: 0.0475\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0371 - val_mse: 0.0371\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0383 - val_mse: 0.0383\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "mse: 0.03361348807811737\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 309 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 33ms/step - loss: 231254496.0000 - mse: 231254496.0000 - val_loss: 182536.5625 - val_mse: 182536.5625\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 768753.9375 - mse: 768753.9375 - val_loss: 130604.5000 - val_mse: 130604.5000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 72173.6016 - mse: 72173.6016 - val_loss: 24071.0352 - val_mse: 24071.0352\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 17460.4492 - mse: 17460.4492 - val_loss: 1416.8833 - val_mse: 1416.8833\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5880.6353 - mse: 5880.6353 - val_loss: 2296.5874 - val_mse: 2296.5874\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2267.3564 - mse: 2267.3564 - val_loss: 1845.8225 - val_mse: 1845.8225\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 894.0164 - mse: 894.0164 - val_loss: 608.3627 - val_mse: 608.3627\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 332.9367 - mse: 332.9367 - val_loss: 62.0559 - val_mse: 62.0559\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 138.0000 - mse: 138.0000 - val_loss: 134.2660 - val_mse: 134.2660\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 643.2424 - mse: 643.2424 - val_loss: 1053.1283 - val_mse: 1053.1283\n",
            "mse: 1053.1282958984375\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 310 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 46ms/step - loss: 8.2234 - mse: 8.2234 - val_loss: 0.0913 - val_mse: 0.0913\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4145 - mse: 0.4145 - val_loss: 0.1236 - val_mse: 0.1236\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.1554 - mse: 0.1554 - val_loss: 0.1129 - val_mse: 0.1129\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 0.0575 - val_mse: 0.0575\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0441 - val_mse: 0.0441\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "mse: 0.034796182066202164\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 311 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 38ms/step - loss: 743410752.0000 - mse: 743410752.0000 - val_loss: 28188.5801 - val_mse: 28188.5801\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 134582.2500 - mse: 134582.2500 - val_loss: 40075.6172 - val_mse: 40075.6172\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 22589.6465 - mse: 22589.6465 - val_loss: 977.4705 - val_mse: 977.4705\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 1446.3645 - mse: 1446.3645 - val_loss: 314.2347 - val_mse: 314.2347\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2771.3955 - mse: 2771.3955 - val_loss: 104.3005 - val_mse: 104.3005\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1615.3242 - mse: 1615.3242 - val_loss: 40.4947 - val_mse: 40.4947\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 566.1080 - mse: 566.1079 - val_loss: 710.7768 - val_mse: 710.7768\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 541.6027 - mse: 541.6027 - val_loss: 511.0711 - val_mse: 511.0711\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 275.3731 - mse: 275.3731 - val_loss: 73.6152 - val_mse: 73.6152\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 108.6120 - mse: 108.6120 - val_loss: 93.2989 - val_mse: 93.2989\n",
            "mse: 93.29888153076172\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 312 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 31ms/step - loss: 0.8427 - mse: 0.8427 - val_loss: 0.0745 - val_mse: 0.0745\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0763 - mse: 0.0763 - val_loss: 0.1395 - val_mse: 0.1395\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1058 - mse: 0.1058 - val_loss: 0.0393 - val_mse: 0.0393\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0489 - val_mse: 0.0489\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0352 - val_mse: 0.0352\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "mse: 0.03107568807899952\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 313 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 30ms/step - loss: 17143948.0000 - mse: 17143948.0000 - val_loss: 7019948.0000 - val_mse: 7019948.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1937423.8750 - mse: 1937423.6250 - val_loss: 1630531.8750 - val_mse: 1630531.8750\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 879082.1875 - mse: 879082.1875 - val_loss: 252422.2656 - val_mse: 252422.2656\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 327376.0312 - mse: 327376.0312 - val_loss: 67171.5859 - val_mse: 67171.5859\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 120733.9609 - mse: 120733.9609 - val_loss: 66306.8438 - val_mse: 66306.8438\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 66637.2188 - mse: 66637.2188 - val_loss: 79325.3438 - val_mse: 79325.3438\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 38260.9180 - mse: 38260.9180 - val_loss: 25725.0117 - val_mse: 25725.0117\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 18727.5371 - mse: 18727.5371 - val_loss: 18765.9590 - val_mse: 18765.9609\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 14468.8740 - mse: 14468.8740 - val_loss: 14375.9883 - val_mse: 14375.9883\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 11527.0859 - mse: 11527.0879 - val_loss: 11474.6084 - val_mse: 11474.6084\n",
            "mse: 11474.6083984375\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 314 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 34ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "mse: 0.024129103869199753\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 315 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 25ms/step - loss: 17018816.0000 - mse: 17018816.0000 - val_loss: 2029050.7500 - val_mse: 2029050.7500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2649939.7500 - mse: 2649939.7500 - val_loss: 1418565.8750 - val_mse: 1418565.8750\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 876792.3750 - mse: 876792.3750 - val_loss: 581937.8750 - val_mse: 581937.8750\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 291928.9062 - mse: 291928.9062 - val_loss: 237926.1719 - val_mse: 237926.1719\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 106458.9844 - mse: 106458.9844 - val_loss: 97792.9062 - val_mse: 97792.9062\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 38497.1406 - mse: 38497.1406 - val_loss: 19137.2832 - val_mse: 19137.2832\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 13333.9775 - mse: 13333.9775 - val_loss: 3205.9446 - val_mse: 3205.9446\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 5921.7632 - mse: 5921.7632 - val_loss: 4011.9971 - val_mse: 4011.9971\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3499.8333 - mse: 3499.8333 - val_loss: 2735.8584 - val_mse: 2735.8582\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2239.7969 - mse: 2239.7969 - val_loss: 1682.5065 - val_mse: 1682.5065\n",
            "mse: 1682.5064697265625\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 316 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 38ms/step - loss: 1.1100 - mse: 1.1100 - val_loss: 0.0760 - val_mse: 0.0760\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2121 - mse: 0.2121 - val_loss: 0.0688 - val_mse: 0.0688\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0897 - mse: 0.0897 - val_loss: 0.0429 - val_mse: 0.0429\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0393 - val_mse: 0.0393\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0276 - val_mse: 0.0276\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0278 - val_mse: 0.0278\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "mse: 0.025414234027266502\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 317 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 36ms/step - loss: 29119396.0000 - mse: 29119396.0000 - val_loss: 13801187.0000 - val_mse: 13801187.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 4696697.0000 - mse: 4696697.0000 - val_loss: 30884.1797 - val_mse: 30884.1797\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 977655.6875 - mse: 977655.6250 - val_loss: 885593.5000 - val_mse: 885593.5000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 413041.9375 - mse: 413041.9375 - val_loss: 182294.7188 - val_mse: 182294.7188\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 109692.7109 - mse: 109692.7266 - val_loss: 22321.4609 - val_mse: 22321.4609\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 50138.9648 - mse: 50138.9648 - val_loss: 60032.9609 - val_mse: 60032.9609\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 24054.2188 - mse: 24054.2188 - val_loss: 4528.8218 - val_mse: 4528.8218\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 10155.0010 - mse: 10155.0010 - val_loss: 5274.5908 - val_mse: 5274.5908\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 4046.0168 - mse: 4046.0168 - val_loss: 2661.4746 - val_mse: 2661.4746\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 2861.6780 - mse: 2861.6780 - val_loss: 2180.6206 - val_mse: 2180.6206\n",
            "mse: 2180.62060546875\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 318 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 36ms/step - loss: 0.4995 - mse: 0.4995 - val_loss: 0.4235 - val_mse: 0.4235\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3335 - mse: 0.3335 - val_loss: 0.2762 - val_mse: 0.2762\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2089 - mse: 0.2089 - val_loss: 0.1708 - val_mse: 0.1708\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 0.1023 - val_mse: 0.1023\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0731 - mse: 0.0731 - val_loss: 0.0634 - val_mse: 0.0634\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0438 - val_mse: 0.0438\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0352 - val_mse: 0.0352\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "mse: 0.03026607073843479\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 2\n",
            "models fitted: 319 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 29ms/step - loss: 7777538.0000 - mse: 7777538.0000 - val_loss: 2467045.0000 - val_mse: 2467045.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1103623.3750 - mse: 1103623.3750 - val_loss: 51091.4766 - val_mse: 51091.4766\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 114566.2266 - mse: 114566.2266 - val_loss: 213273.5000 - val_mse: 213273.5000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 243203.6719 - mse: 243203.6719 - val_loss: 161867.6562 - val_mse: 161867.6562\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 104319.7891 - mse: 104319.7891 - val_loss: 21968.4746 - val_mse: 21968.4766\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 40670.5273 - mse: 40670.5273 - val_loss: 22939.0176 - val_mse: 22939.0176\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 42893.5898 - mse: 42893.5898 - val_loss: 16890.8906 - val_mse: 16890.8906\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 30692.2559 - mse: 30692.2559 - val_loss: 14673.4346 - val_mse: 14673.4346\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 26037.6289 - mse: 26037.6309 - val_loss: 14834.6816 - val_mse: 14834.6816\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 22381.3770 - mse: 22381.3770 - val_loss: 11589.0967 - val_mse: 11589.0967\n",
            "mse: 11589.0966796875\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 2\n",
            "models fitted: 320 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 32ms/step - loss: 2.3775 - mse: 2.3775 - val_loss: 1.9033 - val_mse: 1.9033\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5163 - mse: 1.5163 - val_loss: 1.1643 - val_mse: 1.1643\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.8885 - mse: 0.8885 - val_loss: 0.6538 - val_mse: 0.6538\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4752 - mse: 0.4752 - val_loss: 0.3361 - val_mse: 0.3361\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2307 - mse: 0.2307 - val_loss: 0.1619 - val_mse: 0.1619\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1070 - mse: 0.1070 - val_loss: 0.0790 - val_mse: 0.0790\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0465 - val_mse: 0.0465\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0363 - val_mse: 0.0363\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "mse: 0.03355186805129051\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 2\n",
            "models fitted: 321 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 2008952.2500 - mse: 2008952.2500 - val_loss: 1527985.7500 - val_mse: 1527985.7500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 753925.8750 - mse: 753925.8750 - val_loss: 291019.5000 - val_mse: 291019.5000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 371324.1250 - mse: 371324.1250 - val_loss: 153918.1250 - val_mse: 153918.1250\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 176777.0781 - mse: 176777.0781 - val_loss: 110300.2109 - val_mse: 110300.2109\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100662.3438 - mse: 100662.3438 - val_loss: 68790.8438 - val_mse: 68790.8438\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 67575.3594 - mse: 67575.3594 - val_loss: 52482.5625 - val_mse: 52482.5625\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 48754.6875 - mse: 48754.6875 - val_loss: 36961.7188 - val_mse: 36961.7188\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 32075.0664 - mse: 32075.0664 - val_loss: 22066.9629 - val_mse: 22066.9629\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 18982.8359 - mse: 18982.8359 - val_loss: 14698.2871 - val_mse: 14698.2871\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 11926.4658 - mse: 11926.4658 - val_loss: 9440.5000 - val_mse: 9440.5000\n",
            "mse: 9440.5\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 2\n",
            "models fitted: 322 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 37ms/step - loss: 0.3158 - mse: 0.3158 - val_loss: 0.0350 - val_mse: 0.0350\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0757 - val_mse: 0.0757\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0394 - val_mse: 0.0394\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0293 - val_mse: 0.0293\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0273 - val_mse: 0.0273\n",
            "mse: 0.0273442305624485\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 2\n",
            "models fitted: 323 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 41ms/step - loss: 207311.8438 - mse: 207311.8438 - val_loss: 54102.7422 - val_mse: 54102.7422\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 52388.7852 - mse: 52388.7852 - val_loss: 23886.1719 - val_mse: 23886.1719\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 18498.9688 - mse: 18498.9688 - val_loss: 6299.8101 - val_mse: 6299.8101\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 6563.0703 - mse: 6563.0703 - val_loss: 4129.1553 - val_mse: 4129.1553\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2376.3655 - mse: 2376.3655 - val_loss: 2586.8359 - val_mse: 2586.8359\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1196.0604 - mse: 1196.0604 - val_loss: 1222.5992 - val_mse: 1222.5992\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 800.4130 - mse: 800.4130 - val_loss: 911.1851 - val_mse: 911.1851\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 492.8671 - mse: 492.8671 - val_loss: 784.3598 - val_mse: 784.3598\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 428.6749 - mse: 428.6749 - val_loss: 619.5199 - val_mse: 619.5199\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 443.3858 - mse: 443.3858 - val_loss: 819.0144 - val_mse: 819.0143\n",
            "mse: 819.014404296875\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 2\n",
            "models fitted: 324 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0786 - mse: 0.0786 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0361 - val_mse: 0.0361\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0431 - val_mse: 0.0431\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0495 - val_mse: 0.0495\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0394 - val_mse: 0.0394\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0358 - val_mse: 0.0358\n",
            "mse: 0.03577582538127899\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 325 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 4248074.5000 - mse: 4248074.5000 - val_loss: 336.2658 - val_mse: 336.2658\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3729.6094 - mse: 3729.6094 - val_loss: 118.8309 - val_mse: 118.8309\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 127.9766 - mse: 127.9766 - val_loss: 109.6761 - val_mse: 109.6761\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 82.9592 - mse: 82.9592 - val_loss: 112.8718 - val_mse: 112.8718\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 77.9383 - mse: 77.9383 - val_loss: 90.1581 - val_mse: 90.1581\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 77.2635 - mse: 77.2635 - val_loss: 31.8834 - val_mse: 31.8834\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 33.0962 - mse: 33.0962 - val_loss: 57.3157 - val_mse: 57.3157\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 57.0827 - mse: 57.0827 - val_loss: 17.0815 - val_mse: 17.0815\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 78.8706 - mse: 78.8706 - val_loss: 21.4905 - val_mse: 21.4905\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 55.3803 - mse: 55.3803 - val_loss: 10.9915 - val_mse: 10.9915\n",
            "mse: 10.991494178771973\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 326 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1152 - mse: 0.1152 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0370 - val_mse: 0.0370\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0423 - val_mse: 0.0423\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0344 - val_mse: 0.0344\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0360 - val_mse: 0.0360\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "mse: 0.03287618234753609\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 327 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 7534681.0000 - mse: 7534681.0000 - val_loss: 666.9930 - val_mse: 666.9930\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 165.3605 - mse: 165.3606 - val_loss: 12.2900 - val_mse: 12.2900\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 39.0114 - mse: 39.0114 - val_loss: 13.3755 - val_mse: 13.3755\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 13.3895 - mse: 13.3895 - val_loss: 9.3761 - val_mse: 9.3761\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 24.2706 - mse: 24.2706 - val_loss: 7.0572 - val_mse: 7.0572\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 14.3513 - mse: 14.3513 - val_loss: 7.1130 - val_mse: 7.1130\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 97.6532 - mse: 97.6532 - val_loss: 652.2999 - val_mse: 652.2999\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 68.4098 - mse: 68.4098 - val_loss: 11.2199 - val_mse: 11.2199\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 23.3978 - mse: 23.3978 - val_loss: 204.8841 - val_mse: 204.8841\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 21.8038 - mse: 21.8038 - val_loss: 4.5278 - val_mse: 4.5278\n",
            "mse: 4.527768135070801\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 328 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 15ms/step - loss: 0.7273 - mse: 0.7273 - val_loss: 0.0357 - val_mse: 0.0357\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0383 - val_mse: 0.0383\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0374 - val_mse: 0.0374\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 15ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0382 - val_mse: 0.0382\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 2s 15ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0368 - val_mse: 0.0368\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0412 - val_mse: 0.0412\n",
            "mse: 0.04122858867049217\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 329 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 9ms/step - loss: 73346256.0000 - mse: 73346256.0000 - val_loss: 2680.4382 - val_mse: 2680.4382\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1440.0208 - mse: 1440.0208 - val_loss: 124.4041 - val_mse: 124.4041\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 90.9142 - mse: 90.9142 - val_loss: 16.0054 - val_mse: 16.0054\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 35.0360 - mse: 35.0360 - val_loss: 14.0005 - val_mse: 14.0005\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 177.6404 - mse: 177.6404 - val_loss: 81.1135 - val_mse: 81.1135\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 35.8404 - mse: 35.8404 - val_loss: 5.4938 - val_mse: 5.4938\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 11.2571 - mse: 11.2571 - val_loss: 4.2508 - val_mse: 4.2508\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 22.2110 - mse: 22.2110 - val_loss: 132.8908 - val_mse: 132.8907\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 43.6029 - mse: 43.6029 - val_loss: 17.1300 - val_mse: 17.1300\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 14.7985 - mse: 14.7985 - val_loss: 12.0525 - val_mse: 12.0525\n",
            "mse: 12.05250072479248\n",
            "dropout: 0.1 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 330 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.1444 - mse: 0.1444 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0279 - val_mse: 0.0279\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0261 - val_mse: 0.0261\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0371 - val_mse: 0.0371\n",
            "mse: 0.037074558436870575\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 331 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 171596.7500 - mse: 171596.7500 - val_loss: 838.0846 - val_mse: 838.0846\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1144.8702 - mse: 1144.8702 - val_loss: 352.4120 - val_mse: 352.4120\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1629.6066 - mse: 1629.6066 - val_loss: 456.8547 - val_mse: 456.8547\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 4849.3911 - mse: 4849.3911 - val_loss: 1286.5609 - val_mse: 1286.5609\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 723.9333 - mse: 723.9333 - val_loss: 197.7793 - val_mse: 197.7793\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 225.6235 - mse: 225.6235 - val_loss: 62.8949 - val_mse: 62.8949\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 440.6020 - mse: 440.6020 - val_loss: 270.3651 - val_mse: 270.3651\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 324.6552 - mse: 324.6552 - val_loss: 56.6007 - val_mse: 56.6007\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 312.6064 - mse: 312.6064 - val_loss: 118.3285 - val_mse: 118.3285\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 267.6002 - mse: 267.6002 - val_loss: 30.6090 - val_mse: 30.6090\n",
            "mse: 30.608970642089844\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 332 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1229 - mse: 0.1229 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0291 - val_mse: 0.0291\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0364 - val_mse: 0.0364\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "mse: 0.025636689737439156\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 333 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 9ms/step - loss: 584454.6250 - mse: 584454.6250 - val_loss: 1790.1337 - val_mse: 1790.1337\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 8743.0918 - mse: 8743.0918 - val_loss: 824.8185 - val_mse: 824.8185\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2200.7698 - mse: 2200.7698 - val_loss: 1130.9491 - val_mse: 1130.9491\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 965.2350 - mse: 965.2350 - val_loss: 201.5118 - val_mse: 201.5118\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 643.8465 - mse: 643.8465 - val_loss: 110.4301 - val_mse: 110.4301\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 104.6922 - mse: 104.6922 - val_loss: 79.9025 - val_mse: 79.9025\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 79.0298 - mse: 79.0298 - val_loss: 64.4329 - val_mse: 64.4329\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 62.2430 - mse: 62.2430 - val_loss: 51.5596 - val_mse: 51.5596\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 100.1271 - mse: 100.1271 - val_loss: 113.0065 - val_mse: 113.0065\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 73.2816 - mse: 73.2816 - val_loss: 39.6011 - val_mse: 39.6011\n",
            "mse: 39.60112762451172\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 334 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 15ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0278 - val_mse: 0.0278\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0295 - val_mse: 0.0295\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0417 - val_mse: 0.0417\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "mse: 0.03079124726355076\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 335 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 9ms/step - loss: 723608.6250 - mse: 723608.6250 - val_loss: 45.0976 - val_mse: 45.0976\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 79.7773 - mse: 79.7773 - val_loss: 18.4353 - val_mse: 18.4353\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 335.5751 - mse: 335.5751 - val_loss: 44.5565 - val_mse: 44.5565\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 15ms/step - loss: 581.3069 - mse: 581.3069 - val_loss: 62.7506 - val_mse: 62.7506\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 2s 15ms/step - loss: 512.0404 - mse: 512.0404 - val_loss: 12.4857 - val_mse: 12.4857\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 45.4128 - mse: 45.4128 - val_loss: 30.1383 - val_mse: 30.1383\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 2s 16ms/step - loss: 1063.9111 - mse: 1063.9111 - val_loss: 122.0621 - val_mse: 122.0621\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 256.1839 - mse: 256.1839 - val_loss: 39.0993 - val_mse: 39.0993\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 843.0274 - mse: 843.0274 - val_loss: 422.2253 - val_mse: 422.2253\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 168.8612 - mse: 168.8612 - val_loss: 15.7975 - val_mse: 15.7975\n",
            "mse: 15.797451972961426\n",
            "dropout: 0.1 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 336 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 7ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0301 - val_mse: 0.0301\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0287 - val_mse: 0.0287\n",
            "mse: 0.02873258665204048\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 337 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 28697.6152 - mse: 28697.6152 - val_loss: 909.8058 - val_mse: 909.8058\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 923.7275 - mse: 923.7275 - val_loss: 502.2721 - val_mse: 502.2721\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 484.6828 - mse: 484.6828 - val_loss: 317.1369 - val_mse: 317.1369\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 316.8797 - mse: 316.8797 - val_loss: 233.2671 - val_mse: 233.2671\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 222.9370 - mse: 222.9370 - val_loss: 173.0645 - val_mse: 173.0645\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 176.7141 - mse: 176.7141 - val_loss: 151.5798 - val_mse: 151.5798\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 160.0119 - mse: 160.0119 - val_loss: 142.1421 - val_mse: 142.1421\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 134.2168 - mse: 134.2168 - val_loss: 109.9101 - val_mse: 109.9101\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 114.0396 - mse: 114.0396 - val_loss: 116.7650 - val_mse: 116.7650\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 95.5617 - mse: 95.5617 - val_loss: 89.5043 - val_mse: 89.5043\n",
            "mse: 89.5042724609375\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 338 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2846 - mse: 0.2846 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0273 - val_mse: 0.0273\n",
            "mse: 0.02731233462691307\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 339 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 823161.0000 - mse: 823161.0000 - val_loss: 10231.9971 - val_mse: 10231.9971\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 5801.8013 - mse: 5801.8013 - val_loss: 2230.7229 - val_mse: 2230.7229\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 1782.7213 - mse: 1782.7213 - val_loss: 636.9901 - val_mse: 636.9901\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 544.7930 - mse: 544.7930 - val_loss: 200.0078 - val_mse: 200.0078\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 349.9884 - mse: 349.9884 - val_loss: 158.5014 - val_mse: 158.5014\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 243.3950 - mse: 243.3950 - val_loss: 132.1014 - val_mse: 132.1014\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 202.9495 - mse: 202.9495 - val_loss: 109.3821 - val_mse: 109.3821\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 178.5872 - mse: 178.5872 - val_loss: 92.1436 - val_mse: 92.1436\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 173.7943 - mse: 173.7943 - val_loss: 88.5074 - val_mse: 88.5074\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 134.4376 - mse: 134.4376 - val_loss: 86.7297 - val_mse: 86.7297\n",
            "mse: 86.72972869873047\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 340 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 10ms/step - loss: 0.1009 - mse: 0.1009 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "mse: 0.020281124860048294\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 341 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 2s 10ms/step - loss: 1343585.1250 - mse: 1343585.1250 - val_loss: 1464.9363 - val_mse: 1464.9363\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2051.8418 - mse: 2051.8418 - val_loss: 493.0674 - val_mse: 493.0674\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3240.5049 - mse: 3240.5049 - val_loss: 142.5551 - val_mse: 142.5551\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 162.3843 - mse: 162.3843 - val_loss: 130.3256 - val_mse: 130.3256\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 494.7762 - mse: 494.7762 - val_loss: 93.2114 - val_mse: 93.2114\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 159.6168 - mse: 159.6168 - val_loss: 87.5057 - val_mse: 87.5057\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 162.8041 - mse: 162.8041 - val_loss: 82.9705 - val_mse: 82.9705\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 153.5701 - mse: 153.5701 - val_loss: 59.5589 - val_mse: 59.5589\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 731.3425 - mse: 731.3425 - val_loss: 57.4213 - val_mse: 57.4213\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 152.9909 - mse: 152.9909 - val_loss: 41.8550 - val_mse: 41.8550\n",
            "mse: 41.85502243041992\n",
            "dropout: 0.1 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 342 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.1737 - mse: 0.1737 - val_loss: 0.0663 - val_mse: 0.0663\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0373 - val_mse: 0.0373\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "mse: 0.0324094295501709\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 343 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 42343828.0000 - mse: 42343828.0000 - val_loss: 566821.7500 - val_mse: 566821.6875\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 172802.3750 - mse: 172802.3750 - val_loss: 67651.0625 - val_mse: 67651.0547\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 18653.5059 - mse: 18653.5059 - val_loss: 3551.8442 - val_mse: 3551.8442\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 2434.2634 - mse: 2434.2634 - val_loss: 750.0071 - val_mse: 750.0071\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 447.2791 - mse: 447.2791 - val_loss: 145.3491 - val_mse: 145.3491\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 134.9766 - mse: 134.9766 - val_loss: 110.2781 - val_mse: 110.2781\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 106.6869 - mse: 106.6869 - val_loss: 60.1723 - val_mse: 60.1723\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 77.9366 - mse: 77.9366 - val_loss: 57.1540 - val_mse: 57.1540\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 67.2781 - mse: 67.2781 - val_loss: 45.1873 - val_mse: 45.1873\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 58.9034 - mse: 58.9034 - val_loss: 43.6149 - val_mse: 43.6149\n",
            "mse: 43.61490249633789\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 344 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 0.8304 - mse: 0.8304 - val_loss: 0.1163 - val_mse: 0.1163\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0642 - mse: 0.0642 - val_loss: 0.0532 - val_mse: 0.0532\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0407 - val_mse: 0.0407\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "mse: 0.03421446681022644\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 345 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 109680744.0000 - mse: 109680744.0000 - val_loss: 114007.6406 - val_mse: 114007.6406\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 25405.3574 - mse: 25405.3574 - val_loss: 42257.0820 - val_mse: 42257.0859\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 7917.9272 - mse: 7917.9277 - val_loss: 98.4582 - val_mse: 98.4582\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 358.2804 - mse: 358.2804 - val_loss: 238.7967 - val_mse: 238.7967\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 101.5340 - mse: 101.5340 - val_loss: 158.2242 - val_mse: 158.2242\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 100.0116 - mse: 100.0116 - val_loss: 92.4076 - val_mse: 92.4076\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 121.6330 - mse: 121.6330 - val_loss: 93.6195 - val_mse: 93.6195\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 160.3069 - mse: 160.3069 - val_loss: 75.1736 - val_mse: 75.1736\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 79.9047 - mse: 79.9047 - val_loss: 82.8764 - val_mse: 82.8764\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 87.2153 - mse: 87.2153 - val_loss: 73.1019 - val_mse: 73.1019\n",
            "mse: 73.10185241699219\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 346 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 4.0527 - mse: 4.0527 - val_loss: 0.0634 - val_mse: 0.0634\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1276 - mse: 0.1276 - val_loss: 0.0393 - val_mse: 0.0393\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "mse: 0.03474631533026695\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 347 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 29ms/step - loss: 477481216.0000 - mse: 477481184.0000 - val_loss: 22895.6484 - val_mse: 22895.6484\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 3573.1313 - mse: 3573.1313 - val_loss: 249.7770 - val_mse: 249.7770\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 198.1137 - mse: 198.1137 - val_loss: 46.9672 - val_mse: 46.9672\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 396.3345 - mse: 396.3345 - val_loss: 25.1484 - val_mse: 25.1484\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 148.7762 - mse: 148.7762 - val_loss: 121.7512 - val_mse: 121.7512\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 120.0959 - mse: 120.0959 - val_loss: 123.7841 - val_mse: 123.7841\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 170.0771 - mse: 170.0771 - val_loss: 277.9537 - val_mse: 277.9537\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 145.2252 - mse: 145.2252 - val_loss: 35.6092 - val_mse: 35.6092\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 31.8962 - mse: 31.8962 - val_loss: 9.0862 - val_mse: 9.0862\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 17.9005 - mse: 17.9005 - val_loss: 7.4267 - val_mse: 7.4267\n",
            "mse: 7.426661014556885\n",
            "dropout: 0.1 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 348 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 13ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0261 - val_mse: 0.0261\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "mse: 0.024382825940847397\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 349 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 2s 17ms/step - loss: 15611834.0000 - mse: 15611834.0000 - val_loss: 1849273.0000 - val_mse: 1849273.0000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 546544.9375 - mse: 546544.9375 - val_loss: 18553.3066 - val_mse: 18553.3066\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 52992.1680 - mse: 52992.1680 - val_loss: 36646.3008 - val_mse: 36646.3008\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 12971.6201 - mse: 12971.6201 - val_loss: 9706.0400 - val_mse: 9706.0400\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 7317.0879 - mse: 7317.0879 - val_loss: 6010.2632 - val_mse: 6010.2632\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 5520.7090 - mse: 5520.7090 - val_loss: 4938.9180 - val_mse: 4938.9180\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 4922.7642 - mse: 4922.7642 - val_loss: 4516.8198 - val_mse: 4516.8198\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 4469.8076 - mse: 4469.8076 - val_loss: 4011.1714 - val_mse: 4011.1714\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 4073.9468 - mse: 4073.9468 - val_loss: 3782.5544 - val_mse: 3782.5544\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 3644.8865 - mse: 3644.8865 - val_loss: 3541.4316 - val_mse: 3541.4316\n",
            "mse: 3541.431640625\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 350 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 0.7229 - mse: 0.7229 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0447 - val_mse: 0.0447\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0362 - val_mse: 0.0362\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "mse: 0.029582617804408073\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 351 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 28ms/step - loss: 1189123.3750 - mse: 1189123.3750 - val_loss: 203863.9375 - val_mse: 203863.9375\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 44139.9883 - mse: 44139.9883 - val_loss: 6701.8770 - val_mse: 6701.8770\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 4971.2275 - mse: 4971.2275 - val_loss: 996.4487 - val_mse: 996.4487\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1120.8507 - mse: 1120.8507 - val_loss: 601.8065 - val_mse: 601.8065\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 496.5867 - mse: 496.5867 - val_loss: 463.1935 - val_mse: 463.1935\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 301.5580 - mse: 301.5580 - val_loss: 205.6268 - val_mse: 205.6268\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 192.8569 - mse: 192.8569 - val_loss: 144.6530 - val_mse: 144.6530\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 125.6899 - mse: 125.6899 - val_loss: 99.5516 - val_mse: 99.5516\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 96.2911 - mse: 96.2911 - val_loss: 89.7326 - val_mse: 89.7326\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 84.9463 - mse: 84.9463 - val_loss: 86.5635 - val_mse: 86.5635\n",
            "mse: 86.56354522705078\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 352 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 0.1682 - mse: 0.1682 - val_loss: 0.0849 - val_mse: 0.0849\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0367 - val_mse: 0.0367\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0278 - val_mse: 0.0278\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "mse: 0.024549396708607674\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 353 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 21ms/step - loss: 6029757.5000 - mse: 6029757.5000 - val_loss: 458799.3125 - val_mse: 458799.3125\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 108255.6875 - mse: 108255.6875 - val_loss: 15938.9902 - val_mse: 15938.9912\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 10309.1572 - mse: 10309.1572 - val_loss: 2767.2671 - val_mse: 2767.2671\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 1029.0082 - mse: 1029.0082 - val_loss: 521.2313 - val_mse: 521.2313\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 187.4348 - mse: 187.4348 - val_loss: 91.9245 - val_mse: 91.9245\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 48.5360 - mse: 48.5360 - val_loss: 31.9742 - val_mse: 31.9742\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 29.7832 - mse: 29.7832 - val_loss: 23.5160 - val_mse: 23.5160\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 28.7633 - mse: 28.7633 - val_loss: 23.2719 - val_mse: 23.2719\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 22.9464 - mse: 22.9464 - val_loss: 21.7555 - val_mse: 21.7555\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 19.4475 - mse: 19.4475 - val_loss: 23.1400 - val_mse: 23.1400\n",
            "mse: 23.139986038208008\n",
            "dropout: 0.1 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 354 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "mse: 0.03143835440278053\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 355 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 226853.4375 - mse: 226853.4375 - val_loss: 84881.7656 - val_mse: 84881.7656\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 63319.1602 - mse: 63319.1602 - val_loss: 38748.1406 - val_mse: 38748.1406\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 38569.9258 - mse: 38569.9258 - val_loss: 21925.3633 - val_mse: 21925.3633\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 27701.0605 - mse: 27701.0605 - val_loss: 18319.8711 - val_mse: 18319.8711\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 20315.8164 - mse: 20315.8164 - val_loss: 13279.8135 - val_mse: 13279.8135\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 14432.5498 - mse: 14432.5498 - val_loss: 11483.2148 - val_mse: 11483.2148\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 12057.8232 - mse: 12057.8223 - val_loss: 10022.7324 - val_mse: 10022.7324\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 9591.3555 - mse: 9591.3555 - val_loss: 8376.2842 - val_mse: 8376.2842\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 8626.1523 - mse: 8626.1523 - val_loss: 8331.8213 - val_mse: 8331.8213\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 7390.0171 - mse: 7390.0171 - val_loss: 6293.6211 - val_mse: 6293.6201\n",
            "mse: 6293.62109375\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 356 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 0.6996 - mse: 0.6996 - val_loss: 0.2803 - val_mse: 0.2803\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1164 - mse: 0.1164 - val_loss: 0.0393 - val_mse: 0.0393\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "mse: 0.031714797019958496\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 357 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 3052402.2500 - mse: 3052402.2500 - val_loss: 769565.8125 - val_mse: 769565.8125\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 231515.9219 - mse: 231515.9219 - val_loss: 95551.4922 - val_mse: 95551.4922\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 29923.9082 - mse: 29923.9082 - val_loss: 11967.4033 - val_mse: 11967.4033\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 6728.6133 - mse: 6728.6133 - val_loss: 4705.3687 - val_mse: 4705.3687\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 3142.5686 - mse: 3142.5686 - val_loss: 2156.5818 - val_mse: 2156.5818\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 1873.4617 - mse: 1873.4615 - val_loss: 1015.9312 - val_mse: 1015.9312\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1149.0636 - mse: 1149.0636 - val_loss: 773.3806 - val_mse: 773.3806\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 882.5261 - mse: 882.5261 - val_loss: 736.0992 - val_mse: 736.0992\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 754.3737 - mse: 754.3737 - val_loss: 629.4102 - val_mse: 629.4102\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 671.9549 - mse: 671.9549 - val_loss: 542.6145 - val_mse: 542.6145\n",
            "mse: 542.614501953125\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 358 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 23ms/step - loss: 0.1627 - mse: 0.1627 - val_loss: 0.0725 - val_mse: 0.0725\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0421 - val_mse: 0.0421\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "mse: 0.028910094872117043\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 359 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 149753.5781 - mse: 149753.5781 - val_loss: 44749.3789 - val_mse: 44749.3789\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 15719.3926 - mse: 15719.3926 - val_loss: 4577.8687 - val_mse: 4577.8687\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 2615.6394 - mse: 2615.6394 - val_loss: 885.3942 - val_mse: 885.3942\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1010.7722 - mse: 1010.7722 - val_loss: 218.1371 - val_mse: 218.1371\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 463.3152 - mse: 463.3152 - val_loss: 182.2260 - val_mse: 182.2260\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 730.4434 - mse: 730.4434 - val_loss: 130.5555 - val_mse: 130.5555\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 1050.4563 - mse: 1050.4563 - val_loss: 138.6091 - val_mse: 138.6091\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 833.5657 - mse: 833.5659 - val_loss: 102.0588 - val_mse: 102.0588\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 884.4199 - mse: 884.4199 - val_loss: 239.1403 - val_mse: 239.1403\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 1525.6342 - mse: 1525.6342 - val_loss: 236.1463 - val_mse: 236.1463\n",
            "mse: 236.14630126953125\n",
            "dropout: 0.1 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 360 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 30ms/step - loss: 0.1941 - mse: 0.1941 - val_loss: 0.0723 - val_mse: 0.0723\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0673 - mse: 0.0673 - val_loss: 0.0500 - val_mse: 0.0500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0450 - val_mse: 0.0450\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "mse: 0.03278778865933418\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 361 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 24ms/step - loss: 19612928.0000 - mse: 19612928.0000 - val_loss: 114114.0859 - val_mse: 114114.0859\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 285096.8438 - mse: 285096.8438 - val_loss: 10863.7754 - val_mse: 10863.7754\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 19102.0625 - mse: 19102.0625 - val_loss: 15402.1172 - val_mse: 15402.1172\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6261.0518 - mse: 6261.0518 - val_loss: 2061.5491 - val_mse: 2061.5491\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2541.9978 - mse: 2541.9978 - val_loss: 538.6194 - val_mse: 538.6194\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 959.8749 - mse: 959.8749 - val_loss: 1181.7083 - val_mse: 1181.7081\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 583.2620 - mse: 583.2620 - val_loss: 367.2679 - val_mse: 367.2679\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 328.3866 - mse: 328.3866 - val_loss: 181.7802 - val_mse: 181.7802\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 230.8020 - mse: 230.8020 - val_loss: 180.4502 - val_mse: 180.4502\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 180.2664 - mse: 180.2664 - val_loss: 168.0977 - val_mse: 168.0977\n",
            "mse: 168.09765625\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 362 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 117ms/step - loss: 1.9320 - mse: 1.9320 - val_loss: 0.1272 - val_mse: 0.1272\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2081 - mse: 0.2081 - val_loss: 0.0473 - val_mse: 0.0473\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0767 - mse: 0.0767 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "mse: 0.033741846680641174\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 363 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 43ms/step - loss: 190835440.0000 - mse: 190835440.0000 - val_loss: 1540508.2500 - val_mse: 1540508.2500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 831413.3750 - mse: 831413.3750 - val_loss: 517919.0312 - val_mse: 517918.9688\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 202306.8438 - mse: 202306.8438 - val_loss: 39701.8477 - val_mse: 39701.8477\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 71390.1094 - mse: 71390.1094 - val_loss: 71431.3594 - val_mse: 71431.3594\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 28995.1680 - mse: 28995.1680 - val_loss: 2894.1753 - val_mse: 2894.1753\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 9250.4229 - mse: 9250.4229 - val_loss: 7323.3276 - val_mse: 7323.3276\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3006.6619 - mse: 3006.6619 - val_loss: 1976.0906 - val_mse: 1976.0906\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1261.9708 - mse: 1261.9708 - val_loss: 98.3283 - val_mse: 98.3283\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 454.9549 - mse: 454.9549 - val_loss: 323.9540 - val_mse: 323.9540\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 234.1661 - mse: 234.1661 - val_loss: 187.2374 - val_mse: 187.2374\n",
            "mse: 187.2374267578125\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 364 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 2s 68ms/step - loss: 6.8709 - mse: 6.8709 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.5379 - mse: 0.5379 - val_loss: 0.0537 - val_mse: 0.0537\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.2030 - mse: 0.2030 - val_loss: 0.0415 - val_mse: 0.0415\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.0909 - mse: 0.0909 - val_loss: 0.0363 - val_mse: 0.0363\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0396 - val_mse: 0.0396\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "mse: 0.03329666331410408\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 365 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 42ms/step - loss: 971361152.0000 - mse: 971361216.0000 - val_loss: 176620.8906 - val_mse: 176620.8906\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 315675.4688 - mse: 315675.4688 - val_loss: 5410.8354 - val_mse: 5410.8354\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 15321.4775 - mse: 15321.4775 - val_loss: 845.2756 - val_mse: 845.2756\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 6524.9150 - mse: 6524.9150 - val_loss: 1410.7101 - val_mse: 1410.7101\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1685.8096 - mse: 1685.8096 - val_loss: 498.6071 - val_mse: 498.6071\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 718.8904 - mse: 718.8904 - val_loss: 290.0688 - val_mse: 290.0688\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 157.1973 - mse: 157.1973 - val_loss: 140.6865 - val_mse: 140.6865\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 105.0065 - mse: 105.0065 - val_loss: 83.2636 - val_mse: 83.2636\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 62.4113 - mse: 62.4113 - val_loss: 42.6112 - val_mse: 42.6112\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 37.2526 - mse: 37.2526 - val_loss: 24.2830 - val_mse: 24.2830\n",
            "mse: 24.283021926879883\n",
            "dropout: 0.1 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 366 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 0.6997 - mse: 0.6997 - val_loss: 0.0453 - val_mse: 0.0453\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 0.1381 - val_mse: 0.1381\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0529 - val_mse: 0.0529\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "mse: 0.03190658986568451\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 367 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 29ms/step - loss: 636608.7500 - mse: 636608.7500 - val_loss: 186623.4062 - val_mse: 186623.4062\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 113505.6406 - mse: 113505.6406 - val_loss: 43876.2812 - val_mse: 43876.2812\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 32673.7734 - mse: 32673.7734 - val_loss: 3448.5435 - val_mse: 3448.5435\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 12027.6973 - mse: 12027.6973 - val_loss: 2664.5806 - val_mse: 2664.5806\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5369.2930 - mse: 5369.2935 - val_loss: 5176.4194 - val_mse: 5176.4194\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2370.2451 - mse: 2370.2451 - val_loss: 596.5085 - val_mse: 596.5085\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1146.0499 - mse: 1146.0499 - val_loss: 1032.9225 - val_mse: 1032.9225\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 665.5735 - mse: 665.5735 - val_loss: 378.3705 - val_mse: 378.3705\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 420.8333 - mse: 420.8333 - val_loss: 322.4652 - val_mse: 322.4652\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 317.8442 - mse: 317.8442 - val_loss: 298.4097 - val_mse: 298.4097\n",
            "mse: 298.40972900390625\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 368 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0668 - val_mse: 0.0668\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0394 - val_mse: 0.0394\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0273 - val_mse: 0.0273\n",
            "mse: 0.027256662026047707\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 369 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 32ms/step - loss: 4190451.5000 - mse: 4190451.5000 - val_loss: 147804.6094 - val_mse: 147804.6094\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 424524.5625 - mse: 424524.5625 - val_loss: 154511.6250 - val_mse: 154511.6250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 95468.2109 - mse: 95468.2109 - val_loss: 108034.2500 - val_mse: 108034.2500\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 43664.6992 - mse: 43664.6992 - val_loss: 5230.6816 - val_mse: 5230.6816\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16454.7949 - mse: 16454.7949 - val_loss: 3472.0874 - val_mse: 3472.0874\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5688.0425 - mse: 5688.0425 - val_loss: 5307.3931 - val_mse: 5307.3931\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2501.2732 - mse: 2501.2727 - val_loss: 2971.5559 - val_mse: 2971.5557\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1290.6443 - mse: 1290.6443 - val_loss: 1016.3297 - val_mse: 1016.3297\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 551.4550 - mse: 551.4550 - val_loss: 533.2863 - val_mse: 533.2863\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 393.3276 - mse: 393.3276 - val_loss: 367.9828 - val_mse: 367.9828\n",
            "mse: 367.9827575683594\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 370 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 39ms/step - loss: 0.7021 - mse: 0.7021 - val_loss: 0.1413 - val_mse: 0.1413\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1765 - mse: 0.1765 - val_loss: 0.1082 - val_mse: 0.1082\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0882 - mse: 0.0882 - val_loss: 0.0837 - val_mse: 0.0837\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0456 - val_mse: 0.0456\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0391 - val_mse: 0.0391\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "mse: 0.029022326692938805\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 371 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 39ms/step - loss: 11353042.0000 - mse: 11353042.0000 - val_loss: 2660650.0000 - val_mse: 2660650.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 722780.6875 - mse: 722780.6875 - val_loss: 398133.3438 - val_mse: 398133.3438\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 119695.3203 - mse: 119695.3203 - val_loss: 57101.4492 - val_mse: 57101.4492\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 23048.3633 - mse: 23048.3633 - val_loss: 16822.5781 - val_mse: 16822.5801\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 8901.0801 - mse: 8901.0801 - val_loss: 4517.6851 - val_mse: 4517.6851\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 2883.8230 - mse: 2883.8230 - val_loss: 1832.4054 - val_mse: 1832.4054\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1292.1255 - mse: 1292.1255 - val_loss: 762.5665 - val_mse: 762.5665\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 394.5358 - mse: 394.5358 - val_loss: 69.6017 - val_mse: 69.6017\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 235.1492 - mse: 235.1492 - val_loss: 118.6524 - val_mse: 118.6524\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 100.8511 - mse: 100.8511 - val_loss: 45.0670 - val_mse: 45.0670\n",
            "mse: 45.06697082519531\n",
            "dropout: 0.1 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 372 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 25ms/step - loss: 0.8699 - mse: 0.8699 - val_loss: 0.7740 - val_mse: 0.7740\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6541 - mse: 0.6541 - val_loss: 0.5753 - val_mse: 0.5753\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4769 - mse: 0.4769 - val_loss: 0.4155 - val_mse: 0.4155\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3373 - mse: 0.3373 - val_loss: 0.2929 - val_mse: 0.2929\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2327 - mse: 0.2327 - val_loss: 0.2025 - val_mse: 0.2025\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1575 - mse: 0.1575 - val_loss: 0.1391 - val_mse: 0.1391\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1061 - mse: 0.1061 - val_loss: 0.0964 - val_mse: 0.0964\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0729 - mse: 0.0729 - val_loss: 0.0691 - val_mse: 0.0691\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0525 - val_mse: 0.0525\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0430 - val_mse: 0.0430\n",
            "mse: 0.042993661016225815\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 373 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 502092.6250 - mse: 502092.6250 - val_loss: 436945.4688 - val_mse: 436945.4688\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 198039.3750 - mse: 198039.3750 - val_loss: 149022.8906 - val_mse: 149022.8906\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 143088.5781 - mse: 143088.5781 - val_loss: 118593.7422 - val_mse: 118593.7422\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 109940.8750 - mse: 109940.8750 - val_loss: 90231.6953 - val_mse: 90231.6953\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 86714.6953 - mse: 86714.6953 - val_loss: 73581.4688 - val_mse: 73581.4688\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 64995.2227 - mse: 64995.2227 - val_loss: 52720.9258 - val_mse: 52720.9258\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 47198.5039 - mse: 47198.5039 - val_loss: 40221.2227 - val_mse: 40221.2227\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 33354.8672 - mse: 33354.8672 - val_loss: 30072.9336 - val_mse: 30072.9336\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 27304.7773 - mse: 27304.7773 - val_loss: 26878.9219 - val_mse: 26878.9219\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 22587.8203 - mse: 22587.8203 - val_loss: 21553.1484 - val_mse: 21553.1484\n",
            "mse: 21553.1484375\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 374 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 28ms/step - loss: 0.1744 - mse: 0.1744 - val_loss: 0.0787 - val_mse: 0.0787\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0383 - val_mse: 0.0383\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.033034466207027435\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 375 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 107ms/step - loss: 18081304.0000 - mse: 18081304.0000 - val_loss: 1907950.8750 - val_mse: 1907950.8750\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 626877.1875 - mse: 626877.1875 - val_loss: 1250284.7500 - val_mse: 1250284.7500\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1103633.1250 - mse: 1103633.1250 - val_loss: 350636.8125 - val_mse: 350636.8125\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99043.5703 - mse: 99043.5703 - val_loss: 104505.9609 - val_mse: 104505.9609\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 120091.1094 - mse: 120091.1094 - val_loss: 45936.3047 - val_mse: 45936.3047\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 16155.2607 - mse: 16155.2607 - val_loss: 18236.3340 - val_mse: 18236.3340\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 18725.0898 - mse: 18725.0898 - val_loss: 8873.3828 - val_mse: 8873.3828\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4745.5435 - mse: 4745.5435 - val_loss: 5460.2383 - val_mse: 5460.2383\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4807.3042 - mse: 4807.3042 - val_loss: 2693.4019 - val_mse: 2693.4019\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2528.9314 - mse: 2528.9314 - val_loss: 2218.4685 - val_mse: 2218.4685\n",
            "mse: 2218.468505859375\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 376 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 40ms/step - loss: 0.3311 - mse: 0.3311 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0963 - val_mse: 0.0963\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0374 - val_mse: 0.0374\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "mse: 0.03196530044078827\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 377 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 54ms/step - loss: 660773.3125 - mse: 660773.2500 - val_loss: 472651.5000 - val_mse: 472651.5000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 172932.3594 - mse: 172932.3594 - val_loss: 3450.8877 - val_mse: 3450.8877\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 43456.5000 - mse: 43456.5000 - val_loss: 48938.4062 - val_mse: 48938.4062\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 22072.8340 - mse: 22072.8340 - val_loss: 1920.0225 - val_mse: 1920.0225\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5677.9102 - mse: 5677.9092 - val_loss: 6833.5718 - val_mse: 6833.5718\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 3076.9204 - mse: 3076.9204 - val_loss: 1424.5023 - val_mse: 1424.5023\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 1511.2017 - mse: 1511.2017 - val_loss: 448.6418 - val_mse: 448.6418\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 665.6254 - mse: 665.6254 - val_loss: 570.1181 - val_mse: 570.1181\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 472.0814 - mse: 472.0814 - val_loss: 480.1845 - val_mse: 480.1845\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 370.5343 - mse: 370.5343 - val_loss: 310.9408 - val_mse: 310.9408\n",
            "mse: 310.9407958984375\n",
            "dropout: 0.1 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 378 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0381 - val_mse: 0.0381\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0470 - val_mse: 0.0470\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0496 - val_mse: 0.0496\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0360 - val_mse: 0.0360\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0356 - val_mse: 0.0356\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0365 - val_mse: 0.0365\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0369 - val_mse: 0.0369\n",
            "mse: 0.03687822073698044\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 379 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 7044587.5000 - mse: 7044587.5000 - val_loss: 826.2720 - val_mse: 826.2721\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2133.6462 - mse: 2133.6462 - val_loss: 913.4453 - val_mse: 913.4453\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 853.2907 - mse: 853.2907 - val_loss: 260.9486 - val_mse: 260.9486\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 499.6262 - mse: 499.6262 - val_loss: 186.6754 - val_mse: 186.6754\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 293.5528 - mse: 293.5528 - val_loss: 111.8924 - val_mse: 111.8924\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2066.2195 - mse: 2066.2195 - val_loss: 4149.2275 - val_mse: 4149.2275\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2540.8713 - mse: 2540.8713 - val_loss: 57.7731 - val_mse: 57.7731\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 363.4240 - mse: 363.4240 - val_loss: 60.6379 - val_mse: 60.6379\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 8386.7949 - mse: 8386.7949 - val_loss: 132369.2188 - val_mse: 132369.2188\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 20537.1484 - mse: 20537.1484 - val_loss: 31.3090 - val_mse: 31.3090\n",
            "mse: 31.30900764465332\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 380 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1594 - mse: 0.1594 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0378 - val_mse: 0.0378\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0363 - val_mse: 0.0363\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0420 - val_mse: 0.0420\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0443 - val_mse: 0.0443\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0407 - val_mse: 0.0407\n",
            "mse: 0.04070865362882614\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 381 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 12309424.0000 - mse: 12309424.0000 - val_loss: 229.4234 - val_mse: 229.4233\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 70.3720 - mse: 70.3720 - val_loss: 27.8530 - val_mse: 27.8530\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 61.3654 - mse: 61.3654 - val_loss: 351.3466 - val_mse: 351.3466\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 74.3903 - mse: 74.3903 - val_loss: 19.7152 - val_mse: 19.7152\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 31.0645 - mse: 31.0645 - val_loss: 7.9739 - val_mse: 7.9739\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 16911.5332 - mse: 16911.5332 - val_loss: 55658.6719 - val_mse: 55658.6719\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2841.3301 - mse: 2841.3301 - val_loss: 47.5260 - val_mse: 47.5260\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 33.8329 - mse: 33.8329 - val_loss: 22.2510 - val_mse: 22.2510\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 19.2623 - mse: 19.2623 - val_loss: 15.5671 - val_mse: 15.5671\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 14.7469 - mse: 14.7469 - val_loss: 18.3003 - val_mse: 18.3003\n",
            "mse: 18.300323486328125\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 382 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6845 - mse: 0.6845 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0345 - val_mse: 0.0345\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0361 - val_mse: 0.0361\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0421 - val_mse: 0.0421\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0385 - val_mse: 0.0385\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0371 - val_mse: 0.0371\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0384 - val_mse: 0.0384\n",
            "mse: 0.03836766257882118\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 383 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 9ms/step - loss: 137133072.0000 - mse: 137133056.0000 - val_loss: 63.9460 - val_mse: 63.9460\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2557.0615 - mse: 2557.0618 - val_loss: 128.4847 - val_mse: 128.4847\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 62.1676 - mse: 62.1676 - val_loss: 31.4740 - val_mse: 31.4740\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 13.3093 - mse: 13.3093 - val_loss: 5.2568 - val_mse: 5.2568\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 11.9999 - mse: 11.9999 - val_loss: 9.2729 - val_mse: 9.2729\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 8.4076 - mse: 8.4076 - val_loss: 5.0219 - val_mse: 5.0219\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 6.3734 - mse: 6.3734 - val_loss: 4.7101 - val_mse: 4.7101\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 5.4552 - mse: 5.4552 - val_loss: 4.0877 - val_mse: 4.0877\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 5.4374 - mse: 5.4374 - val_loss: 2.8918 - val_mse: 2.8918\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 5.1180 - mse: 5.1180 - val_loss: 1.9613 - val_mse: 1.9613\n",
            "mse: 1.9612858295440674\n",
            "dropout: 0.3 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 384 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0412 - val_mse: 0.0412\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0291 - val_mse: 0.0291\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0375 - val_mse: 0.0375\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0268 - val_mse: 0.0268\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "mse: 0.023672379553318024\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 385 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 524678.0000 - mse: 524678.0000 - val_loss: 660.9157 - val_mse: 660.9157\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 510.5927 - mse: 510.5927 - val_loss: 374.3741 - val_mse: 374.3741\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 309.8971 - mse: 309.8971 - val_loss: 220.9639 - val_mse: 220.9639\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 210.6338 - mse: 210.6338 - val_loss: 222.3628 - val_mse: 222.3628\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 123.3492 - mse: 123.3492 - val_loss: 121.4481 - val_mse: 121.4481\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 112.9738 - mse: 112.9738 - val_loss: 69.5965 - val_mse: 69.5965\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 56.4572 - mse: 56.4572 - val_loss: 41.8795 - val_mse: 41.8795\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 39.2147 - mse: 39.2147 - val_loss: 39.0642 - val_mse: 39.0642\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 31.6049 - mse: 31.6049 - val_loss: 28.3049 - val_mse: 28.3049\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 27.5693 - mse: 27.5693 - val_loss: 26.6318 - val_mse: 26.6318\n",
            "mse: 26.631805419921875\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 386 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0293 - val_mse: 0.0293\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0262 - val_mse: 0.0262\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 2s 20ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0297 - val_mse: 0.0297\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "mse: 0.032768771052360535\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 387 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 533370.7500 - mse: 533370.7500 - val_loss: 367.1852 - val_mse: 367.1852\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2590.8040 - mse: 2590.8037 - val_loss: 172.7492 - val_mse: 172.7492\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 262.2798 - mse: 262.2798 - val_loss: 68.1790 - val_mse: 68.1790\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 344.5298 - mse: 344.5298 - val_loss: 33.0975 - val_mse: 33.0975\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 122.8761 - mse: 122.8761 - val_loss: 53.1811 - val_mse: 53.1811\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1701.4556 - mse: 1701.4556 - val_loss: 70.5424 - val_mse: 70.5424\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 855.8130 - mse: 855.8130 - val_loss: 15.1859 - val_mse: 15.1859\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 81.1317 - mse: 81.1317 - val_loss: 116.4943 - val_mse: 116.4943\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 3354.9021 - mse: 3354.9021 - val_loss: 382.3508 - val_mse: 382.3508\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 12938.1104 - mse: 12938.1104 - val_loss: 1006.5251 - val_mse: 1006.5251\n",
            "mse: 1006.5250854492188\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 388 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 3s 24ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0426 - val_mse: 0.0426\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0261 - val_mse: 0.0261\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0363 - val_mse: 0.0363\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0372 - val_mse: 0.0372\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0286 - val_mse: 0.0286\n",
            "mse: 0.028638707473874092\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 389 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 2s 11ms/step - loss: 890252.0625 - mse: 890252.0625 - val_loss: 783.0385 - val_mse: 783.0385\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 4366.0742 - mse: 4366.0742 - val_loss: 371.2355 - val_mse: 371.2355\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 880.2329 - mse: 880.2329 - val_loss: 337.7482 - val_mse: 337.7482\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 662.9825 - mse: 662.9825 - val_loss: 454.6088 - val_mse: 454.6088\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 208.9955 - mse: 208.9955 - val_loss: 22.0540 - val_mse: 22.0540\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 543.5385 - mse: 543.5385 - val_loss: 885.8190 - val_mse: 885.8190\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 292.2441 - mse: 292.2441 - val_loss: 108.4677 - val_mse: 108.4677\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 947.0411 - mse: 947.0411 - val_loss: 514.0695 - val_mse: 514.0695\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 628.2415 - mse: 628.2415 - val_loss: 141.2255 - val_mse: 141.2255\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 774.5013 - mse: 774.5013 - val_loss: 6030.6816 - val_mse: 6030.6816\n",
            "mse: 6030.681640625\n",
            "dropout: 0.3 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 390 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3908 - mse: 0.3908 - val_loss: 0.0705 - val_mse: 0.0705\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "mse: 0.032583169639110565\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 391 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 12299.5176 - mse: 12299.5176 - val_loss: 1060.6318 - val_mse: 1060.6318\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 918.9504 - mse: 918.9504 - val_loss: 679.8061 - val_mse: 679.8061\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 792.0455 - mse: 792.0455 - val_loss: 513.7283 - val_mse: 513.7283\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 490.6431 - mse: 490.6431 - val_loss: 362.1046 - val_mse: 362.1046\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 528.1581 - mse: 528.1582 - val_loss: 283.4450 - val_mse: 283.4450\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 388.3517 - mse: 388.3517 - val_loss: 272.6068 - val_mse: 272.6068\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 271.9803 - mse: 271.9803 - val_loss: 264.0266 - val_mse: 264.0266\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 405.0387 - mse: 405.0387 - val_loss: 474.6161 - val_mse: 474.6161\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 641.2759 - mse: 641.2759 - val_loss: 241.8750 - val_mse: 241.8750\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 658.0890 - mse: 658.0890 - val_loss: 1211.0806 - val_mse: 1211.0806\n",
            "mse: 1211.08056640625\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 392 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 2s 8ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "mse: 0.02457962930202484\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 393 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 97215.5234 - mse: 97215.5234 - val_loss: 4673.2148 - val_mse: 4673.2148\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 3960.7031 - mse: 3960.7034 - val_loss: 1361.0291 - val_mse: 1361.0291\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1076.3381 - mse: 1076.3381 - val_loss: 515.9335 - val_mse: 515.9335\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1084.6270 - mse: 1084.6270 - val_loss: 246.3542 - val_mse: 246.3542\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 336.7337 - mse: 336.7337 - val_loss: 320.7079 - val_mse: 320.7079\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 277.8349 - mse: 277.8349 - val_loss: 127.6748 - val_mse: 127.6748\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 278.1648 - mse: 278.1648 - val_loss: 204.6746 - val_mse: 204.6746\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 2023.8940 - mse: 2023.8940 - val_loss: 154.2201 - val_mse: 154.2201\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 562.4313 - mse: 562.4313 - val_loss: 77.7089 - val_mse: 77.7089\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1079.4207 - mse: 1079.4207 - val_loss: 71.1022 - val_mse: 71.1022\n",
            "mse: 71.10221099853516\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 394 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 2s 10ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0350 - val_mse: 0.0350\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "mse: 0.02182411588728428\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 395 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 2s 11ms/step - loss: 51782.3984 - mse: 51782.4023 - val_loss: 266.6972 - val_mse: 266.6972\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 153.2264 - mse: 153.2264 - val_loss: 108.8938 - val_mse: 108.8938\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 348.9121 - mse: 348.9121 - val_loss: 614.9781 - val_mse: 614.9781\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1841.7717 - mse: 1841.7717 - val_loss: 130.0116 - val_mse: 130.0116\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 490.9543 - mse: 490.9543 - val_loss: 271.7851 - val_mse: 271.7851\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1156.2811 - mse: 1156.2811 - val_loss: 3684.0642 - val_mse: 3684.0642\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 11387.5928 - mse: 11387.5928 - val_loss: 227.0202 - val_mse: 227.0202\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 395.3199 - mse: 395.3199 - val_loss: 3285.8760 - val_mse: 3285.8760\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 6461.6553 - mse: 6461.6553 - val_loss: 112.0510 - val_mse: 112.0510\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1348.8663 - mse: 1348.8663 - val_loss: 137.5411 - val_mse: 137.5411\n",
            "mse: 137.54107666015625\n",
            "dropout: 0.3 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 396 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 0.3115 - mse: 0.3115 - val_loss: 0.0463 - val_mse: 0.0463\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0416 - val_mse: 0.0416\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "mse: 0.03316628932952881\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 397 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 12431618.0000 - mse: 12431618.0000 - val_loss: 37429.1680 - val_mse: 37429.1680\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 15027.0869 - mse: 15027.0869 - val_loss: 1661.8348 - val_mse: 1661.8348\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2008.5847 - mse: 2008.5847 - val_loss: 1048.2896 - val_mse: 1048.2896\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1216.3424 - mse: 1216.3424 - val_loss: 943.6472 - val_mse: 943.6471\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 906.1691 - mse: 906.1691 - val_loss: 491.7991 - val_mse: 491.7991\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 254.7999 - mse: 254.7999 - val_loss: 116.8491 - val_mse: 116.8491\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 64.8712 - mse: 64.8712 - val_loss: 28.0625 - val_mse: 28.0625\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 37.8386 - mse: 37.8386 - val_loss: 18.2767 - val_mse: 18.2767\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 28.9578 - mse: 28.9578 - val_loss: 17.5316 - val_mse: 17.5316\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 24.5057 - mse: 24.5057 - val_loss: 11.5137 - val_mse: 11.5137\n",
            "mse: 11.513726234436035\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 398 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 0.6576 - mse: 0.6576 - val_loss: 0.1705 - val_mse: 0.1705\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0661 - mse: 0.0661 - val_loss: 0.0524 - val_mse: 0.0524\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0373 - val_mse: 0.0373\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0358 - val_mse: 0.0358\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "mse: 0.0328088216483593\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 399 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 20420738.0000 - mse: 20420738.0000 - val_loss: 33773.7031 - val_mse: 33773.7031\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 70765.9062 - mse: 70765.9062 - val_loss: 411.4091 - val_mse: 411.4091\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 5890.5029 - mse: 5890.5029 - val_loss: 270.1418 - val_mse: 270.1418\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 3709.3123 - mse: 3709.3123 - val_loss: 467.3428 - val_mse: 467.3428\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 235.6402 - mse: 235.6402 - val_loss: 153.5627 - val_mse: 153.5627\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 135.2746 - mse: 135.2746 - val_loss: 88.6408 - val_mse: 88.6408\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 85.4592 - mse: 85.4592 - val_loss: 104.6419 - val_mse: 104.6419\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 75.5622 - mse: 75.5622 - val_loss: 56.3634 - val_mse: 56.3634\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 56.0188 - mse: 56.0188 - val_loss: 64.4955 - val_mse: 64.4955\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 49.6484 - mse: 49.6484 - val_loss: 47.8452 - val_mse: 47.8452\n",
            "mse: 47.84519958496094\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 400 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 3.2874 - mse: 3.2874 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1526 - mse: 0.1526 - val_loss: 0.0380 - val_mse: 0.0380\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0429 - val_mse: 0.0429\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0349 - val_mse: 0.0349\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "mse: 0.0327477864921093\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 401 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 335580992.0000 - mse: 335580992.0000 - val_loss: 26524.1445 - val_mse: 26524.1445\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 14576.2852 - mse: 14576.2852 - val_loss: 2388.8379 - val_mse: 2388.8379\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 5157.1025 - mse: 5157.1025 - val_loss: 4392.7095 - val_mse: 4392.7095\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1357.2839 - mse: 1357.2839 - val_loss: 1017.2556 - val_mse: 1017.2556\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 383.6417 - mse: 383.6417 - val_loss: 138.6594 - val_mse: 138.6594\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 196.8387 - mse: 196.8387 - val_loss: 107.9773 - val_mse: 107.9773\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 180.5388 - mse: 180.5388 - val_loss: 119.7316 - val_mse: 119.7316\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 72.7047 - mse: 72.7047 - val_loss: 14.4859 - val_mse: 14.4859\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 33.7707 - mse: 33.7707 - val_loss: 27.5875 - val_mse: 27.5875\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 38.2816 - mse: 38.2816 - val_loss: 68.5456 - val_mse: 68.5456\n",
            "mse: 68.54557037353516\n",
            "dropout: 0.3 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 402 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 1.2174 - mse: 1.2174 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0878 - mse: 0.0878 - val_loss: 0.0441 - val_mse: 0.0441\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0391 - val_mse: 0.0391\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "mse: 0.030406564474105835\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 403 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 211146.7969 - mse: 211146.7969 - val_loss: 64004.4453 - val_mse: 64004.4453\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 19223.0410 - mse: 19223.0410 - val_loss: 5397.7158 - val_mse: 5397.7158\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 4803.9395 - mse: 4803.9395 - val_loss: 2822.1721 - val_mse: 2822.1721\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1685.6105 - mse: 1685.6102 - val_loss: 950.0062 - val_mse: 950.0062\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 722.7220 - mse: 722.7220 - val_loss: 542.9570 - val_mse: 542.9570\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 337.8965 - mse: 337.8965 - val_loss: 216.9911 - val_mse: 216.9911\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 189.7803 - mse: 189.7803 - val_loss: 154.1161 - val_mse: 154.1161\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 143.2781 - mse: 143.2781 - val_loss: 103.9922 - val_mse: 103.9922\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 111.9465 - mse: 111.9466 - val_loss: 75.1446 - val_mse: 75.1446\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 94.9197 - mse: 94.9197 - val_loss: 51.4628 - val_mse: 51.4628\n",
            "mse: 51.46277618408203\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 404 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 21ms/step - loss: 0.4306 - mse: 0.4306 - val_loss: 0.0566 - val_mse: 0.0566\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0644 - mse: 0.0644 - val_loss: 0.0452 - val_mse: 0.0452\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0268 - val_mse: 0.0268\n",
            "mse: 0.026791157200932503\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 405 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 23ms/step - loss: 2018918.3750 - mse: 2018918.0000 - val_loss: 60772.9258 - val_mse: 60772.9258\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 97558.7188 - mse: 97558.7188 - val_loss: 28714.8496 - val_mse: 28714.8496\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 11702.4023 - mse: 11702.4023 - val_loss: 687.8734 - val_mse: 687.8733\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 1644.2091 - mse: 1644.2091 - val_loss: 1094.8629 - val_mse: 1094.8629\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 1109.0336 - mse: 1109.0336 - val_loss: 367.1323 - val_mse: 367.1323\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 739.5842 - mse: 739.5842 - val_loss: 316.7365 - val_mse: 316.7365\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 566.2935 - mse: 566.2935 - val_loss: 294.0017 - val_mse: 294.0017\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 369.5401 - mse: 369.5401 - val_loss: 250.6929 - val_mse: 250.6929\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 214.1219 - mse: 214.1219 - val_loss: 160.3647 - val_mse: 160.3647\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 182.3739 - mse: 182.3739 - val_loss: 178.1774 - val_mse: 178.1774\n",
            "mse: 178.17735290527344\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 406 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 0.1464 - mse: 0.1464 - val_loss: 0.0364 - val_mse: 0.0364\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0278 - val_mse: 0.0278\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "mse: 0.024850662797689438\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 407 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 26ms/step - loss: 11860537.0000 - mse: 11860537.0000 - val_loss: 843846.6875 - val_mse: 843846.6875\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 186853.8750 - mse: 186853.8750 - val_loss: 30583.9805 - val_mse: 30583.9805\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 13119.0254 - mse: 13119.0254 - val_loss: 2221.0635 - val_mse: 2221.0635\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1040.7610 - mse: 1040.7610 - val_loss: 456.9891 - val_mse: 456.9891\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 366.4481 - mse: 366.4481 - val_loss: 220.4582 - val_mse: 220.4582\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 206.8557 - mse: 206.8557 - val_loss: 143.4800 - val_mse: 143.4800\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 152.8694 - mse: 152.8694 - val_loss: 105.9982 - val_mse: 105.9982\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 117.4923 - mse: 117.4923 - val_loss: 82.6414 - val_mse: 82.6414\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 91.5848 - mse: 91.5848 - val_loss: 63.8481 - val_mse: 63.8481\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 78.2471 - mse: 78.2471 - val_loss: 52.0382 - val_mse: 52.0382\n",
            "mse: 52.038230895996094\n",
            "dropout: 0.3 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 408 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 14ms/step - loss: 1.8886 - mse: 1.8886 - val_loss: 1.5481 - val_mse: 1.5481\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1.2305 - mse: 1.2305 - val_loss: 0.9818 - val_mse: 0.9818\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7544 - mse: 0.7544 - val_loss: 0.5906 - val_mse: 0.5906\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4389 - mse: 0.4389 - val_loss: 0.3376 - val_mse: 0.3376\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2424 - mse: 0.2424 - val_loss: 0.1875 - val_mse: 0.1875\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1308 - mse: 0.1308 - val_loss: 0.1057 - val_mse: 0.1057\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0735 - mse: 0.0735 - val_loss: 0.0644 - val_mse: 0.0644\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0457 - val_mse: 0.0457\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0380 - val_mse: 0.0380\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0349 - val_mse: 0.0349\n",
            "mse: 0.034935154020786285\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 409 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 191460.0781 - mse: 191460.0781 - val_loss: 53833.5430 - val_mse: 53833.5430\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 34888.7578 - mse: 34888.7578 - val_loss: 6124.5884 - val_mse: 6124.5884\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 16738.2070 - mse: 16738.2070 - val_loss: 2350.2183 - val_mse: 2350.2183\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 10159.9463 - mse: 10159.9463 - val_loss: 1925.1654 - val_mse: 1925.1654\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 5930.7119 - mse: 5930.7119 - val_loss: 1316.9817 - val_mse: 1316.9816\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 3930.5642 - mse: 3930.5642 - val_loss: 1166.3029 - val_mse: 1166.3029\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 2670.4729 - mse: 2670.4729 - val_loss: 1150.3943 - val_mse: 1150.3943\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1716.3398 - mse: 1716.3398 - val_loss: 893.9092 - val_mse: 893.9092\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1253.0980 - mse: 1253.0980 - val_loss: 771.0275 - val_mse: 771.0275\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 958.9872 - mse: 958.9872 - val_loss: 700.9626 - val_mse: 700.9626\n",
            "mse: 700.9625854492188\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 410 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 4.1205 - mse: 4.1205 - val_loss: 2.7940 - val_mse: 2.7940\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 1.8916 - mse: 1.8916 - val_loss: 1.1449 - val_mse: 1.1449\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.6995 - mse: 0.6995 - val_loss: 0.3732 - val_mse: 0.3732\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2039 - mse: 0.2039 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0426 - val_mse: 0.0426\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "mse: 0.0328371487557888\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 411 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 301312.5000 - mse: 301312.5000 - val_loss: 6200.6509 - val_mse: 6200.6509\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 36835.2656 - mse: 36835.2617 - val_loss: 15054.4277 - val_mse: 15054.4277\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 11133.0605 - mse: 11133.0605 - val_loss: 2718.9932 - val_mse: 2718.9934\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2708.9944 - mse: 2708.9944 - val_loss: 1457.2207 - val_mse: 1457.2207\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 931.2317 - mse: 931.2317 - val_loss: 712.6238 - val_mse: 712.6238\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 466.9070 - mse: 466.9070 - val_loss: 569.2766 - val_mse: 569.2766\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 402.5319 - mse: 402.5319 - val_loss: 518.7676 - val_mse: 518.7676\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 331.8546 - mse: 331.8546 - val_loss: 404.7050 - val_mse: 404.7050\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 283.4894 - mse: 283.4894 - val_loss: 356.6221 - val_mse: 356.6221\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 239.0633 - mse: 239.0633 - val_loss: 305.8756 - val_mse: 305.8756\n",
            "mse: 305.8755798339844\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 412 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 27ms/step - loss: 1.7271 - mse: 1.7271 - val_loss: 0.1837 - val_mse: 0.1837\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0638 - mse: 0.0638 - val_loss: 0.0755 - val_mse: 0.0755\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "mse: 0.031076129525899887\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 413 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 4360718.5000 - mse: 4360718.0000 - val_loss: 1072566.5000 - val_mse: 1072566.5000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 359260.4375 - mse: 359260.4375 - val_loss: 17249.3418 - val_mse: 17249.3438\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 41710.8984 - mse: 41710.8984 - val_loss: 3539.0347 - val_mse: 3539.0347\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 6829.7554 - mse: 6829.7554 - val_loss: 1959.2194 - val_mse: 1959.2194\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 1874.2773 - mse: 1874.2773 - val_loss: 722.6903 - val_mse: 722.6904\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 748.9113 - mse: 748.9113 - val_loss: 570.5701 - val_mse: 570.5701\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 480.3549 - mse: 480.3549 - val_loss: 380.6140 - val_mse: 380.6140\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 331.7443 - mse: 331.7443 - val_loss: 301.5300 - val_mse: 301.5300\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 254.9907 - mse: 254.9907 - val_loss: 246.4521 - val_mse: 246.4521\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 210.8624 - mse: 210.8624 - val_loss: 202.6285 - val_mse: 202.6285\n",
            "mse: 202.6284942626953\n",
            "dropout: 0.3 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 414 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 0.1793 - mse: 0.1793 - val_loss: 0.1178 - val_mse: 0.1178\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0477 - val_mse: 0.0477\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.0329994261264801\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 415 /162\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 33ms/step - loss: 93886280.0000 - mse: 93886280.0000 - val_loss: 1737009.3750 - val_mse: 1737009.3750\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 485340.1250 - mse: 485340.1250 - val_loss: 2890.8584 - val_mse: 2890.8584\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 55964.3555 - mse: 55964.3555 - val_loss: 11755.6377 - val_mse: 11755.6377\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 14123.7217 - mse: 14123.7217 - val_loss: 13950.2715 - val_mse: 13950.2715\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5305.4033 - mse: 5305.4033 - val_loss: 2255.4236 - val_mse: 2255.4236\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2056.4182 - mse: 2056.4182 - val_loss: 185.0340 - val_mse: 185.0340\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 806.9272 - mse: 806.9272 - val_loss: 396.4494 - val_mse: 396.4494\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 361.8978 - mse: 361.8978 - val_loss: 259.8773 - val_mse: 259.8773\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 215.9545 - mse: 215.9545 - val_loss: 161.8731 - val_mse: 161.8731\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 172.8754 - mse: 172.8754 - val_loss: 135.8861 - val_mse: 135.8861\n",
            "mse: 135.88609313964844\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 416 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 47ms/step - loss: 0.9380 - mse: 0.9380 - val_loss: 0.0585 - val_mse: 0.0585\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1610 - mse: 0.1610 - val_loss: 0.1678 - val_mse: 0.1678\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0737 - val_mse: 0.0737\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0388 - val_mse: 0.0388\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0356 - val_mse: 0.0356\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0357 - val_mse: 0.0357\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.032964617013931274\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 417 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 43ms/step - loss: 123829920.0000 - mse: 123829920.0000 - val_loss: 394775.0938 - val_mse: 394775.0938\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 164483.9688 - mse: 164483.9688 - val_loss: 30958.5938 - val_mse: 30958.5938\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 31666.4434 - mse: 31666.4434 - val_loss: 31182.4355 - val_mse: 31182.4355\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 11648.7256 - mse: 11648.7256 - val_loss: 8077.7900 - val_mse: 8077.7900\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2409.3259 - mse: 2409.3259 - val_loss: 805.6401 - val_mse: 805.6401\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 374.7484 - mse: 374.7484 - val_loss: 193.3259 - val_mse: 193.3259\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 231.0299 - mse: 231.0299 - val_loss: 186.4875 - val_mse: 186.4875\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 181.2467 - mse: 181.2467 - val_loss: 144.0022 - val_mse: 144.0022\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 146.2958 - mse: 146.2958 - val_loss: 170.6006 - val_mse: 170.6006\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 120.0917 - mse: 120.0917 - val_loss: 121.3505 - val_mse: 121.3505\n",
            "mse: 121.35050964355469\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 418 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 41ms/step - loss: 7.2605 - mse: 7.2605 - val_loss: 0.1709 - val_mse: 0.1709\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.3369 - mse: 0.3369 - val_loss: 0.1418 - val_mse: 0.1418\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1342 - mse: 0.1342 - val_loss: 0.1063 - val_mse: 0.1063\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0710 - mse: 0.0710 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0404 - val_mse: 0.0404\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "mse: 0.032901182770729065\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 419 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 40ms/step - loss: 653394368.0000 - mse: 653394368.0000 - val_loss: 2307545.0000 - val_mse: 2307545.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 499212.4375 - mse: 499212.4375 - val_loss: 93188.3359 - val_mse: 93188.3359\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 34228.3438 - mse: 34228.3438 - val_loss: 11959.1943 - val_mse: 11959.1943\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 4811.4971 - mse: 4811.4971 - val_loss: 1775.3695 - val_mse: 1775.3695\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1932.9313 - mse: 1932.9313 - val_loss: 206.1435 - val_mse: 206.1435\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 858.9788 - mse: 858.9788 - val_loss: 588.8539 - val_mse: 588.8539\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 253.6463 - mse: 253.6463 - val_loss: 71.8529 - val_mse: 71.8529\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 88.9751 - mse: 88.9751 - val_loss: 22.1706 - val_mse: 22.1706\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 31.2560 - mse: 31.2560 - val_loss: 25.2989 - val_mse: 25.2989\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 14.5919 - mse: 14.5919 - val_loss: 19.2005 - val_mse: 19.2005\n",
            "mse: 19.200515747070312\n",
            "dropout: 0.3 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 420 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 25ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0477 - val_mse: 0.0477\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0352 - val_mse: 0.0352\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "mse: 0.03160249441862106\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 421 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 46ms/step - loss: 1163733.5000 - mse: 1163733.5000 - val_loss: 520027.7812 - val_mse: 520027.7812\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 185586.0625 - mse: 185586.0625 - val_loss: 11389.8721 - val_mse: 11389.8721\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 40143.7344 - mse: 40143.7344 - val_loss: 27994.5820 - val_mse: 27994.5820\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 17965.8574 - mse: 17965.8574 - val_loss: 8724.8584 - val_mse: 8724.8584\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 4962.3999 - mse: 4962.3994 - val_loss: 2769.4685 - val_mse: 2769.4685\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2769.0911 - mse: 2769.0911 - val_loss: 1135.3721 - val_mse: 1135.3721\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 795.0889 - mse: 795.0889 - val_loss: 318.5938 - val_mse: 318.5938\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 337.6022 - mse: 337.6022 - val_loss: 140.1719 - val_mse: 140.1720\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 193.2104 - mse: 193.2104 - val_loss: 120.5125 - val_mse: 120.5125\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 140.1146 - mse: 140.1146 - val_loss: 119.0652 - val_mse: 119.0652\n",
            "mse: 119.06523895263672\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 422 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 32ms/step - loss: 0.2148 - mse: 0.2148 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0630 - mse: 0.0630 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0345 - val_mse: 0.0345\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0351 - val_mse: 0.0351\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "mse: 0.02980668470263481\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 423 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 31ms/step - loss: 5252002.0000 - mse: 5252002.0000 - val_loss: 29256.1035 - val_mse: 29256.1035\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 696756.0625 - mse: 696756.0625 - val_loss: 449699.9375 - val_mse: 449699.9375\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 177051.6406 - mse: 177051.6406 - val_loss: 124403.9531 - val_mse: 124403.9531\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 59106.4961 - mse: 59106.4961 - val_loss: 18116.1426 - val_mse: 18116.1426\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 10721.2051 - mse: 10721.2051 - val_loss: 3069.5852 - val_mse: 3069.5852\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 4476.8267 - mse: 4476.8267 - val_loss: 2806.3740 - val_mse: 2806.3740\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 2437.8235 - mse: 2437.8235 - val_loss: 2108.2622 - val_mse: 2108.2620\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1725.3733 - mse: 1725.3733 - val_loss: 1512.4106 - val_mse: 1512.4106\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1229.3798 - mse: 1229.3799 - val_loss: 1029.7483 - val_mse: 1029.7483\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 867.2272 - mse: 867.2272 - val_loss: 820.1915 - val_mse: 820.1915\n",
            "mse: 820.1914672851562\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 424 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 46ms/step - loss: 0.6067 - mse: 0.6067 - val_loss: 0.2093 - val_mse: 0.2093\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1671 - mse: 0.1671 - val_loss: 0.1323 - val_mse: 0.1323\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0817 - val_mse: 0.0817\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0389 - val_mse: 0.0389\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0287 - val_mse: 0.0287\n",
            "mse: 0.02869539149105549\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 425 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 56ms/step - loss: 14914539.0000 - mse: 14914539.0000 - val_loss: 1755711.1250 - val_mse: 1755710.8750\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 502544.4062 - mse: 502544.4062 - val_loss: 259643.4062 - val_mse: 259643.4062\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 90362.6250 - mse: 90362.6250 - val_loss: 53557.4844 - val_mse: 53557.4844\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 20240.0488 - mse: 20240.0488 - val_loss: 20501.4434 - val_mse: 20501.4434\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 8572.3115 - mse: 8572.3115 - val_loss: 7422.7520 - val_mse: 7422.7520\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 3297.1062 - mse: 3297.1062 - val_loss: 2414.3816 - val_mse: 2414.3816\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 1187.7811 - mse: 1187.7811 - val_loss: 423.7526 - val_mse: 423.7526\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 575.7407 - mse: 575.7407 - val_loss: 601.9108 - val_mse: 601.9108\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 413.0117 - mse: 413.0117 - val_loss: 296.4648 - val_mse: 296.4648\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 262.3775 - mse: 262.3775 - val_loss: 203.4200 - val_mse: 203.4200\n",
            "mse: 203.4199676513672\n",
            "dropout: 0.3 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 426 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 27ms/step - loss: 2.8447 - mse: 2.8447 - val_loss: 2.6608 - val_mse: 2.6608\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4303 - mse: 2.4303 - val_loss: 2.2657 - val_mse: 2.2657\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.0583 - mse: 2.0583 - val_loss: 1.9136 - val_mse: 1.9136\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7286 - mse: 1.7286 - val_loss: 1.6037 - val_mse: 1.6037\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4401 - mse: 1.4401 - val_loss: 1.3346 - val_mse: 1.3346\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.1912 - mse: 1.1912 - val_loss: 1.1025 - val_mse: 1.1025\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9778 - mse: 0.9778 - val_loss: 0.9040 - val_mse: 0.9040\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7959 - mse: 0.7959 - val_loss: 0.7360 - val_mse: 0.7360\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6432 - mse: 0.6432 - val_loss: 0.5947 - val_mse: 0.5947\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5155 - mse: 0.5155 - val_loss: 0.4773 - val_mse: 0.4773\n",
            "mse: 0.47730910778045654\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 427 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 8729111.0000 - mse: 8729111.0000 - val_loss: 2361763.2500 - val_mse: 2361763.2500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 797200.0000 - mse: 797200.0000 - val_loss: 77192.6875 - val_mse: 77192.6875\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 337714.9688 - mse: 337714.9688 - val_loss: 414212.7812 - val_mse: 414212.7812\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 224082.0312 - mse: 224082.0312 - val_loss: 30757.0547 - val_mse: 30757.0547\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 33162.4961 - mse: 33162.5000 - val_loss: 46412.6797 - val_mse: 46412.6797\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 47998.2617 - mse: 47998.2617 - val_loss: 22719.5801 - val_mse: 22719.5801\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 21626.2441 - mse: 21626.2441 - val_loss: 18766.8594 - val_mse: 18766.8594\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20812.7832 - mse: 20812.7832 - val_loss: 17389.3066 - val_mse: 17389.3066\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 17042.3359 - mse: 17042.3359 - val_loss: 14532.5859 - val_mse: 14532.5859\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 16100.6875 - mse: 16100.6875 - val_loss: 14211.0059 - val_mse: 14211.0059\n",
            "mse: 14211.005859375\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 428 /162\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 43ms/step - loss: 0.2892 - mse: 0.2892 - val_loss: 0.1453 - val_mse: 0.1453\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0727 - mse: 0.0727 - val_loss: 0.0374 - val_mse: 0.0374\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0367 - val_mse: 0.0367\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "mse: 0.03264613449573517\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 429 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 56ms/step - loss: 198924.2031 - mse: 198924.2031 - val_loss: 127605.8281 - val_mse: 127605.8438\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 57256.8828 - mse: 57256.8828 - val_loss: 22289.8320 - val_mse: 22289.8301\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 13688.9844 - mse: 13688.9844 - val_loss: 3676.6907 - val_mse: 3676.6907\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 5767.5059 - mse: 5767.5059 - val_loss: 4114.4243 - val_mse: 4114.4243\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 2421.5103 - mse: 2421.5103 - val_loss: 2035.0482 - val_mse: 2035.0482\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1449.6241 - mse: 1449.6241 - val_loss: 738.1825 - val_mse: 738.1825\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 735.0622 - mse: 735.0622 - val_loss: 601.2028 - val_mse: 601.2028\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 489.0593 - mse: 489.0593 - val_loss: 490.6609 - val_mse: 490.6609\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 375.6042 - mse: 375.6042 - val_loss: 430.3089 - val_mse: 430.3089\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 329.8454 - mse: 329.8454 - val_loss: 367.5518 - val_mse: 367.5518\n",
            "mse: 367.5517578125\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 430 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 41ms/step - loss: 0.7921 - mse: 0.7921 - val_loss: 0.1878 - val_mse: 0.1878\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.0578 - val_mse: 0.0578\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0812 - mse: 0.0812 - val_loss: 0.0694 - val_mse: 0.0694\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0410 - val_mse: 0.0410\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.03299403935670853\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 431 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 51ms/step - loss: 433296.7500 - mse: 433296.7500 - val_loss: 285301.6250 - val_mse: 285301.6250\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 113052.9688 - mse: 113052.9688 - val_loss: 6791.3193 - val_mse: 6791.3193\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 26388.8223 - mse: 26388.8223 - val_loss: 28528.9805 - val_mse: 28528.9805\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 14713.7002 - mse: 14713.7002 - val_loss: 2032.3500 - val_mse: 2032.3499\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3833.3394 - mse: 3833.3394 - val_loss: 4684.6680 - val_mse: 4684.6680\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 1920.9203 - mse: 1920.9203 - val_loss: 603.0943 - val_mse: 603.0943\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 788.4587 - mse: 788.4587 - val_loss: 299.3203 - val_mse: 299.3203\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 332.4963 - mse: 332.4963 - val_loss: 328.4692 - val_mse: 328.4692\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 194.2822 - mse: 194.2822 - val_loss: 194.2969 - val_mse: 194.2969\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 114.0344 - mse: 114.0344 - val_loss: 135.1446 - val_mse: 135.1446\n",
            "mse: 135.1445770263672\n",
            "dropout: 0.3 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 432 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 2s 9ms/step - loss: 0.1450 - mse: 0.1450 - val_loss: 0.0350 - val_mse: 0.0350\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0361 - val_mse: 0.0361\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0385 - val_mse: 0.0385\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0402 - val_mse: 0.0402\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0435 - val_mse: 0.0435\n",
            "mse: 0.043543145060539246\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 433 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 2987491.0000 - mse: 2987491.0000 - val_loss: 25.3406 - val_mse: 25.3406\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 134.1075 - mse: 134.1075 - val_loss: 19.1243 - val_mse: 19.1243\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 15.7973 - mse: 15.7973 - val_loss: 7.5401 - val_mse: 7.5401\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 14.9609 - mse: 14.9609 - val_loss: 3.9579 - val_mse: 3.9579\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 491.1821 - mse: 491.1821 - val_loss: 22.7902 - val_mse: 22.7902\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 17.2060 - mse: 17.2060 - val_loss: 2.0692 - val_mse: 2.0692\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 32.2169 - mse: 32.2169 - val_loss: 2.5050 - val_mse: 2.5050\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 16.0776 - mse: 16.0776 - val_loss: 9.6953 - val_mse: 9.6953\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 8.9294 - mse: 8.9294 - val_loss: 9.3461 - val_mse: 9.3461\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 19.5050 - mse: 19.5050 - val_loss: 0.9145 - val_mse: 0.9145\n",
            "mse: 0.9144944548606873\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 434 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1537 - mse: 0.1537 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0400 - val_mse: 0.0400\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0347 - val_mse: 0.0347\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0349 - val_mse: 0.0349\n",
            "mse: 0.03485199064016342\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 435 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 18549338.0000 - mse: 18549338.0000 - val_loss: 15299.6162 - val_mse: 15299.6162\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1981.5535 - mse: 1981.5535 - val_loss: 50.6837 - val_mse: 50.6837\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 261.9410 - mse: 261.9410 - val_loss: 123.4069 - val_mse: 123.4069\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1134.1859 - mse: 1134.1859 - val_loss: 19365.8828 - val_mse: 19365.8848\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 9735.6338 - mse: 9735.6338 - val_loss: 1554.4866 - val_mse: 1554.4866\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 712.2088 - mse: 712.2088 - val_loss: 12.1927 - val_mse: 12.1927\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 19.2717 - mse: 19.2717 - val_loss: 2.2618 - val_mse: 2.2618\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 10.7740 - mse: 10.7740 - val_loss: 4.0022 - val_mse: 4.0022\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 16.2766 - mse: 16.2766 - val_loss: 11.5275 - val_mse: 11.5275\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 64.3740 - mse: 64.3740 - val_loss: 5.6818 - val_mse: 5.6818\n",
            "mse: 5.681760787963867\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 436 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6456 - mse: 0.6456 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0404 - val_mse: 0.0404\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0415 - val_mse: 0.0415\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0410 - val_mse: 0.0410\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0354 - val_mse: 0.0354\n",
            "mse: 0.03544364869594574\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 437 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 9ms/step - loss: 94515728.0000 - mse: 94515728.0000 - val_loss: 242.9489 - val_mse: 242.9489\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 517.5010 - mse: 517.5010 - val_loss: 625.3309 - val_mse: 625.3309\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 5447.6709 - mse: 5447.6709 - val_loss: 1269.2839 - val_mse: 1269.2839\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 554.8971 - mse: 554.8971 - val_loss: 54.1275 - val_mse: 54.1275\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 65.8609 - mse: 65.8609 - val_loss: 39.0648 - val_mse: 39.0648\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 119.4296 - mse: 119.4296 - val_loss: 159.2436 - val_mse: 159.2436\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 56.8418 - mse: 56.8418 - val_loss: 157.7812 - val_mse: 157.7812\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 76.6004 - mse: 76.6004 - val_loss: 158.1294 - val_mse: 158.1294\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 68.5986 - mse: 68.5986 - val_loss: 9.9963 - val_mse: 9.9963\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 33.5372 - mse: 33.5372 - val_loss: 31.7383 - val_mse: 31.7383\n",
            "mse: 31.738298416137695\n",
            "dropout: 0.5 batch_size: 20 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 438 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2061 - mse: 0.2061 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0270 - val_mse: 0.0270\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "mse: 0.02963229827582836\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 439 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 6ms/step - loss: 379929.1875 - mse: 379929.1250 - val_loss: 1182.6201 - val_mse: 1182.6201\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 1861.9318 - mse: 1861.9318 - val_loss: 288.6713 - val_mse: 288.6713\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 275.9875 - mse: 275.9875 - val_loss: 125.9287 - val_mse: 125.9287\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 807.9745 - mse: 807.9745 - val_loss: 81.2518 - val_mse: 81.2518\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 102.9441 - mse: 102.9441 - val_loss: 85.6392 - val_mse: 85.6392\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 453.2552 - mse: 453.2552 - val_loss: 28.9106 - val_mse: 28.9106\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 151.1348 - mse: 151.1348 - val_loss: 26.9289 - val_mse: 26.9289\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 192.3746 - mse: 192.3746 - val_loss: 44.8877 - val_mse: 44.8877\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 79.9113 - mse: 79.9113 - val_loss: 46.1451 - val_mse: 46.1451\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 83.9136 - mse: 83.9136 - val_loss: 32.8876 - val_mse: 32.8876\n",
            "mse: 32.887603759765625\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 440 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0983 - mse: 0.0983 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0357 - val_mse: 0.0357\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0273 - val_mse: 0.0273\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0317 - val_mse: 0.0317\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0370 - val_mse: 0.0370\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "mse: 0.031841568648815155\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 441 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 2s 9ms/step - loss: 395994.9688 - mse: 395994.9688 - val_loss: 390.4342 - val_mse: 390.4342\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 7825.0029 - mse: 7825.0029 - val_loss: 233.9810 - val_mse: 233.9810\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 747.9370 - mse: 747.9370 - val_loss: 129.4243 - val_mse: 129.4243\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 563.0810 - mse: 563.0810 - val_loss: 65.2586 - val_mse: 65.2586\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2365.0823 - mse: 2365.0823 - val_loss: 233.7262 - val_mse: 233.7262\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 945.3945 - mse: 945.3945 - val_loss: 563.3126 - val_mse: 563.3126\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 542.6685 - mse: 542.6685 - val_loss: 148.0385 - val_mse: 148.0385\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 4509.3081 - mse: 4509.3086 - val_loss: 586.9194 - val_mse: 586.9194\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 355.2342 - mse: 355.2342 - val_loss: 68.1783 - val_mse: 68.1783\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 56.7331 - mse: 56.7331 - val_loss: 83.0968 - val_mse: 83.0968\n",
            "mse: 83.09680938720703\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 442 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 2s 11ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0356 - val_mse: 0.0356\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0381 - val_mse: 0.0381\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0362 - val_mse: 0.0362\n",
            "mse: 0.03615344688296318\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 443 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 2s 12ms/step - loss: 1187555.1250 - mse: 1187555.1250 - val_loss: 116.5482 - val_mse: 116.5482\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 185.7802 - mse: 185.7802 - val_loss: 156.9603 - val_mse: 156.9603\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 709.8754 - mse: 709.8754 - val_loss: 60.5576 - val_mse: 60.5576\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 68.5413 - mse: 68.5413 - val_loss: 251.8182 - val_mse: 251.8182\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 38.7665 - mse: 38.7665 - val_loss: 80.3231 - val_mse: 80.3231\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 70.7590 - mse: 70.7590 - val_loss: 145.5581 - val_mse: 145.5581\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 23.9001 - mse: 23.9001 - val_loss: 20.3322 - val_mse: 20.3322\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 76.9878 - mse: 76.9878 - val_loss: 85.5218 - val_mse: 85.5218\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 374.2532 - mse: 374.2532 - val_loss: 90.1324 - val_mse: 90.1324\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 270.2354 - mse: 270.2354 - val_loss: 375.0901 - val_mse: 375.0901\n",
            "mse: 375.090087890625\n",
            "dropout: 0.5 batch_size: 20 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 444 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 1.9904 - mse: 1.9904 - val_loss: 0.6905 - val_mse: 0.6905\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.2603 - mse: 0.2603 - val_loss: 0.0748 - val_mse: 0.0748\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0345 - val_mse: 0.0345\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "mse: 0.032582662999629974\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 445 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 1526133.6250 - mse: 1526133.6250 - val_loss: 47828.2656 - val_mse: 47828.2656\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 29547.1660 - mse: 29547.1660 - val_loss: 16813.1660 - val_mse: 16813.1660\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 10075.3906 - mse: 10075.3906 - val_loss: 4440.5723 - val_mse: 4440.5723\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 4413.1094 - mse: 4413.1094 - val_loss: 2379.8591 - val_mse: 2379.8591\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 2853.4102 - mse: 2853.4102 - val_loss: 1669.9268 - val_mse: 1669.9268\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 2138.2227 - mse: 2138.2227 - val_loss: 1493.9261 - val_mse: 1493.9261\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1771.9902 - mse: 1771.9902 - val_loss: 1102.7000 - val_mse: 1102.7000\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1402.1508 - mse: 1402.1508 - val_loss: 969.1476 - val_mse: 969.1476\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 1202.3734 - mse: 1202.3734 - val_loss: 892.0419 - val_mse: 892.0419\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 983.5329 - mse: 983.5329 - val_loss: 786.3249 - val_mse: 786.3249\n",
            "mse: 786.3248901367188\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 446 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "mse: 0.023791462182998657\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 447 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 7ms/step - loss: 399047.1875 - mse: 399047.1875 - val_loss: 2856.9219 - val_mse: 2856.9219\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 1311.2681 - mse: 1311.2681 - val_loss: 430.3125 - val_mse: 430.3125\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 838.2409 - mse: 838.2408 - val_loss: 347.5851 - val_mse: 347.5851\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 1518.5664 - mse: 1518.5664 - val_loss: 535.2596 - val_mse: 535.2596\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 833.5378 - mse: 833.5378 - val_loss: 415.7680 - val_mse: 415.7680\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 224.1025 - mse: 224.1025 - val_loss: 248.0143 - val_mse: 248.0143\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 219.5770 - mse: 219.5770 - val_loss: 224.3541 - val_mse: 224.3541\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 387.6346 - mse: 387.6346 - val_loss: 196.9170 - val_mse: 196.9170\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 234.5923 - mse: 234.5923 - val_loss: 265.5196 - val_mse: 265.5196\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 277.0735 - mse: 277.0735 - val_loss: 205.4080 - val_mse: 205.4080\n",
            "mse: 205.4080352783203\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 448 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 2s 11ms/step - loss: 0.4170 - mse: 0.4170 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0276 - val_mse: 0.0276\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "mse: 0.02259230986237526\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 449 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 10ms/step - loss: 61707.9219 - mse: 61707.9219 - val_loss: 480.9506 - val_mse: 480.9506\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 938.2406 - mse: 938.2406 - val_loss: 363.4081 - val_mse: 363.4081\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1628.2347 - mse: 1628.2347 - val_loss: 291.0155 - val_mse: 291.0155\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 318.6489 - mse: 318.6489 - val_loss: 119.9998 - val_mse: 119.9998\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 650.6790 - mse: 650.6790 - val_loss: 330.4779 - val_mse: 330.4779\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 659.4510 - mse: 659.4510 - val_loss: 547.6180 - val_mse: 547.6181\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 310.0643 - mse: 310.0643 - val_loss: 517.4996 - val_mse: 517.4996\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 4087.3877 - mse: 4087.3877 - val_loss: 221.4056 - val_mse: 221.4056\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3609.5435 - mse: 3609.5435 - val_loss: 797.3195 - val_mse: 797.3195\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 555.5457 - mse: 555.5457 - val_loss: 102.1894 - val_mse: 102.1894\n",
            "mse: 102.18936920166016\n",
            "dropout: 0.5 batch_size: 20 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 450 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.1942 - mse: 0.1942 - val_loss: 0.0507 - val_mse: 0.0507\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0354 - val_mse: 0.0354\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0396 - val_mse: 0.0396\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "mse: 0.033987827599048615\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 451 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 15ms/step - loss: 15475523.0000 - mse: 15475523.0000 - val_loss: 186062.8750 - val_mse: 186062.8750\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 58589.2188 - mse: 58589.2188 - val_loss: 3741.8945 - val_mse: 3741.8945\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 5041.9927 - mse: 5041.9927 - val_loss: 3301.2156 - val_mse: 3301.2156\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1607.6874 - mse: 1607.6874 - val_loss: 951.2276 - val_mse: 951.2276\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 862.3855 - mse: 862.3855 - val_loss: 731.5424 - val_mse: 731.5424\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 621.7271 - mse: 621.7271 - val_loss: 490.3528 - val_mse: 490.3528\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 414.2004 - mse: 414.2004 - val_loss: 351.8702 - val_mse: 351.8702\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 326.8119 - mse: 326.8119 - val_loss: 254.0827 - val_mse: 254.0827\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 235.4790 - mse: 235.4790 - val_loss: 239.1297 - val_mse: 239.1297\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 184.3466 - mse: 184.3466 - val_loss: 135.2240 - val_mse: 135.2240\n",
            "mse: 135.22398376464844\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 452 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 0.8723 - mse: 0.8723 - val_loss: 0.0796 - val_mse: 0.0796\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0409 - val_mse: 0.0409\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0414 - val_mse: 0.0414\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0353 - val_mse: 0.0353\n",
            "mse: 0.03534604609012604\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 453 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 24085314.0000 - mse: 24085314.0000 - val_loss: 7501.8101 - val_mse: 7501.8101\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 18609.4727 - mse: 18609.4727 - val_loss: 2849.4275 - val_mse: 2849.4275\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 1456.0336 - mse: 1456.0336 - val_loss: 88.0704 - val_mse: 88.0704\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 225.1114 - mse: 225.1114 - val_loss: 87.4328 - val_mse: 87.4328\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 84.2449 - mse: 84.2449 - val_loss: 39.6382 - val_mse: 39.6382\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 72.4305 - mse: 72.4305 - val_loss: 55.7189 - val_mse: 55.7189\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 53.7270 - mse: 53.7270 - val_loss: 47.6930 - val_mse: 47.6930\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 36.8172 - mse: 36.8172 - val_loss: 68.4172 - val_mse: 68.4172\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 30.8036 - mse: 30.8036 - val_loss: 17.5845 - val_mse: 17.5845\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 17.1382 - mse: 17.1382 - val_loss: 8.9891 - val_mse: 8.9891\n",
            "mse: 8.98913288116455\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 454 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 2s 26ms/step - loss: 4.6786 - mse: 4.6786 - val_loss: 0.1696 - val_mse: 0.1696\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1391 - mse: 0.1391 - val_loss: 0.0913 - val_mse: 0.0913\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0398 - val_mse: 0.0398\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.032954152673482895\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 455 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 24ms/step - loss: 367464256.0000 - mse: 367464256.0000 - val_loss: 731.2598 - val_mse: 731.2598\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 15880.6953 - mse: 15880.6943 - val_loss: 1193.9202 - val_mse: 1193.9202\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 1153.9498 - mse: 1153.9498 - val_loss: 113.9934 - val_mse: 113.9934\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 145.0891 - mse: 145.0891 - val_loss: 56.8109 - val_mse: 56.8109\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 47.0257 - mse: 47.0257 - val_loss: 26.9363 - val_mse: 26.9363\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 21.9780 - mse: 21.9780 - val_loss: 15.4343 - val_mse: 15.4343\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 16.1464 - mse: 16.1464 - val_loss: 17.6262 - val_mse: 17.6262\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 12.1020 - mse: 12.1020 - val_loss: 7.0110 - val_mse: 7.0110\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 9.8184 - mse: 9.8184 - val_loss: 6.9098 - val_mse: 6.9098\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 8.5406 - mse: 8.5406 - val_loss: 5.2870 - val_mse: 5.2870\n",
            "mse: 5.287039279937744\n",
            "dropout: 0.5 batch_size: 100 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 456 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 19ms/step - loss: 0.0779 - mse: 0.0779 - val_loss: 0.0429 - val_mse: 0.0429\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "mse: 0.023744752630591393\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 457 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 588768.5000 - mse: 588768.5000 - val_loss: 85325.1719 - val_mse: 85325.1719\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 32114.0195 - mse: 32114.0195 - val_loss: 3276.7622 - val_mse: 3276.7622\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 6732.0625 - mse: 6732.0625 - val_loss: 2967.6353 - val_mse: 2967.6353\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2395.4668 - mse: 2395.4668 - val_loss: 1633.3120 - val_mse: 1633.3120\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1379.5127 - mse: 1379.5127 - val_loss: 825.7286 - val_mse: 825.7286\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 890.2711 - mse: 890.2711 - val_loss: 616.9119 - val_mse: 616.9119\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 810.6007 - mse: 810.6007 - val_loss: 417.6915 - val_mse: 417.6915\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 668.9318 - mse: 668.9318 - val_loss: 297.6813 - val_mse: 297.6813\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 696.4390 - mse: 696.4390 - val_loss: 251.2826 - val_mse: 251.2826\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 423.6572 - mse: 423.6572 - val_loss: 263.4491 - val_mse: 263.4491\n",
            "mse: 263.4490661621094\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 458 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 18ms/step - loss: 0.1759 - mse: 0.1759 - val_loss: 0.0632 - val_mse: 0.0632\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0406 - val_mse: 0.0406\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0293 - val_mse: 0.0293\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "mse: 0.026424899697303772\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 459 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 20ms/step - loss: 4060798.2500 - mse: 4060798.2500 - val_loss: 211226.6875 - val_mse: 211226.6875\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 155649.9375 - mse: 155649.9375 - val_loss: 17200.5469 - val_mse: 17200.5469\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 16312.5303 - mse: 16312.5303 - val_loss: 7516.6763 - val_mse: 7516.6763\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2826.9102 - mse: 2826.9102 - val_loss: 1837.5430 - val_mse: 1837.5430\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 896.0956 - mse: 896.0956 - val_loss: 566.6663 - val_mse: 566.6663\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 431.2385 - mse: 431.2385 - val_loss: 333.5688 - val_mse: 333.5688\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 283.5458 - mse: 283.5458 - val_loss: 255.6755 - val_mse: 255.6755\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 199.6508 - mse: 199.6508 - val_loss: 126.1274 - val_mse: 126.1274\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 271.9593 - mse: 271.9593 - val_loss: 213.4934 - val_mse: 213.4934\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 125.5385 - mse: 125.5385 - val_loss: 116.4694 - val_mse: 116.4694\n",
            "mse: 116.46939849853516\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 460 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 28ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 0.0482 - val_mse: 0.0482\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "mse: 0.022273221984505653\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 461 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 25ms/step - loss: 6073434.5000 - mse: 6073434.5000 - val_loss: 8102.3574 - val_mse: 8102.3574\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 116415.0000 - mse: 116415.0000 - val_loss: 7628.5273 - val_mse: 7628.5283\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 7886.5859 - mse: 7886.5859 - val_loss: 2168.5171 - val_mse: 2168.5171\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 921.8498 - mse: 921.8498 - val_loss: 248.7476 - val_mse: 248.7476\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 318.9818 - mse: 318.9818 - val_loss: 248.4571 - val_mse: 248.4571\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 225.6034 - mse: 225.6034 - val_loss: 58.1108 - val_mse: 58.1108\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 474.1468 - mse: 474.1469 - val_loss: 54.5480 - val_mse: 54.5480\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 325.7529 - mse: 325.7529 - val_loss: 24.7153 - val_mse: 24.7153\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 93.7223 - mse: 93.7223 - val_loss: 15.7293 - val_mse: 15.7293\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 43.4845 - mse: 43.4845 - val_loss: 14.5233 - val_mse: 14.5233\n",
            "mse: 14.523258209228516\n",
            "dropout: 0.5 batch_size: 100 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 462 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 0.1380 - mse: 0.1380 - val_loss: 0.0788 - val_mse: 0.0788\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0356 - val_mse: 0.0356\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "mse: 0.032998502254486084\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 463 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 16ms/step - loss: 40324596.0000 - mse: 40324596.0000 - val_loss: 10056822.0000 - val_mse: 10056822.0000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2721056.0000 - mse: 2721056.0000 - val_loss: 140310.2344 - val_mse: 140310.2344\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 347234.7500 - mse: 347234.7500 - val_loss: 171000.0000 - val_mse: 171000.0000\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 72022.7578 - mse: 72022.7578 - val_loss: 58207.1484 - val_mse: 58207.1484\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 42956.6680 - mse: 42956.6602 - val_loss: 35643.7266 - val_mse: 35643.7227\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 26635.0957 - mse: 26635.0957 - val_loss: 22643.1816 - val_mse: 22643.1816\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 15732.9854 - mse: 15732.9854 - val_loss: 14788.6084 - val_mse: 14788.6084\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 10774.9365 - mse: 10774.9365 - val_loss: 11949.4502 - val_mse: 11949.4502\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 9067.5654 - mse: 9067.5664 - val_loss: 10709.2041 - val_mse: 10709.2041\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 8164.6460 - mse: 8164.6460 - val_loss: 9787.5508 - val_mse: 9787.5498\n",
            "mse: 9787.55078125\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 464 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 26ms/step - loss: 0.6273 - mse: 0.6273 - val_loss: 0.2429 - val_mse: 0.2429\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0984 - mse: 0.0984 - val_loss: 0.0367 - val_mse: 0.0367\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0324 - val_mse: 0.0324\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "mse: 0.03214075043797493\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 465 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 17ms/step - loss: 864219.1875 - mse: 864219.1875 - val_loss: 30544.1426 - val_mse: 30544.1426\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 76571.8672 - mse: 76571.8672 - val_loss: 38111.5781 - val_mse: 38111.5781\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 10161.0117 - mse: 10161.0117 - val_loss: 4891.7695 - val_mse: 4891.7695\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 2432.7366 - mse: 2432.7366 - val_loss: 823.7599 - val_mse: 823.7599\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 861.2286 - mse: 861.2286 - val_loss: 614.6059 - val_mse: 614.6059\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 614.9765 - mse: 614.9765 - val_loss: 556.0443 - val_mse: 556.0443\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 524.7538 - mse: 524.7538 - val_loss: 484.6549 - val_mse: 484.6549\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 436.5267 - mse: 436.5267 - val_loss: 434.3028 - val_mse: 434.3028\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 381.7574 - mse: 381.7574 - val_loss: 388.5981 - val_mse: 388.5981\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 324.0355 - mse: 324.0355 - val_loss: 345.8469 - val_mse: 345.8469\n",
            "mse: 345.846923828125\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 466 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 22ms/step - loss: 1.1608 - mse: 1.1608 - val_loss: 0.0627 - val_mse: 0.0627\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0616 - mse: 0.0616 - val_loss: 0.0650 - val_mse: 0.0650\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0367 - val_mse: 0.0367\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0326 - val_mse: 0.0326\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "mse: 0.031270597130060196\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 467 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 2s 24ms/step - loss: 3221769.5000 - mse: 3221769.5000 - val_loss: 558683.2500 - val_mse: 558683.2500\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 254220.1250 - mse: 254220.1094 - val_loss: 9203.0332 - val_mse: 9203.0322\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 28524.1797 - mse: 28524.1797 - val_loss: 7600.9731 - val_mse: 7600.9731\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 5315.1294 - mse: 5315.1289 - val_loss: 1693.5826 - val_mse: 1693.5826\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 1353.8517 - mse: 1353.8517 - val_loss: 636.9527 - val_mse: 636.9527\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 701.0428 - mse: 701.0428 - val_loss: 552.2153 - val_mse: 552.2153\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 533.6452 - mse: 533.6452 - val_loss: 416.3128 - val_mse: 416.3128\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 426.5497 - mse: 426.5497 - val_loss: 347.7766 - val_mse: 347.7766\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 361.2231 - mse: 361.2231 - val_loss: 306.8053 - val_mse: 306.8053\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 306.4055 - mse: 306.4055 - val_loss: 255.9247 - val_mse: 255.9247\n",
            "mse: 255.92466735839844\n",
            "dropout: 0.5 batch_size: 100 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 468 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 37ms/step - loss: 0.1848 - mse: 0.1848 - val_loss: 0.1133 - val_mse: 0.1133\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0635 - mse: 0.0635 - val_loss: 0.0371 - val_mse: 0.0371\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0418 - val_mse: 0.0418\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0375 - val_mse: 0.0375\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "mse: 0.03292401507496834\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 469 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 31ms/step - loss: 107907264.0000 - mse: 107907264.0000 - val_loss: 530152.0000 - val_mse: 530152.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 230559.9844 - mse: 230559.9844 - val_loss: 1517.0411 - val_mse: 1517.0411\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 37738.3750 - mse: 37738.3750 - val_loss: 23545.7109 - val_mse: 23545.7109\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 13889.0859 - mse: 13889.0859 - val_loss: 10788.4619 - val_mse: 10788.4619\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 6107.1514 - mse: 6107.1514 - val_loss: 5355.9668 - val_mse: 5355.9668\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3290.9150 - mse: 3290.9150 - val_loss: 2896.2661 - val_mse: 2896.2661\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1375.1906 - mse: 1375.1906 - val_loss: 1284.8567 - val_mse: 1284.8567\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 680.5721 - mse: 680.5721 - val_loss: 215.9418 - val_mse: 215.9418\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 307.3151 - mse: 307.3151 - val_loss: 140.5340 - val_mse: 140.5340\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 241.6482 - mse: 241.6482 - val_loss: 207.5385 - val_mse: 207.5385\n",
            "mse: 207.5384979248047\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 470 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 35ms/step - loss: 1.0302 - mse: 1.0302 - val_loss: 0.0703 - val_mse: 0.0703\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1600 - mse: 0.1600 - val_loss: 0.1426 - val_mse: 0.1426\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0786 - mse: 0.0786 - val_loss: 0.0736 - val_mse: 0.0736\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0339 - val_mse: 0.0339\n",
            "mse: 0.033876121044158936\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 471 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 37ms/step - loss: 41534600.0000 - mse: 41534600.0000 - val_loss: 8968.8135 - val_mse: 8968.8135\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 204488.2031 - mse: 204488.2344 - val_loss: 21443.4082 - val_mse: 21443.4082\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 39284.5352 - mse: 39284.5391 - val_loss: 2197.3655 - val_mse: 2197.3655\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 13826.3525 - mse: 13826.3525 - val_loss: 5812.0479 - val_mse: 5812.0479\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 5274.8740 - mse: 5274.8740 - val_loss: 792.5199 - val_mse: 792.5199\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1994.3291 - mse: 1994.3291 - val_loss: 816.1671 - val_mse: 816.1671\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 855.6406 - mse: 855.6405 - val_loss: 702.4903 - val_mse: 702.4903\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 443.6166 - mse: 443.6166 - val_loss: 245.6551 - val_mse: 245.6551\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 221.8010 - mse: 221.8010 - val_loss: 108.3832 - val_mse: 108.3832\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 129.0842 - mse: 129.0842 - val_loss: 108.9294 - val_mse: 108.9294\n",
            "mse: 108.92938995361328\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 472 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 44ms/step - loss: 6.1608 - mse: 6.1608 - val_loss: 0.0373 - val_mse: 0.0373\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.6137 - mse: 0.6137 - val_loss: 0.0381 - val_mse: 0.0381\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.1995 - mse: 0.1995 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 0.0378 - val_mse: 0.0378\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0368 - val_mse: 0.0368\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0421 - val_mse: 0.0421\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0349 - val_mse: 0.0349\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0328 - val_mse: 0.0328\n",
            "mse: 0.03275790438055992\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 473 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 35ms/step - loss: 1171716864.0000 - mse: 1171716864.0000 - val_loss: 132991.6250 - val_mse: 132991.6250\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 942503.6875 - mse: 942503.6875 - val_loss: 289377.4688 - val_mse: 289377.4688\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 69999.1953 - mse: 69999.1953 - val_loss: 36315.7617 - val_mse: 36315.7617\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 9435.0391 - mse: 9435.0391 - val_loss: 271.9270 - val_mse: 271.9270\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 174.6664 - mse: 174.6664 - val_loss: 79.9268 - val_mse: 79.9268\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 40.2010 - mse: 40.2010 - val_loss: 11.3379 - val_mse: 11.3379\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 18.7445 - mse: 18.7445 - val_loss: 1122.4172 - val_mse: 1122.4172\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 238.9569 - mse: 238.9569 - val_loss: 79.7845 - val_mse: 79.7845\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 43.8967 - mse: 43.8967 - val_loss: 54.9301 - val_mse: 54.9301\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 26.5958 - mse: 26.5958 - val_loss: 15.3899 - val_mse: 15.3899\n",
            "mse: 15.38990592956543\n",
            "dropout: 0.5 batch_size: 200 lr: 0.01\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 474 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 28ms/step - loss: 0.2013 - mse: 0.2013 - val_loss: 0.0752 - val_mse: 0.0752\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0826 - mse: 0.0826 - val_loss: 0.0358 - val_mse: 0.0358\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0501 - val_mse: 0.0501\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0333 - val_mse: 0.0333\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "mse: 0.03148757666349411\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 475 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 26ms/step - loss: 730596.6250 - mse: 730596.6250 - val_loss: 456540.6562 - val_mse: 456540.6562\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 213739.1719 - mse: 213739.1719 - val_loss: 150357.3906 - val_mse: 150357.3750\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 84643.6641 - mse: 84643.6641 - val_loss: 49360.3242 - val_mse: 49360.3242\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 32773.0039 - mse: 32773.0039 - val_loss: 23310.1777 - val_mse: 23310.1777\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 14120.6855 - mse: 14120.6875 - val_loss: 8132.0176 - val_mse: 8132.0176\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5159.8877 - mse: 5159.8877 - val_loss: 1591.6301 - val_mse: 1591.6301\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2052.6082 - mse: 2052.6082 - val_loss: 942.3228 - val_mse: 942.3228\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1104.7091 - mse: 1104.7092 - val_loss: 800.5454 - val_mse: 800.5454\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 646.9946 - mse: 646.9946 - val_loss: 521.4427 - val_mse: 521.4427\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 422.7811 - mse: 422.7811 - val_loss: 273.3445 - val_mse: 273.3445\n",
            "mse: 273.3445129394531\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 476 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 31ms/step - loss: 0.3092 - mse: 0.3092 - val_loss: 0.1253 - val_mse: 0.1253\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0782 - mse: 0.0782 - val_loss: 0.0845 - val_mse: 0.0845\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0472 - val_mse: 0.0472\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0424 - val_mse: 0.0424\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "mse: 0.03120066411793232\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 477 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 29ms/step - loss: 2346113.5000 - mse: 2346113.5000 - val_loss: 267233.5000 - val_mse: 267233.4688\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 172147.7188 - mse: 172147.7188 - val_loss: 50092.2188 - val_mse: 50092.2188\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 36856.8008 - mse: 36856.7969 - val_loss: 22577.0156 - val_mse: 22577.0156\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 14501.6934 - mse: 14501.6934 - val_loss: 4108.0469 - val_mse: 4108.0469\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 4145.8462 - mse: 4145.8462 - val_loss: 1316.1976 - val_mse: 1316.1976\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1948.6368 - mse: 1948.6368 - val_loss: 1171.7986 - val_mse: 1171.7986\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1283.5706 - mse: 1283.5706 - val_loss: 1217.7555 - val_mse: 1217.7555\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 593.7605 - mse: 593.7605 - val_loss: 374.0539 - val_mse: 374.0539\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 341.3696 - mse: 341.3696 - val_loss: 330.6535 - val_mse: 330.6535\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 223.3457 - mse: 223.3457 - val_loss: 220.4141 - val_mse: 220.4141\n",
            "mse: 220.4140625\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 478 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 39ms/step - loss: 0.9275 - mse: 0.9275 - val_loss: 0.0365 - val_mse: 0.0365\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1947 - mse: 0.1947 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0299 - val_mse: 0.0299\n",
            "mse: 0.029875846579670906\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 479 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 38ms/step - loss: 7703723.5000 - mse: 7703723.5000 - val_loss: 38676.0273 - val_mse: 38676.0273\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 292932.7500 - mse: 292932.7500 - val_loss: 224067.0625 - val_mse: 224067.0625\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 88283.9766 - mse: 88283.9766 - val_loss: 55673.8242 - val_mse: 55673.8242\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 24989.2539 - mse: 24989.2539 - val_loss: 3611.5562 - val_mse: 3611.5562\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 8406.0889 - mse: 8406.0889 - val_loss: 5157.5410 - val_mse: 5157.5405\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 3371.7805 - mse: 3371.7800 - val_loss: 2010.9728 - val_mse: 2010.9728\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 1125.8214 - mse: 1125.8214 - val_loss: 581.3615 - val_mse: 581.3615\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 467.9352 - mse: 467.9352 - val_loss: 107.1890 - val_mse: 107.1890\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 179.2756 - mse: 179.2756 - val_loss: 200.4112 - val_mse: 200.4112\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 116.2944 - mse: 116.2944 - val_loss: 80.8146 - val_mse: 80.8145\n",
            "mse: 80.8145523071289\n",
            "dropout: 0.5 batch_size: 200 lr: 0.001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 480 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 34ms/step - loss: 1.4471 - mse: 1.4471 - val_loss: 1.3349 - val_mse: 1.3349\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1851 - mse: 1.1851 - val_loss: 1.0874 - val_mse: 1.0874\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9561 - mse: 0.9561 - val_loss: 0.8735 - val_mse: 0.8735\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.7602 - mse: 0.7602 - val_loss: 0.6924 - val_mse: 0.6924\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5964 - mse: 0.5964 - val_loss: 0.5421 - val_mse: 0.5421\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4613 - mse: 0.4613 - val_loss: 0.4196 - val_mse: 0.4196\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3528 - mse: 0.3528 - val_loss: 0.3211 - val_mse: 0.3211\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2663 - mse: 0.2663 - val_loss: 0.2439 - val_mse: 0.2439\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1996 - mse: 0.1996 - val_loss: 0.1842 - val_mse: 0.1842\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1487 - mse: 0.1487 - val_loss: 0.1393 - val_mse: 0.1393\n",
            "mse: 0.1392749696969986\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: sigmoid layers: 3\n",
            "models fitted: 481 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 33ms/step - loss: 12651075.0000 - mse: 12651075.0000 - val_loss: 2213021.0000 - val_mse: 2213021.0000\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 710024.0000 - mse: 710024.0000 - val_loss: 911146.6875 - val_mse: 911146.6875\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1033225.9375 - mse: 1033225.9375 - val_loss: 396231.3750 - val_mse: 396231.4062\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 215616.9062 - mse: 215616.9062 - val_loss: 210078.9375 - val_mse: 210078.9375\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 193257.3281 - mse: 193257.3281 - val_loss: 164531.4062 - val_mse: 164531.4062\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 88817.9844 - mse: 88817.9844 - val_loss: 61451.6133 - val_mse: 61451.6133\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 53137.1836 - mse: 53137.1836 - val_loss: 27754.0234 - val_mse: 27754.0234\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 18152.0293 - mse: 18152.0293 - val_loss: 9492.9141 - val_mse: 9492.9141\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 5743.0034 - mse: 5743.0034 - val_loss: 3907.8018 - val_mse: 3907.8015\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 4079.8687 - mse: 4079.8687 - val_loss: 3274.2043 - val_mse: 3274.2043\n",
            "mse: 3274.204345703125\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 64 activation: relu layers: 3\n",
            "models fitted: 482 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 38ms/step - loss: 0.3194 - mse: 0.3194 - val_loss: 0.1736 - val_mse: 0.1736\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0924 - mse: 0.0924 - val_loss: 0.0460 - val_mse: 0.0460\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0336 - val_mse: 0.0336\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0361 - val_mse: 0.0361\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "mse: 0.03222629055380821\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: sigmoid layers: 3\n",
            "models fitted: 483 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 54ms/step - loss: 278448.2500 - mse: 278448.2500 - val_loss: 12505.8867 - val_mse: 12505.8867\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 65211.4414 - mse: 65211.4414 - val_loss: 36050.2852 - val_mse: 36050.2852\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 28503.6113 - mse: 28503.6113 - val_loss: 25971.8438 - val_mse: 25971.8438\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 11848.9824 - mse: 11848.9824 - val_loss: 6732.7231 - val_mse: 6732.7231\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 4203.9556 - mse: 4203.9561 - val_loss: 1084.3735 - val_mse: 1084.3735\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 1936.1844 - mse: 1936.1844 - val_loss: 2014.6404 - val_mse: 2014.6404\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1204.4625 - mse: 1204.4625 - val_loss: 661.7195 - val_mse: 661.7195\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 647.1119 - mse: 647.1119 - val_loss: 581.8359 - val_mse: 581.8359\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 532.0417 - mse: 532.0417 - val_loss: 409.3867 - val_mse: 409.3867\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 428.2443 - mse: 428.2443 - val_loss: 379.9152 - val_mse: 379.9152\n",
            "mse: 379.91522216796875\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 128 activation: relu layers: 3\n",
            "models fitted: 484 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 53ms/step - loss: 1.2849 - mse: 1.2849 - val_loss: 0.4645 - val_mse: 0.4645\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.1752 - mse: 0.1752 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0790 - val_mse: 0.0790\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0446 - val_mse: 0.0446\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0368 - val_mse: 0.0368\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0322 - val_mse: 0.0322\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "mse: 0.03140552341938019\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: sigmoid layers: 3\n",
            "models fitted: 485 /162\n",
            "----------------------------------------------\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 40ms/step - loss: 2319675.0000 - mse: 2319675.0000 - val_loss: 1008051.5625 - val_mse: 1008051.5625\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 363997.2812 - mse: 363997.2812 - val_loss: 410990.8438 - val_mse: 410990.8438\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 138794.0000 - mse: 138794.0000 - val_loss: 153248.3906 - val_mse: 153248.3906\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 60513.9766 - mse: 60513.9766 - val_loss: 55344.9492 - val_mse: 55344.9492\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 24877.8984 - mse: 24877.8984 - val_loss: 20795.0938 - val_mse: 20795.0938\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 10640.9980 - mse: 10640.9980 - val_loss: 9935.3525 - val_mse: 9935.3525\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 4894.2949 - mse: 4894.2949 - val_loss: 4057.6338 - val_mse: 4057.6338\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 2310.6841 - mse: 2310.6841 - val_loss: 2036.8491 - val_mse: 2036.8491\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 1208.8478 - mse: 1208.8478 - val_loss: 647.1905 - val_mse: 647.1905\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 665.2618 - mse: 665.2618 - val_loss: 495.4966 - val_mse: 495.4966\n",
            "mse: 495.4965515136719\n",
            "dropout: 0.5 batch_size: 200 lr: 0.0001\n",
            "nodes: 256 activation: relu layers: 3\n",
            "models fitted: 486 /162\n",
            "----------------------------------------------\n",
            "The best_hps are: {'dropout': 0.3, 'batch_size': 200, 'lr': 0.001, 'layers': 1, 'nodes': 256, 'activation': 'sigmoid'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best_hps are:\", hps[np.argmin(val_losses)])\n",
        "print(\"mse: \", np.min(val_losses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcrJIBezMGMh",
        "outputId": "b2f187ec-3157-48e4-e133-86550ff364e9"
      },
      "id": "VcrJIBezMGMh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best_hps are: {'dropout': 0.3, 'batch_size': 200, 'lr': 0.001, 'layers': 1, 'nodes': 256, 'activation': 'sigmoid'}\n",
            "mse:  0.01998710073530674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropout = hps[np.argmin(val_losses)]['dropout']\n",
        "batch_size = hps[np.argmin(val_losses)]['batch_size']\n",
        "lr = hps[np.argmin(val_losses)]['lr']\n",
        "nodes = hps[np.argmin(val_losses)]['nodes']\n",
        "activation = hps[np.argmin(val_losses)]['activation']\n",
        "layers = hps[np.argmin(val_losses)]['layers']"
      ],
      "metadata": {
        "id": "b7pXziUYr_2s"
      },
      "id": "b7pXziUYr_2s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "p7RF4FGdGarC"
      },
      "id": "p7RF4FGdGarC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will train multiple models with the best_hps and validate each one to ensure that the model is not prone to overfitting and the find the best number of epochs."
      ],
      "metadata": {
        "id": "P5lBSNXgXnD3"
      },
      "id": "P5lBSNXgXnD3"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(nodes, activation=activation, input_shape=(X_train.shape[1],)))\n",
        "if layers == 1:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 2:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 3:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mse',\n",
        "              optimizer=keras.optimizers.Adam(lr=lr),\n",
        "              metrics=['mse'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, y_val))\n",
        "\n",
        "plt.plot(np.arange(1,101,1), np.array(history.history['val_mse']), np.arange(1,101,1), np.array(history.history['mse']))\n",
        "plt.legend(['val_mse','train_mse'])\n",
        "plt.rcParams['figure.figsize'] = [8,8]\n",
        "plt.ylim([.02, 0.04])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3774
        },
        "id": "PprVH-y1SU_s",
        "outputId": "9ee669aa-73c5-48d0-ce2d-2c969941cfc0"
      },
      "id": "PprVH-y1SU_s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 32ms/step - loss: 0.1419 - mse: 0.1419 - val_loss: 0.0775 - val_mse: 0.0775\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0474 - val_mse: 0.0474\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0334 - val_mse: 0.0334\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0267 - val_mse: 0.0267\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0270 - val_mse: 0.0270\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0270 - val_mse: 0.0270\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0278 - val_mse: 0.0278\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0305 - val_mse: 0.0305\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0281 - val_mse: 0.0281\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0267 - val_mse: 0.0267\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0262 - val_mse: 0.0262\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0367 - val_mse: 0.0367\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0308 - val_mse: 0.0308\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0276 - val_mse: 0.0276\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0283 - val_mse: 0.0283\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0275 - val_mse: 0.0275\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(nodes, activation=activation, input_shape=(X_train.shape[1],)))\n",
        "if layers == 1:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 2:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 3:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mse',\n",
        "              optimizer=keras.optimizers.Adam(lr=lr),\n",
        "              metrics=['mse'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, y_val))\n",
        "\n",
        "plt.plot(np.arange(1,51,1), np.array(history.history['val_mse']), np.arange(1,51,1), np.array(history.history['mse']))\n",
        "plt.legend(['val_mse','train_mse'])\n",
        "plt.rcParams['figure.figsize'] = [8,8]\n",
        "plt.ylim([.015, 0.04])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2257
        },
        "id": "fN1Mp5fkzPuo",
        "outputId": "ade2a172-990f-48ab-8a08-44a121dbda40"
      },
      "id": "fN1Mp5fkzPuo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 29ms/step - loss: 0.9347 - mse: 0.9347 - val_loss: 0.0872 - val_mse: 0.0872\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1788 - mse: 0.1788 - val_loss: 0.0330 - val_mse: 0.0330\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0199 - val_mse: 0.0199\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0235 - val_mse: 0.0235\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAHWCAYAAACFR6uKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde5ycZX3//9dnZnZmd3aT7CYsJNmciRAIgUAOoOAJCoJFkAoEFAsWG61Srfr1a2wtUr60lf7aorUWCkJVtHKIRWOJBSxEkEPIgYQkhJAj2c1xs5tNNns+XL8/5p7NZrObnXvmmmx2834+HnnMzD33XHNP9JE3n/s6mXMOERERGRoiA30BIiIi4o+CXUREZAhRsIuIiAwhCnYREZEhRMEuIiIyhCjYRUREhpCMgt3MrjSzDWa2ycwW9PJ+wsweD95famaTerw/wcwOmdn/6a9NM5sctLEpaDOe/c8TERE5ufQb7GYWBX4AXAWcDdxsZmf3OO12YL9zbipwH3Bvj/f/GfhNhm3eC9wXtLU/aFtEREQykEnFPhfY5Jzb4pxrBR4Dru1xzrXAj4PnC4HLzMwAzOzjwFZgXX9tBp+5NGiDoM2Ph/9ZIiIiJ6dMgr0CqOz2uio41us5zrl24AAwysxKgG8Af5Nhm6OAuqCNvr5LRERE+hDLc/t3kbqtfigo4L0xs/nAfIDi4uJZ06ZN89p+b5rbOtm4t54JI5OMKCrIrbG2RqjeACOnQOEIPxcoIiInhRUrVuxzzpX39l4mwb4DGN/t9bjgWG/nVJlZDBgB1AAXAteb2T8ApUCnmTUDK/poswYoNbNYULX39l0AOOceBB4EmD17tlu+fHkGPyU3G/fUc/l9L3LfJ8/n6nPH5tbYnnVw//vghv8Ppqu3QUREMmdm7/b1XibBvgx4j5lNJhWyNwGf7HHOIuBW4FXgeuB5l9pd5v3dLuIu4JBz7l+D8D+qTeecM7MXgjYeC9r8VUa/8jhI33Xo9LFvTqww9djR6qExERGRlH772IPK+Q7gGWA98IRzbp2Z3W1m1wSnPUyqT30T8FXgqClxmbQZvP0N4KtBW6OCtk8IkaA3wcuOeNFgFl97c+5tiYiIBDLqY3fOLQYW9zh2Z7fnzcAN/bRxV39tBse3kBo1f8I5XLF7CPZ0xd7ekntbIiIigXwPnhtSDlfsHhqLpSt2BbuIDB1tbW1UVVXR3Ky7kT4UFhYybtw4CgoyH7CtYA8hkpc+dgW7iAwdVVVVDBs2jEmTJuF7NtTJxjlHTU0NVVVVTJ48OePPaa34ENL/H/VyKz6qil1Ehp7m5mZGjRqlUPfAzBg1alToux8K9hDSFbuXwXNmEE0o2EVkyFGo+5PN36WCPYTDFbunBmMKdhER8UvBHsLhit1Tg7GE+thFRAZQSUnJQF+Cdwr2ELz2sYNuxYuIiHcaFR+C1z520K14ERnS/ubX63hr50GvbZ49djjf/tj0Pt9fsGAB48eP54tf/CIAd911F7FYjBdeeIH9+/fT1tbGPffcw7XX9tyk9GhLlizh29/+NqWlpaxZs4Ybb7yRGTNm8L3vfY+mpiZ++ctfcvrpp/Pkk0/yN3/zN0SjUUaMGMGLL75IR0cHCxYsYMmSJbS0tPDFL36Rz33uc97+Ho5FFXsIXqe7QRDsmuspIuLLvHnzeOKJJ7peP/HEE9x666089dRTrFy5khdeeIGvfe1rGRdoq1ev5oEHHmD9+vU8+uijvPPOO7z++ut89rOf5fvf/z4Ad999N8888wyrV69m0aJFADz88MOMGDGCZcuWsWzZMh566CG2bt3q/wf3QhV7COmxid5uxccSWiteRIasY1XW+XL++eezd+9edu7cSXV1NWVlZYwePZqvfOUrvPjii0QiEXbs2MGePXsYPXp0v+3NmTOHMWPGAHD66adzxRVXADBjxgxeeOEFAC6++GJuu+02brzxRv7oj/4IgGeffZY333yThQsXAnDgwAE2btwYaj56thTsIXgfPBdVxS4i4tsNN9zAwoUL2b17N/PmzeNnP/sZ1dXVrFixgoKCAiZNmpTx3PBEItH1PBKJdL2ORCK0t7cD8MADD7B06VKefvppZs2axYoVK3DO8f3vf5+PfOQj/n9gP3QrPgQL/ra8VuztqthFRHyaN28ejz32GAsXLuSGG27gwIEDnHrqqRQUFPDCCy/w7rt97nialc2bN3PhhRdy9913U15eTmVlJR/5yEe4//77aWtrA+Cdd96hoaHB6/f2RRV7CHmZ7tZ8wFNjIiICMH36dOrr66moqGDMmDF86lOf4mMf+xgzZsxg9uzZTJs2zev3ff3rX2fjxo0457jssss477zzOPfcc9m2bRsXXHABzjnKy8v55S9/6fV7+2LeRngPoNmzZ7vly5fn/XsaW9s5+85n+OZV0/jcB0/PvcHHb4GazfCFV3NvS0TkBLB+/XrOOuusgb6MIaW3v1MzW+Gcm93b+boVH4LheVS8+thFRMQz3YoPIb1AjcNXH3uh+thFRAbYmjVr+PSnP33EsUQiwdKlSwfoinKjYA/Bfx97XBW7iMgAmzFjBqtWrRroy/BGt+JDiKSXlPV1Lz5WqHnsIiLilYI9BO8rz0VVsYuIiF8K9hC8bwKTrtiHwMwEERE5MSjYQ0hveO8thmPx1KM2ghEREU8U7CFFzOfuboWpR+3JLiLiRV1dHf/2b/8W+nMf/ehHqaury8MVHX8K9pAiZh73Y1fFLiLiU1/Bnl7XvS+LFy+mtLQ0X5d1XGm6W0ipYPfUWLpiV7CLyFD0mwWwe43fNkfPgKu+0+fbCxYsYPPmzcycOZOCggIKCwspKyvj7bff5p133uHjH/84lZWVNDc38+Uvf5n58+cDMGnSJJYvX86hQ4e46qqruOSSS3jllVeoqKjgV7/6FUVFRb1+34c+9CHOP/98XnrpJRoaGvjJT37C3//937NmzRrmzZvHPffcQ0NDAzfeeCNVVVV0dHTw13/918ybN48VK1bw1a9+lUOHDnHKKafwox/9qGsnuVwo2MMyz5vAgIJdRMST73znO6xdu5ZVq1axZMkS/vAP/5C1a9d2bZf6yCOPMHLkSJqampgzZw6f+MQnGDVq1BFtbNy4kZ///Oc89NBD3HjjjfziF7/glltu6fM74/E4y5cv53vf+x7XXnstK1asYOTIkZx++ul85StfYcmSJYwdO5ann34aSG3h2tbWxp//+Z/zq1/9ivLych5//HH+6q/+ikceeSTnvwMFe0gRw9/ouXSwq49dRIaiY1TWx8vcuXOP2AP9X/7lX3jqqacAqKysZOPGjUcF++TJk5k5cyYAs2bNYtu2bcf8jmuuuQZILXQzffr0rqp7ypQpVFZWMmPGDL72ta/xjW98g6uvvpr3v//9rF27lrVr13L55ZcD0NHR4aVaBwV7aH772NMVu+ayi4jkQ3FxcdfzJUuW8Nvf/pZXX32VZDLJhz70oV73Ze++B3s0GqWpqemY39F9j/ae+7e3t7dzxhlnsHLlShYvXsy3vvUtLrvsMq677jqmT5/Oq6/63wRMg+dC8tvHng52rT4nIuLDsGHDqK+v7/W9AwcOUFZWRjKZ5O233+a11147Lte0c+dOkskkt9xyC1//+tdZuXIlZ555JtXV1V3B3tbWxrp167x8nyr2kCwvfeyq2EVEfBg1ahQXX3wx55xzDkVFRZx22mld71155ZU88MADnHXWWZx55plcdNFFx+Wa1qxZw9e//nUikQgFBQXcf//9xONxFi5cyJe+9CUOHDhAe3s7f/EXf8H06dNz/j7txx7SuXc9wx9dMI67rsn9L58dK+ChS+GTT8AZH8m9PRGRAab92P3Tfux5FomYvwVq1McuIiKe6VZ8SPmZx64+dhGRE9kXv/hFXn755SOOffnLX+Yzn/nMAF1R3xTsIUW89rGnV55TxS4iciL7wQ9+MNCXkDHdig/J8lGxax67iAwhQ2Hs1okim79LBXtIhsf/02qteBEZYgoLC6mpqVG4e+Cco6amhsLCwlCf0634kCJm/rZP11rxIjLEjBs3jqqqKqqrqwf6UoaEwsJCxo0bF+ozCvaQvPaxq2IXkSGmoKDgiCVc5fjTrfiQvPaxRyKpcFcfu4iIeKJgDykS8TwwJJpQxS4iIt4o2EMyPG4CA6llZRXsIiLiiYI9pIj527UVULCLiIhXCvaQvK48B6lgVx+7iIh4omAPyevubhD0sWvlORER8UPBHlJqHrvvPnatFS8iIn4o2EMyg85Ojw3GVLGLiIg/CvaQImY4n8PnYgnoUMUuIiJ+ZBTsZnalmW0ws01mtqCX9xNm9njw/lIzmxQcn2tmq4I/q83suuD4md2OrzKzg2b2F8F7d5nZjm7vfdTfz82d1wVqQH3sIiLiVb9LyppZFPgBcDlQBSwzs0XOube6nXY7sN85N9XMbgLuBeYBa4HZzrl2MxsDrDazXzvnNgAzu7W/A3iqW3v3Oef+0cPv8y5inheoUR+7iIh4lEnFPhfY5Jzb4pxrBR4Dru1xzrXAj4PnC4HLzMycc43OufbgeCG9TwG/DNjsnHs3/OUff3mZ7qaKXUREPMkk2CuAym6vq4JjvZ4TBPkBYBSAmV1oZuuANcDnuwV92k3Az3scu8PM3jSzR8ysrLeLMrP5ZrbczJYfz12EvE93ixWqj11ERLzJ++A559xS59x0YA7wTTPr2ljWzOLANcCT3T5yP3A6qVv1u4B/6qPdB51zs51zs8vLy/N2/T2Zz21bIbUJjCp2ERHxJJNg3wGM7/Z6XHCs13PMLAaMAGq6n+CcWw8cAs7pdvgqYKVzbk+38/Y45zqcc53AQ6S6Ak4YXrdthVTFrj52ERHxJJNgXwa8x8wmBxX2TcCiHucsAm4Nnl8PPO+cc8FnYgBmNhGYBmzr9rmb6XEbPhhkl3YdqQF4J4yI74o9popdRET86XdUfDCi/Q7gGSAKPOKcW2dmdwPLnXOLgIeBR81sE1BLKvwBLgEWmFkb0Al8wTm3D8DMikmNtP9cj6/8BzObSWqg3bZe3h9QeanYO1rAuVQHvoiISA76DXYA59xiYHGPY3d2e94M3NDL5x4FHu2jzQaCAXY9jn86k2saKN63bY3GU48drakR8iIiIjnQynMhmeH5VnwwllBbt4qIiAcK9pD897EHVbqmvImIiAcK9pAiEd997EGwawCdiIh4oGAPKbXynOf92EG34kVExAsFexa8LykLCnYREfFCwR5SattWj7r62BXsIiKSOwV7SHnZ3Q1UsYuIiBcK9pDUxy4iIicyBXtIZkZnp8cGNY9dREQ8UrCH5H/b1vTKcwp2ERHJnYI9pIjv5dxVsYuIiEcK9pD897EHFbuCXUREPFCwh5QKdo8NdlXsWnlORERyp2APKX997ForXkREcqdgD8l8bwIT1VrxIiLij4I9pPwtUKOKXUREcqdgD8l7H3skCpGYKnYREfFCwR6S9z52SA2gUx+7iIh4oGAPKeK7jx1SU95UsYuIiAcK9pCMPFXsmscuIiIeKNhDykvFHosr2EVExAsFe0iRSL762BXsIiKSOwV7SOZ7VDwEfewKdhERyZ2CPSTv89hBfewiIuKNgj0kw/MmMJBapEbBLiIiHijYQ4oY+L4TTyyhPnYREfFCwR6SmdHpu5M9qopdRET8ULCHlJ/pbgp2ERHxQ8EeUiQvS8oq2EVExA8Fe0ipteI9N6o+dhER8UTBHlLEDOd7+Fw0obXiRUTECwV7SHlZoCaW0H7sIiLihYI9pPwsUBNU7N5H5YmIyMlGwR5SJF8VOw462z03LCIiJxsFe0iWj1Hx0UTqUf3sIiKSIwV7SJaXeeyFqUf1s4uISI4U7CFFLPXotZ89Fk89qmIXEZEcKdhDilgq2b32s6crds1lFxGRHCnYQ0pX7F772aPpil3BLiIiuVGwh2RdFbvPW/HpPnYFu4iI5EbBHpJ19bF7bDSmil1ERPxQsIeU7mP3G+zqYxcRET8U7CHlp489PY9dwS4iIrlRsIcUyUsfu4JdRET8ULBnye90N608JyIifmQU7GZ2pZltMLNNZragl/cTZvZ48P5SM5sUHJ9rZquCP6vN7Lpun9lmZmuC95Z3Oz7SzJ4zs43BY1nuP9OfSNfoOY+NpoO9QyvPiYhIbvoNdjOLAj8ArgLOBm42s7N7nHY7sN85NxW4D7g3OL4WmO2cmwlcCfy7mcW6fe7DzrmZzrnZ3Y4tAP7XOfce4H+D1yeM/Paxq2IXEZHcZFKxzwU2Oee2OOdagceAa3uccy3w4+D5QuAyMzPnXKNzLr1lWSGZ1bnd2/ox8PEMPnPcRCL57GNXxS4iIrnJJNgrgMpur6uCY72eEwT5AWAUgJldaGbrgDXA57sFvQOeNbMVZja/W1unOed2Bc93A6eF+D15Z3lZUlYVu4iI+BHr/5TcOOeWAtPN7Czgx2b2G+dcM3CJc26HmZ0KPGdmbzvnXuzxWWdmvUZo8B8D8wEmTJiQ51/R7XuDR6+bwETVxy4iIn5kUrHvAMZ3ez0uONbrOUEf+gigpvsJzrn1wCHgnOD1juBxL/AUqVv+AHvMbEzQ1hhgb28X5Zx70Dk32zk3u7y8PIOf4UfXAjU+G43GwKKq2EVEJGeZBPsy4D1mNtnM4sBNwKIe5ywCbg2eXw88H1Tbk9OD5cxsIjAN2GZmxWY2LDheDFxBaqBdz7ZuBX6V3U/Lj7wMnoPU6nOaxy4iIjnq91a8c67dzO4AngGiwCPOuXVmdjew3Dm3CHgYeNTMNgG1pMIf4BJggZm1AZ3AF5xz+8xsCvBU0F8dA/7TOfc/wWe+AzxhZrcD7wI3+vqxPuRl21ZIrRevYBcRkRxl1MfunFsMLO5x7M5uz5uBG3r53KPAo70c3wKc18d31QCXZXJdAyE9jb3Td7LHCrVWvIiI5Ewrz4Vk+dgEBlJ7sqtiFxGRHCnYQ4p0LTynPnYRETnxKNhDUh+7iIicyBTsIVk+R8Wrj11ERHKkYA+pax6772CPJlSxi4hIzhTsIR2u2D03HFOwi4hI7hTsIUXyNSo+ltCteBERyZmCPaT8rTynil1ERHKnYA/p8O5u6mMXEZETj4I9pLzeilewi4hIjhTsIaW3bc3LrXj1sYuISI4U7CFFgr8xVewiInIiUrCHpD52ERE5kSnYQ8rfkrKF4Dqgo91zwyIicjJRsIfUtQmM9z72eOpR/ewiIpIDBXtIRh4rdtDteBERyYmCPaS8VezRoGJXsIuISA4U7CFZPvvYAdqbPTcsIiInEwV7SPnvY2/1266IiJxUFOwhRSKq2EVE5MSlYA8pbyvPRROpx3ZV7CIikj0Fe0jpPnbfBTuxdLCrYhcRkewp2EPK67atoHnsIiKSEwV7SId3d8tTsGu6m4iI5EDBHlLXkrKdnhuOKthFRCR3CvaQLN+34hXsIiKSAwV7SOlgz9vgOfWxi4hIDhTsIeWvj11rxYuISO4U7CHlbdtWrRUvIiIeKNhDyt90N1XsIiKSOwV7SIcHz3luOBoDi6iPXUREcqJgD8ny1ccOqapdK8+JiEgOFOwhHR48l4fGo3GtFS8iIjlRsIeUtz52UMUuIiI5U7CHlLdR8ZDak137sYuISA4U7FnKS8UeTahiFxGRnCjYQ4pE8rX0HMGteFXsIiKSPQV7SPntY4+rYhcRkZwo2EOKBsnelo9O9lih+thFRCQnCvaQiuMxABpb2v03HlXFLiIiuVGwh1RUEAWgobXDf+OxQi0pKyIiOVGwhxSJGMXxKA35qNhjcQW7iIjkRMGehWQiRmNrPoK9UGvFi4hIThTsWShJxGhoycOt+KgqdhERyY2CPQvJvN2KVx+7iIjkJqNgN7MrzWyDmW0yswW9vJ8ws8eD95ea2aTg+FwzWxX8WW1m1wXHx5vZC2b2lpmtM7Mvd2vrLjPb0e1zH/XzU/0pjsdoyMut+ISCXUREchLr7wQziwI/AC4HqoBlZrbIOfdWt9NuB/Y756aa2U3AvcA8YC0w2znXbmZjgNVm9mugHfiac26lmQ0DVpjZc93avM8594/efqVnxYko+w7lYb55LKE+dhERyUkmFftcYJNzbotzrhV4DLi2xznXAj8Oni8ELjMzc841OufSpW0hwUKszrldzrmVwfN6YD1QkdtPOX6SiTxV7NEEdLZDZx7670VE5KSQSbBXAJXdXldxdAh3nRME+QFgFICZXWhm64A1wOe7BT3B+5OA84Gl3Q7fYWZvmtkjZlaW8a85TkrisTz1sSdSj7odLyIiWcr74Dnn3FLn3HRgDvBNMytMv2dmJcAvgL9wzh0MDt8PnA7MBHYB/9Rbu2Y238yWm9ny6urqvP6GnpKJKI35GBXfFexafU5ERLKTSbDvAMZ3ez0uONbrOWYWA0YANd1PcM6tBw4B5wTnFZAK9Z855/6r23l7nHMdzrlO4CFSXQFHcc496Jyb7ZybXV5ensHP8Cc9eM753ggmHexaL15ERLKUSbAvA95jZpPNLA7cBCzqcc4i4Nbg+fXA8845F3wmBmBmE4FpwDYzM+BhYL1z7p+7NxQMsku7jtQAvBNKcSJGp4Pmtk6/DUdVsYuISG76HRUfjGi/A3gGiAKPOOfWmdndwHLn3CJSIf2omW0CakmFP8AlwAIzawM6gS845/aZ2SXAp4E1ZrYqOPcvnXOLgX8ws5mkBtptAz7n68f6UpxIrxffTlE86q/hrlvxqthFRCQ7/QY7QBC4i3scu7Pb82bghl4+9yjwaC/Hfw9YH9/16UyuaSCld3hraGnnlJKEv4bVxy4iIjnSynNZ6KrYfQ+giwXjCtXHLiIiWVKwZyGZ3pPd91z2aDz1qIpdRESypGDPQnEiFeyHfM9lT1fsmscuIiJZUrBnIX0rvrHV9634dMWuYBcRkewo2LOQHjyXt4pd68WLiEiWFOxZSN+Kb/Qd7FFV7CIikhsFexaS8fQ89jyNilewi4hIlhTsWUjEIsQi5n8jGG0CIyIiOVKwZ8HMSMajeRg8l14rXsEuIiLZUbBnqSQR8z94TmvFi4hIjhTsWUomYnlYoKYAMK0VLyIiWVOwZ6k4HvW/pKxZ6na8bsWLiEiWFOxZKk7E/A+eg1Swa/CciIhkScGepWQ85n+6G6T62RXsIiKSJQV7lkoS0TxV7IUKdhERyZqCPUt5GTwHqfXi1ccuIiJZUrBnKS/T3UAVu4iI5ETBnqVkPEpzWycdnc5vw9G4gl1ERLKmYM9Seoc377fjY4VaoEZERLKmYM9Seoc373PZY3Ho0AI1IiKSHQV7looT6R3eVLGLiMiJQ8GepfSteO9T3qJxLSkrIiJZU7BnKZmu2L3filfFLiIi2VOwZyl/g+fUxy4iItlTsGcpPXjO+1x2VewiIpIDBXuW0oPnGn2vFx9NqI9dRESypmDP0uHpbr4r9oQqdhERyZqCPUvJgnwNnktAZxt0dvptV0RETgoK9izFohESsUgeBs8lUo/aCEZERLKgYM9BXjaCiQbBrvXiRUQkCwr2HCQTUf+D52IKdhERyZ6CPQfF8TxU7LoVLyIiOVCw56A4EcvP7m6gil1ERLKiYM9BMh71Pyo+Gk89KthFRCQLCvYclCRieZjHropdRESyp2DPQTIey8PguaBiVx+7iIhkQcGeg5JEND9rxYNWnxMRkawo2HOQzMfgua4+dq0XLyIi4SnYc1Acj9LW4Whp93g7XhW7iIjkQMGeg/RGMI0+R8Z3zWNXxS4iIuEp2HNQHA92ePN5O75r5TlV7CIiEp6CPQeHt271WLFrrXgREcmBgj0HyUSwdWteKnYFu4iIhKdgz0FJV8Weh2DXPHYREcmCgj0HyXhQsXu9Fa8lZUVEJHsK9hykB895nctulupnV7CLiEgWMgp2M7vSzDaY2SYzW9DL+wkzezx4f6mZTQqOzzWzVcGf1WZ2XX9tmtnkoI1NQZvx3H9mfhTn41Y8pOayK9hFRCQL/Qa7mUWBHwBXAWcDN5vZ2T1Oux3Y75ybCtwH3BscXwvMds7NBK4E/t3MYv20eS9wX9DW/qDtE1Jx1+C5PKwXrz52ERHJQiYV+1xgk3Nui3OuFXgMuLbHOdcCPw6eLwQuMzNzzjU659LlbCHgjtWmmRlwadAGQZsfz+aHHQ9FBVHMVLGLiMiJI5NgrwAqu72uCo71ek4Q5AeAUQBmdqGZrQPWAJ8P3u+rzVFAXbf/GOjtuwjanW9my81seXV1dQY/wz8zozgey8+e7Ap2ERHJQt4HzznnljrnpgNzgG+aWaGndh90zs12zs0uLy/30WRWkvGo/41gYoVaeU5ERLKSSbDvAMZ3ez0uONbrOWYWA0YANd1PcM6tBw4B5xyjzRqgNGijr+86oZQkYnnYujWuteJFRCQrmQT7MuA9wWj1OHATsKjHOYuAW4Pn1wPPO+dc8JkYgJlNBKYB2/pq0znngBeCNgja/FXWv+44SCaiNHofPKeKXUREshPr7wTnXLuZ3QE8A0SBR5xz68zsbmC5c24R8DDwqJltAmpJBTXAJcACM2sDOoEvOOf2AfTWZvCZbwCPmdk9wBtB2yes4ngeKnb1sYuISJb6DXYA59xiYHGPY3d2e94M3NDL5x4FHs20zeD4FlKj5geF4kSMvfWeq+tYITQf8NumiIicFLTyXI6S8aj/UfHqYxcRkSwp2HNUkoj5n8ceTaiPXUREsqJgz1EyHsvT4DlV7CIiEp6CPUcliSgNre2kBvR7EourYhcRkawo2HOUTMRwDpraPFbtsUL1sYuISFYU7DkqDvZk9zrlLaqKXUREsqNgz1F669ZGnyPj0xW7z9v7IiJyUlCw5ygZD/Zk97lefCzYgl6L1IiISEgK9hyVBBW717nssWCfHO3JLiIiISnYc5RMpPrYvVbsUVXsIiKSHQV7jorTt+J9Dp5LV+wKdhERCUnBnqPioGL3O3gukXpUsIuISEgK9hwV52XwXBDs6mMXEZGQFOw5Kk7k4VZ8NF2xay67iIiEo2DPUTwWoSBqNPhcL1634kVEJEsKdg+Kfe/wVjg89dh80F+bIiJyUlCwe1Acj/mdx15Ulnps2u+vTREROSko2D1IxqM0+hw8VzQy9R1DwW0AACAASURBVNhU669NERE5KSjYPShOxPxuApMYDhZRxS4iIqEp2D0oTkRp9Dl4LhJJ3Y5vVMUuIiLhKNg9SPWxe6zYIRXsqthFRCQkBbsHxYmY3wVqINXPrj52EREJScHuQTIe9TsqHlSxi4hIVhTsHpT4nscOkBwJjQp2EREJR8HuQTIeo6W9k/aOTn+NqmIXEZEsKNg9KO7ak93nIjUjobUe2lv9tSkiIkOegt2D9EYwfhepKU09Ntf5a1NERIY8BbsHyXhQsfvsZ08Gq89pLruIiISgYPegpGvrVq0XLyIiA0vB7kEyHgS71osXEZEBpmD3QBW7iIicKBTsHiSDUfFeB8+pj11ERLKgYPegOLgV73WHt3gJRGKq2EVEJBQFuwfpeeyNPm/Fm2m9eBERCU3B7kFeBs+BVp8TEZHQFOweRCNGUUE0T+vFq2IXEZHMKdg9KU5E/S4pC0HFrpXnREQkcwp2T5LxPOzwpj52EREJScHuSXEiloc92UvVxy4iIqEo2D0pjkf9zmOHVB97WyO0NfttV0REhiwFuyepij0Po+JBVbuIiGRMwe5JfgbPab14EREJR8HuSXFeBs+pYhcRkXAU7J7k5Va81osXEZGQFOyeJOOpW/HOOX+NqmIXEZGQMgp2M7vSzDaY2SYzW9DL+wkzezx4f6mZTQqOX25mK8xsTfB4aXB8mJmt6vZnn5l9N3jvNjOr7vbeZ/393PwpTsTo6HS0tHf6a1R97CIiElKsvxPMLAr8ALgcqAKWmdki59xb3U67HdjvnJtqZjcB9wLzgH3Ax5xzO83sHOAZoMI5Vw/M7PYdK4D/6tbe4865O3L8bcdVcTy9dWsHhQVRP40WFEE0oYpdREQylknFPhfY5Jzb4pxrBR4Dru1xzrXAj4PnC4HLzMycc28453YGx9cBRWaW6P5BMzsDOBV4KdsfcSIoTgQbwXjoZz/Q1MY3/+tNDra0a714EREJJZNgrwAqu72uCo71eo5zrh04AIzqcc4ngJXOuZYex28iVaF375z+hJm9aWYLzWx8Btc44LqC3cMiNS9v2sfPX69k6ZZa7fAmIiKhHJfBc2Y2ndTt+c/18vZNwM+7vf41MMk5dy7wHIfvBPRsc76ZLTez5dXV1b4vObRkcCveR8W+vbYRgJ11TcF68Qp2ERHJTCbBvgPoXjWPC471eo6ZxYARQE3wehzwFPDHzrnN3T9kZucBMefcivQx51xNt6r+h8Cs3i7KOfegc262c252eXl5Bj8jv0q6bsXnvkhNOth31DVpvXgREQklk2BfBrzHzCabWZxUhb2oxzmLgFuD59cDzzvnnJmVAk8DC5xzL/fS9s0cWa1jZmO6vbwGWJ/BNQ64ZDwV7D7Wi6/sHuzqYxcRkRD6HRXvnGs3sztIjWiPAo8459aZ2d3AcufcIuBh4FEz2wTUkgp/gDuAqcCdZnZncOwK59ze4PmNwEd7fOWXzOwaoD1o67asf91xlK7YD3mo2Cu734ovD/rYnQOznNsWEZGhrd9gB3DOLQYW9zh2Z7fnzcANvXzuHuCeY7Q7pZdj3wS+mcl1nUiSifR0t9wq9o5OR9X+JgB27A/62DtaUru8xYtzvk4RERnatPKcJ8XxdMWeW7DvOtBEe6djzIhC9ta30JYYkXpD/ewiIpIBBbsnhQURIgaNOd6KTw+cu2hKarbgfjcs9Yb62UVEJAMKdk/MLLXDW4634tP96+8Ngn1ve1HqDVXsIiKSAQW7Rz52eNte20g0YsyalNoAZmdLMvWG1osXEZEMKNg9SiZSO7zlYnttExWlRYwrS1Xq2xuDFXhVsYuISAYU7B4Vx/1U7BNGJknEopQPS7C1oSD1hvrYRUQkAwp2j4oT0ZwHz1XWNjJ+ZOr2e0VpEe8e7ISCpCp2ERHJiILdo1wHzx1qaae2oZUJ3YJd68WLiEgYCnaPch08lx4Rnw72saWF7Khrwmm9eBERyZCC3aPiHAfPbe8R7BWlRbS0d9KWKFMfu4iIZETB7lEyx8FzR1fsqZHxjdFhqthFRCQjCnaPihMxGls76Ox0WX1+e20jwwtjjEimRsJXBFPeDjJM89hFRCQjCnaPiuPBRjBt2d2O317byIRRya7XFUHFXttZfHiHNxERkWNQsHtUHGzd2pjl7fjttY2MLzsc7COKCiiOR9nbkYTOdmip93KdIiIydCnYPSoOtm7NZgBdZ6ejqrapq38dUuvPjy0tYleL1osXEZHMKNg9SgZbt2YzgG5PfTOtHZ1di9OkjS0tYntzYeqF+tlFRKQfCnaPShLZB/v2miNHxKdVlBWxtSGeeqGKXURE+qFg9ygZT9+KzyLYa/sI9tIi3m0KKnbNZRcRkX4o2D06XLGH72Ov3N9ExA7PXU+rKC3igCtJvVDFLiIi/VCwe5RMj4rPomKvrG1kzIgi4rEj/ycZW1pEHcWpFwp2ERHph4Ldo5Jg8NyhLCr29HatPY0tLaSdGG2xYgW7iIj0S8HuUVF6gZpsBs/1EeyjhxcSMWiMDlcfu4iI9EvB7lE8FiEejXAo5K34ptYOqutbGD+y6Kj3YtEIo4cXctC0XryIiPRPwe5ZcSJKY8hb8ZX7UyPie85hT6soK6K2s0Tz2EVEpF8Kds+S8Vjo6W59zWFPG1taxL6OpCp2ERHpl4Lds5JE+K1b+5rDnlZRWsSu1iKc+thFRKQfCnbPkokojSHXit9e20hxPMrI4niv748tLaLWFUNzHXR2+rhMEREZohTsnhXHYxwKWbFX1jYyfmQSM+v1/YrSIurcMMx1QssBH5cpIiJDlILds2wHz/V1Gx5Sg+fqnBapERGR/inYPSsOOXjOOdfnHPa0saVF7GdY6kWjgl1ERPqmYPesOOTguepDLTS3dTJhVN/BXpKI0R4fkXqhil1ERI5Bwe5ZMhGlIcTgucpgRPz4sr6DHSAxvDz1RHPZRUTkGBTsnhXHY7S2d9LWkdno9fRUt74Wp0krKT0l9UQVu4iIHIOC3bPi9A5vGQ6g217TBMC4sqOXk+2udGRQsWsuu4iIHIOC3bPiYCOYTNeL317byOjhhRQWRI953piyEg64JC2HanK+RhERGboU7J4drtgzC/bKfkbEp1WUFbHfDaP5QHVO1yciIkObgt2z4kSq8s50AN32YHGa/owtLaKOYtobVLGLiEjfFOyeJeOpij2TKW/NbR3sPticUcU+Llh9zjWoj11ERPqmYPesJJF5sFftTw2cmzDq2APnAE4pSXDQSohqSVkRETkGBbtnyXj6Vnz/wZ7ehz2Tij0SMVrjpSTa6nK7QBERGdIU7J4drtj772PPdHGaLoVlJDsPQWe4tehFROTkoWD3LJkeFZ9Bxb69ppFELEL5sERGbUdLRqWeNKlqFxGR3inYPUsG89EPZVCxpzd/6Wu71p4Sw1LB3qaR8SIi0gcFu2eRiJGMRzOax97frm49FZemVp+rrd6d9fWJiMjQpmDPg2QGW7c656jMcA572vCRpwJQV7Mnp+sTEZGhK6NgN7MrzWyDmW0yswW9vJ8ws8eD95ea2aTg+OVmtsLM1gSPl3b7zJKgzVXBn1OP1dZgUpKIUt987GCvbWilobUjVMU+qnw0APX79+Z0fSIiMnT1G+xmFgV+AFwFnA3cbGZn9zjtdmC/c24qcB9wb3B8H/Ax59wM4Fbg0R6f+5RzbmbwZ28/bQ0aZ48dzrNv7WFNVd9zztO7uoUJ9lNPHQNA04F9uV2giIgMWZlU7HOBTc65Lc65VuAx4Noe51wL/Dh4vhC4zMzMOfeGc25ncHwdUGRm/Q0B77WtDK7zhPH/rj2H8pIEn//pCmoOtfR6Tlewj8o82AtLyuggQps2ghERkT5kEuwVQGW311XBsV7Pcc61AweAUT3O+QSw0jnXPen+I7gN/9fdwjuTtk5oo0oSPHDLLKoPtfDnP3+D9l72Zg89hx0gEqHBSujU1q0iItKH4zJ4zsymk7ql/rluhz8V3KJ/f/Dn0yHbnG9my81seXX1ibfj2YxxI/i762bwyuYa7v2ft496v7K2ifJhCYrix96utaem2HCizft9XaaIiAwxmQT7DmB8t9fjgmO9nmNmMWAEUBO8Hgc8Bfyxc25z+gPOuR3BYz3wn6Ru+R+zre6ccw8652Y752aXl5dn8DOOv+tnjePW907koZe28qtVR/6Vba9tZHxZ/2vE99QWLyXedhDnnK/LFBGRISSTYF8GvMfMJptZHLgJWNTjnEWkBscBXA8875xzZlYKPA0scM69nD7ZzGJmdkrwvAC4Glh7rLbC/7QTw7euPps5k8r4xi/e5K2dB7uOh53DntZZVMZwd5C6xjaflykiIkNEv8Ee9HPfATwDrAeecM6tM7O7zeya4LSHgVFmtgn4KpCeEncHMBW4s8e0tgTwjJm9CawiVaU/1E9bg1JBNMIPPnUBI4oK+NxPl1PX2Epreye7DjRlFezR5EhKaWBHXVMerlZERAa7WCYnOecWA4t7HLuz2/Nm4IZePncPcE8fzc7q47t6bWswO3VYIfffMot5//4qX3psFd/+2Nl0OkItTpOWGH4KCTvEW3VNnFMxIg9XKyIig5lWnjtOLphQxt3XnsOL71TzzV+sAcLNYU9LjihnmDWxs+Zg/yeLiMhJR8F+HN08dwI3zx3P69tS09XCzGFPKxpxCgB1NVp9TkREjqZgP87uumY6M8eXUhyPctqwwtCft6IyAOrrFOwiInK0jPrYxZ9ELMqjt89lR10TkUgWC+olRwLQWHfizd0XEZGBp2AfAMMKC5g2uiC7DwcVe2u9Vp8TEZGj6Vb8YFOUqtijLbU0t3UM8MWIiMiJRsE+2AQVeymH2HWgeYAvRkRETjQK9sEmMYxOi1Fqh9ipRWpERKQHBftgY4YrLKWMQ+zYr2AXEZEjKdgHoUjxKErtEFWq2EVEpAcF+yBkRWWcGmtUxS4iIkdRsA9GyZGMijayo65xoK9EREROMAr2waiojFLqtcObiIgcRcE+GBWVUdxZz666Zjo6B+1W9SIikgcK9sGoqIx4ZzPRzhb2HNRcdhEROUzBPhgF68WPoEG340VE5AgK9sEoWH2uzOqp2q8BdCIicpiCfTAK1osvpUFT3kRE5AgK9sEoqNgnFDXpVryIiBxBwT4YBX3sE5OtVKliFxGRbhTsg1FQsVckmnQrXkREjqBgH4wKkhAvYXx0PzvqmnBOc9lFRCRFwT4YmcGY85jQ8g4t7Z3sO9Q60FckIiInCAX7YFVxAaPq36aAdk15ExGRLgr2wapiFtHOVs607RoZLyIiXRTsg1XFLABmRjZrAJ2IiHRRsA9WI8ZDcTlzCrZoypuIiHRRsA9WZlAxi/MjW3QrXkTkBNXW0ckvVlRx16J1x+07Y8ftm8S/ilmMe+cZ9tfuG+grEREZkjo6HT96ZRunlxdz8dRTKIhmVg83t3Xw+LJKHnwxVXxNGz2MhpZ2ihP5j10F+2BWMYsIjrK6dTh3JWY20FckIjKkLF6zi//3328BUJYs4KoZY/jYuWOZO3kk0cjR/+YeaGrjp6+9yyO/30pNQyuzJpZx97XTuXTaqcft32gF+2A29nwAzuzYyIGmNkqT8QG+IBGRocM5x4MvbmHKKcUsuGoa//3mLp5auYP/XLqdU4cl+MNzx/Cx88Zy/vhS9h1q5eHfb+Vnr71LfUs7HzyjnC986HTmTh553IsuBftglhxJQ8lEzjuwmar9TQp2ERGPXt1Sw5odB/i762ZwxfTRXDF9NI2t7Tz/9l4WrdrJz17bzn+8vI2K0iKqD7XQ1tHJR2eM4c8+eDrnVIwYsOtWsA9yraddwHn1v2P1/qYB/T+SiMhQ8+CLWzilJM4fXVDRdSwZj3H1uWO5+tyxHGxu49l1e/iftbv4wLBy5n9gCpNPKR7AK05RsA9y8YmzKdv8FEt2b4NzRg/05YiIDAkbdtezZEM1X7v8DAoLor2eM7ywgOtnjeP6WeOO89Udm6a7DXLJyXMBiOx6Y4CvREQGkyeWV/JPz24Y6Ms4YT344haKCqLcctHEgb6U0BTsg5yNPpd2ogyvWT3QlyIig8iPXt7Gv76wiZ1aB+Mouw80s2j1DubNGU9Z8eAbu6RgH+wKCqmMT2HMoeO3+IGIDG5NrR1s2FOPc7BwRdVAX84J5z9e3kpHp+P2Syb7aXD9f8Nzd0Lr8dmwS8E+BOwdNp2p7Ruhs3OgL0VEBoG1Ow/Q0ekYlojx+LJKOjvdQF/SCaO+uY3/XLqdj84Yw/iRydwbdA6W/D1s+A3ECnNvLwMK9iGg4ZSZlNBEw671A30pIjIIrK6sA+Arl5/BjromXt6s1SvTfv76dupb2pn/gSl+GnznGdizFi75KkSOT+Qq2IeCcbMBOLhp6QBfiIgMBm9U1lFRWsQnL5xAabKAx5dVDvQlnRBa2zt55PfbuGjKSM4dV5p7g87BS/8IpRNgxvW5t5chBfsQMGL82dS7Ijoqlw30pYjIILBqex0zx5dSWBDluvMreHbdHmobWgf6sgbcf7+5k90Hm/ncB0730+C2l6BqGVz8ZYgW+GkzAwr2IWD8yGLe7JxC4V6NjBeRY6uub2FHXRMzx6cq0nlzxtPa0clTb+wY4CsbWOnlY884rYQPnVnup9GX/glKToOZt/hpL0MK9iHglJIEa5lKWf0GaGse6MsRkRxt2lvPo6+9m5e20/3r5wXBPm30cM4bX8oTyypx7uQdRPfixn28vbueP33/FD9ru1etgC1L4L13QMHxGTSXpmAfAiIRozJ5FlHXnhqkISKD2v1LtvDXv1xLdX2L97ZXVdYRjRjnVAzvOnbTnPFs2FPPqiD0T0YPvriZ04YnuHZmRf8nZ+Klf4LCUpj9J37aC0HBPkQcGHlu6knV8oG9EBHJ2dKtNQCseLfWe9urq+o447RhJOOHVxS/+twxFBVET9pBdGt3HODlTTV85uLJxGMeYnHPOtjwNFz0Z5Aoyb29kBTsQ0Ry1Hj2MhJ2rBjoSxGRHOyoa6Jqf2o1uGXb9nttu7PTsaqyrqt/PW1YYQFXnzuGX6/eSUNLu9fvHAwefHELJYkYn7xwgp8Gf38fxEtg7nw/7YWUUbCb2ZVmtsHMNpnZgl7eT5jZ48H7S81sUnD8cjNbYWZrgsdLg+NJM3vazN42s3Vm9p1ubd1mZtVmtir481k/P3Voqygr4o2OKXQq2EUGtdeDav2UkgTLt/mt2LfWNFDf3M7544+eyjVvzngaWjt4+s1dXr/zRFe1v5Gn1+zi5rnjGV7oYeR6zWZY+4vULfjkyNzby0K/wW5mUeAHwFXA2cDNZnZ2j9NuB/Y756YC9wH3Bsf3AR9zzs0AbgUe7faZf3TOTQPOBy42s6u6vfe4c25m8OeH2fywk01FaRGrO08nUrsZGv3fvhOR4+P1rbUMK4xx4+xxrN15kMZWfxX0qu1HDpzrbtbEMk4vL+axZdu9fV+u2jo6eWJZJfXNbXn7jieXV9HpHJ+52NPysS9/DyIFqUFzAySTin0usMk5t8U51wo8Blzb45xrgR8HzxcCl5mZOefecM7tDI6vA4rMLOGca3TOvQAQtLkSOLH2vRtkxpUVscoFcy93aqc3kcFq6ZZa5k4ayYVTRtHR6brC2IdVlXUUx6NMPfXofl8z46Y5E1i5vY6Ne+q9fWcufrN2N//3F2/yqR8uzds8+2fW7WbOxJGMLS3KvbEDO2DVf8IFn4Zhp+XeXpYyCfYKoPuIiqrgWK/nOOfagQPAqB7nfAJY6Zw7YpinmZUCHwP+t/u5ZvammS00s/G9XZSZzTez5Wa2vLq6OoOfMbRVlBWxpnMKDoMdKwf6ckQkC3vrm9myr4G5k0dywYRSIgave7wdv7qqjnPHlRKN9D6d67oLKohF7IQZRPfalhoKCyJs2F3Pjf/+KrsP+J3Ou72mkbd313PFdE8h/Mr3AZdakGYAHZfBc2Y2ndTt+c/1OB4Dfg78i3NuS3D418Ak59y5wHMcvhNwBOfcg8652c652eXlnhYTGMRGDy+kMVJMbdEkDaATGUA1h1q48O9+y2/WhO+rfn1rKsQvnDKKYYUFTBs9nOWeBtA1t3WwftfBXm/Dp51SkuDys0/jv97YQWv7wG8qtXRLDe+dMoof/8lcdh9o5voHXmHbvgZv7T/71m4Arjh7dO6NNeyDFT+CGTemlpAdQJkE+w6ge9U8LjjW6zlBWI8AaoLX44CngD92zm3u8bkHgY3Oue+mDzjnarpV9T8EZmX2U05usWiE0cML2VxwRirYT+KFJkQG0uPLK9lzsIUns9gO9fWttSTjUaaPTc0xnzOpjJXb99PekXvIvrXrIG0d7qgR8T3dOGc8tQ2t/Hb9npy/MxfV9S1srm7gwimjuGjKKH7+pxfR0NLO9Q+8yvpdB718x7Pr9jBt9DAmjPKwi9tr/wbtzXDJV3JvK0eZBPsy4D1mNtnM4sBNwKIe5ywiNTgO4HrgeeecC26zPw0scM693P0DZnYPqf8A+Isex8d0e3kNoC3LMlRRVsRqpkLDXjigPZZFjreOTsfPXksNPvv9pn0cCjl1bOmWWmZNLKMgmvqnefakkTS2drB+V+593um++v6C/QPvKWfMiEIeG+Db8em5/BdNSfXqzhg3gic//15iEWPev7/Kindzu5Ox71ALy96t5YrpHqr15gPw+kNw9jVQfkbu7eWo32AP+szvAJ4hFbJPOOfWmdndZnZNcNrDwCgz2wR8FUhPibsDmArc2W362qlBFf9XpEbZr+wxre1LwRS41cCXgNv8/NShb1xpEa82TUy92KGFauRI2nM7/154ey876pq47X2TaG3v5HcbMh//s7+hlQ176rlw8uEpUrMnlQGwzEM/+6rKOkYPL2T0iGMvbxqNGDfMHs9LG6vZUdeU8/dma+mWWorjUc4Ze3iFvKmnDuPJz7+XkcVxbvnhUl7amP34qv9dvwfn4CM++tdffwhaDsL7v5Z7Wx5k1MfunFvsnDvDOXe6c+5vg2N3OucWBc+bnXM3OOemOufmpvvLnXP3OOeKu01dm+mc2+ucq3LOmXPurJ7T2pxz33TOTXfOneec+7Bz7u18/fihZlxZES8fGo2LxtXPLkdYv+sgM+56hm/+15t5nTp0svvJa+9y2vAE3/zoNEYWx7v6cDORHiR34ZTD447HjChiXFkRyz2sQLe66uiFafpyw6zUJKUnlw9c1b50aw2zJo0kFj0ypsaPTPLE59/LxFFJbv/Rcv5nbXbz7p9dt4eK0iLOHjO8/5OPpbEWXv1XmHo5jDkvt7Y80cpzQ0hFWREtLkbrKedoZLwc4Z+fe4f2Tsfjyyq58rsv5VTpSO+27mvgxXeq+eTciSRiUf7grFN5/u29GQ9Ce31rLYlYhHPHjTji+JxJI1m2bX9OG7TUNrTybk3jMQfOdTd+ZJJLpp7Ck8ur6BiAOz01h1p4Z8+hI+5edHfqsEIen/9ezqkYzhd+tpLn3go3HuBQSzsvbdrHFdNPy33Dl9/dm7oV/wd35daORwr2IaSiNDUApLZ0Rmoue8fJtzSkHG1N1QGee2sPX/zwVJ78/PtIFET49MOv883/WjPkqvfW9k6WbqkZkG6Hn772LrGIcfPc1Fjjj0wfTX1zO69tqcno80u31nD+hFISsegRx2dPKqO6voXttY1ZX1t6R7dMK3aAm+ZMYEddE0s27M36e7OVnh1w0ZS+V24bkSzgp5+9kPecOozv/GZ9qP/NX3ynmtb2Tj6Sa/969YbUbfgLboXR5+TWlkcK9iGkoiy1wEJl8ixoa4R9Gwb4iuRE8N3fvsOIogI+c/EkZk0sY/GX3s/8D0zh8WXbufK7L/H7jfsG+hJz1tHpeOqNKv7gn3/HvAdf45GXtx7X729q7eDJ5ZVcec5oTh2e6sO+eOopJONRnlnX/+34g81tvLXzIHMn91z+I1WxQ27rxq+qrMMsNQAtU1dMP43Thif40Svbsv7ebC3dWktRQZQZFcf+D5FkPMYXL53K5uoGngsxiv+ZdbspSxYwe2JZbhf6zF+m1oS/9Fu5teOZgn0IGVua+gflrcjU1AH1s5/0VlXW8b9v72X+B6YwLFgHu7Agyl9+9Kyu6v2Wh5cO2urdOcez63bz0e+9xFceX01JIsZ540v5l//dSF1jflYq682i1Ts42NzOpy+a2HWssCDKh84s57m39vRbTa7Ytp9OBxf1cut5ankJI4oKclo3flVlHWecOoySRKz/kwMF0Qi3XDiRlzbuY9PeQ1l/dzZe21LDrIllGe209tFzRjN+ZBH3L9mcUXdFa3snz7+9lz8467Sj+u9DeedZ2PRb+OD/heJTsm8nDxTsQ0giFuXUYQnWNZVD4QgFu3Dfc+9Qlizg1vdNOuq93qr3XLYJXbJhL5f+4xLm/2Q59y/ZzNItNV7XOe/plU37uO7fXmH+oyto6+jkXz95Pv/955dw7ydmcKilnX99flPevrs75xw/efVdzjxtGHN7BPMVZ49mb30Lq6qOvSzsa1trKIga5084uoKMRIzZE8uyHhnvnAs1cK67my+cQDwa4Sevbsvqu7NR13j07IBjiUUjzP/A6ayqrGPp1v7/jpZuraG+uT23aW4dbalqfdTUAdvB7VgU7ENMRVkROw40Q8Us7c1+klvx7n5+9041n/vg6X1Wat2r91jUuO2RZWzYHX7O9Nu7D/LFn62ktaOTd/bUc+//vM28B19jxl3P8of/8hLf+uUafrGiiq0eVg17Y/t+PvXD1/jkD5ey92Az935iBs9+5QNcfe5YIhFj2ujh3DBrPD9+dRvba7Lvl87Uyu11rNt5kE+/d+JRA7E+PO1UYhHj2XXHvk38+tZazh1XSlE82uv7cyaPZHN1AzWHWnp9/1jerWmkrrEt44Fz3Z1SkuDq88awcEUVB4/THZ3Xt9bi3JGzA/pzw6xxnFIS54Hf9VwDj+O8bwAAIABJREFU7WjPrNtNUUGU978nhyr79YegZiNc8bcQi2ffTp4o2IeYcWXJ1F7O4+bC3reg2c8KTTL4fPe37zCqOM4fv3div+fOmljGf/7pRSQTUW77j9dDrcm9t76Z23+0nJLCGAs//z6WfP3DrPzry3nkttl84UOnU5aM88s3dvK1J1fz4X9cwrd+uSarwW3OOf7+N+u57t9e4e1d9dx59dk8/38+xLw5E466pfrVK84gFolw7zP5ny376KvbGJaIcd35PbfQgBFFBbz39FE8u253n7eJG1vbWVN14JgV6pxgPvvyLBZlWZXFwLnuPvO+yTS2drBw+fFZ9Oq1LanZAeeNz3w8QGFBlM9cPJklG6p5a2ff/+Z1djqee2sPHzyjnMKC3v8jql8NNfC778Dpl8IZH8mujTxTsA8xFaVF7DrQROe4ueA6tVDNSer1rbW8tHEff/ah00nGM+tXrSgt4pHb5nCwqY3b/uP1jPrcm9s6mP+TFdQ2tPLwrXO6Fj8ZWRzn0mmn8bUrzuSnn72Q1d++gme/8gFue98kfvradv7yqXDh7pzjb379Fv/+uy3cPHcCv/u/H+ZPLpnc5z/Opw0vZP4HpvD0m7tyXqHsWPYdamHxmt18YtY4ivu4K3LF9NFs2dfQZz/1ynfraO90R93G7+6cihHEY5Gs+tlXVdZRVBDljNOO3tEtEzPGjeCCCaX85NVtx2W2wdKtNVwwoeyo2QH9ueWiiZQkYses2ldX1bHnYEtum7688LfQcgg+8veQ61S5PFGwDzEVZUW0dTiqR5wLGFS+PtCXJAPgvufeoXxYgk9d2H+13t30sSO4/5ZZbNp7iC/8bCVtx1ijvLPT8bUnV7O6qo7v3jSTcyr6rrCiEeOM04bx7Y+dzZ9fOpXHllXyjV+8mdEc6c5Ox7d+uZYfvbKN2y+ZzN9dd05Gg8Dmf2AK5cMS/N3i9TnNAT+Wx5dV0trRyS0X9b3px+VnpULk2T7mWi/dWkPEUsvH9iURizJzXGlWI+NXVdYxo2JETgPFbrt4MttqGvndO/ld/+BAUxtv7TrIhceY5taXEUUFfPLCCfz3mzv77IJ59q09RCPGZdOyDPY962DFf8Ccz8Kp07Jr4zhQsA8x49JT3hqjcNp02P7aAF+RHG+vbN7H/9/eecdHVWVx/HuTEJJAKpCENEOA0CFAgNCkCyJKUSmCgAiIImJfdN21r66ugshaFguiIEWqSpFiQSAhlAAJocZ0EkhIIZA+d/+4AwbSZtIwyf1+PvOZmTf3vbm5mffOu/ec8zv7o1J5dEDLUn22ZXG7fzPeGteJPWdSWLDueKlGceHO0/x47DwLRrQ1OR9YCMHTw/yZP6Q1aw/F89x3R8s07oUGyYL1x1gREsucAS156a52JguKNGpoxTPD/DkUk8a2cNMV4Eyl0CBZGRJLn5ZNaOVqX2o7d0cbArydSk17C/njEh09Hcu9WQn0dSY8IYPsvEKT+5hXYOBEYiYBPhVbhr/GnR3dcbWv/tS3g9FG/3oJaX+m8HC/FlhZWLB0T1SJn2+PSCLIzwVHuwbmH1xK2PaCCkweuKD89rcQbdjrGF5OyrAnpGeDdy8VQGcw/UKgqd1IKVm04wxuDg15oFfFS0feH+jNk0Nbs+5wPAt3nC72+frD8Xy4+yzjA72YfbufWccWQvDUMH+eGurP+sMJPLu2ZONeUGjgubVHWXMwnieGtOZvI9qYrRJ2f6A3/m6NeXvbySovQ7orMpmE9GyTYhju6ODGsfgMEm/SXs/JLyQsLt2kCPAevi4UGOR1n7kpRJ7PJK/QQBevEgx7TgYkn4D88uMpGlhaMLnXbfx6+iLnLlZf6ltwVCrWlhZ0reCNiJuDDWO7erLmYBwpNwUanr2QRdTFKxUv0XpqC/zxKwx8EezMX1GoSbRhr2NcE6mJT8sGnyDIu6yC6P5CSCk5FJPGSxuPc8+S39l4JKHalkrrG/vOpXIg+hJzB7WqeHCQkflDWjM+0IvFu8+y6kDs9e2h0ZdYsO44vf2a8MaYThWW5Jw/tDXP3uHPhiMJPLU67IbSpPmFBp5ac5T1RxJ4Zpg/Tw/zr9D3WFoIXhjZjpjUq6wIialQP0vj6+AYmjvaMLRd+cu611Y0bpY+PRqXTl6BoURhmpvp5uOMEJjlZ78eOFeSoVw7HT7uDf9qDou7wsqJsOOfcGSFmhDkZNzQ/IFePjSwFHy9v2rHsSghf1wiwMfJ9N9u3AHV7+BPrpeqnj3Aj7xCA8v2Rt/Q9Jpu/7D2FViGL8iF7X+HZm0hcIb5+9cwpqsVaGoFdtZWONs1UIY9oKfaGBcC7p1uaBeekMF3h+KZN7gVTRo3rJG+xaReYcORBDYeSSA69So2DSzwcLLlydVh/HAskTfGdCq38pSmdKSUvL/jNM0dbZjQw7vSxxNC8ObYTiRl5vL3jeG4OdrQsmljHvn6EF7Otnw8pZtJAiJl8fjg1lhaWPDvbScplJJFEwKQEuavOsLW8CQW3NmWOQNaVuo7Bvo3o1+rpnyw6wzjunnhaFuBZdibiLqYxZ4zKTwzzN8k33XLZo1p2awRP51IukFTIOSPSwgBPcvwr1/D0a4BbdzsCTUjGPBoXDpNGzfE4+bzKjkCzu2GLg+Ao5dSqUw5A+d2QWERYR9nX+gzD7pOpZl9Q0Z19mDtwTieucP/uuBRVXE5J5/whAweH9Sq/MYpZ2DXqxD5PVjZwumtELsfRi+hZTN7hrd3Z/n+aOYM/DPVc3tEMp29HPEwrmqaRcgnkPYHTFkPln99s/nX76HGbLyc7dRSvFNHaOwOsSEq2MNIbOpVpn95gJSsPHacSOZ/U7vTwcP01BJzyLiazw/HE1l/OIFDMWkIAb39mjB3UCtGdHTHztqKZfuieXf7SYYt/JV/3NWe+wO9Kl+YoR7y25kUDsWk8caYjmZHFJdGA0sLPprcjQmf7mfuisO42jfEICWfT++Bk91N+btSQmaCMhRm8OjAllhawL+2nMRgkOQXSnZGJvOPUe15uF+LSv8NQgheGNmWUR/+zkc/n+WFke0qfcxvgmNpYCmY0NP0G6jhHdz59Lco0q/mXR+7A39coo2bvck+30BfZzYeSaTQILG0KP8cCYtTwjTFzqfgj5VBHP7mjcvKhQWQHqM00FNOwalt8OMzsHcxDHyB6UF3sOFIAusOxTO9b+X/N0U5GKPU98rMX888r1LNDn8NDexg0EsQ9CiEfqYM/YUTMP5r5gxsybaIJL4NiWXW7X4kZeRwNC6d54a3Ma9TV1Lg8HLY8x74j4BWQyr3R9YQeim+DuLpZEtC2lWViuHdU83YjVy6kse0Lw9QYJAsntQVg5Tc+/E+vj+aWKV9yC808NaWSHq8uZO/bwgnMzuf50e0Ye/fBrNyVhD3B3pjb9MASwvBw/1asG3+7bRv7sDz644x9YsDxKdVv7BIXeLabN3TyZbxgZWfrRelcUMrvpzeA2c7axLSs/lkSndaNG1UvGHIp7CwA/zy7+vLoqYy+3YVGLc1PImdkcm8PrpDlRj1a3TwcOTebl58uTeauEoUUwGVd772UBwjOjbH1d70FaY7OrhTaJDsPqmKquQXGjgUk0aQGUIsPXxdyMot4GRS+foUGVfziUq5UtxffSUFjq2BLhOL+4otraBJS2g7Evo9BTO2weTvVMDYxjl0+WEkc1wjWL6v6lPfQqIu0cBS0K0E9T1yMmDX68plcGQF9JwF88NgwHPQsDH0exKmbobsNFg6mID0nfT2a8Jnv0eRW1DIDuMy/B2mLMNLqZb418+G99upGwbPbjDyP1X691YnesZeB/F0tuWX0xeQUiJ8giByM1xOIsemGTO/CiUhPZuVM3sR6OtCkJ8Lj31zmHnfHiHyfCbP3NHGpJlAWSRl5PD4ysMcjEnj3m5ePNTXlw4eDmXOwn2bNuLbWUGsCInhra0nGb7wNxaMbMfknj5YVLI/9YEtx5M4GpfO2+M6VXp5vCRcHWzY8FgfLlzOLTmt7UoK/PwvZQB++RfkpCtVLgvT+zKzvx+uDjZYWwpGdGxevMGFSNj5KiQdhwnLlbqiGTxzhz8/HEvk3e2nWDypq1n7FuWTX6O4nFNgUtBcUTp7OuLuYMP2iCTGdfPiWHwG2fmFZeav38y1lLiD0WnlrrIdNcrYFgucO/glFOaqmW55CAGth0HLIeo68vObLMh8k5GGFhz/7R90GTCuynK5g6NSi6vvGQxw4FP49R3IvgQd74PBfweXEgI2W/SHR/ao2IF1D/Mf/2kMjBrCpiOJ/HQiGb+mjWjlWkYuf95VCP9OqcolHYOGDtD9IejxMDQzc6Z/i9Ez9jqIl7MtOfkGUq/kqch4oDA2mPmrjnAkLp0PJgRcv0C42tuwclYQk3p689Ev55i1/GClpCP3nk3hrsV7OHE+kw8mBvDe+C509HQ0aWndwkLwYG9ftj95O91uc+YfG8OZtDS4RmRBazN7z6bw1JowOnk6cm9385bBzcHVwab0XPXdb0BeFsz4CXo9CsEfwebHzS4dfE8Xj+JGPTMRNj0OH/eBmL1KeGnZKDizw6xjN3e0ZWY/PzYfTTQrsrwoe85c5MPdZxjX1dPsymAWFoJh7d349fRFcqJDubz3M4ZaHKKPTTSkx6kArXLwdLLFw9HGJN34axXdOhdVcCvIhdCl0GqoecbKwgI6jIFH91Nw90c0tciiyy8zYNldqu+V5EpuAccTMoqXaT3yNWxboGKEZv8C931eslG/hkNzmP4DBD2G5+mv2NT4LVbtCmH/uVSGFa29LiVcvaTKW5/YpNLY3m8Lm+epLKJRC+HpSBj5Tq0z6qBn7HUSz2spb2nZNG3eGWllw4Fft7A9djQv392eOzvdeOG0trLgX2M70d7DkVc3RzDmv3tZOjWQls1MV6oyGCT//fks7+88TctmjVk9pVuZub1l4e1ix/IZPVlzMI43fohk5OI9vDa6A2O7emrf+02ERKXy8Feh+DVtxPIZPWlQmWpVFeX8MTi0DHrNUaIdI94CW2fjzD0D7v0cGlQgKDInA/Z+APs/AkOBOn7/Z9XrFffByglwz2LoOsXkQ84Z2JLVB+OY9+1h1s3pc73EqikkZeTw5KowWrs25o2xHSv0WxzewZ24A5uw/mohA2U+A62BFe/92cDGERq7QSNXtfw75OViwVqBvi6E/JGqVuTK6MPRuHRaNmuMQ9Egt4gNkJUMQR+Z3XcALK2w6j6ZdalduPDrUl5NXIvF9/NhyrpKzdwPxaRRaJA35q8X5MJv74JnIEzdZPrxLRuo36BXD/w3zOXT7Kf4SgxnaqYdrEyG9Fj1yCuStmdhBe1Hq1gkn95/WUU5U9GGvQ5yLeUtIT2bLt5OJDVqh03SIWb2e5KHSgl4EULwYNBt+Ls25rEVhxmzZC+LJ3VlUFvXcr8v7UoeT60J45dTFxkT4MGbYzuVKq9pKkIIJvTwoW+rpjy1Ooyn1xzll1MXeX1MxyqJaq4LHIpJY8ayULyc7fhmZi+cG92CYhTXRDtsnWHg39Q2IdRrG0fY9jdYOR4mrlS+UFMoyFPqXr/+G66mGpdfXwKXIr/dh7bA6gdh01wVUHX7syZdjBs3tOKzqYFMWhrMtC9DWTU7yKTfU36hgcdXHiY7v5CPJnczWab3ZoIsIwm0XkhCwxbMyX6Mkf6NmRtor4xt1gW4ckG9zjwP+xZD/lXl2y3yt/Vo4cLmo4nEp2Xj7WJX7DsMBsmGIwkER6XeuPohJez/LzRto5bWK8GE3q3o++tw+ro5MuLcB3DyR2g3qsLHC/kjFUsLQfeiqyCHl0NGHNz9QcUMbcdx0LQdVz69j2cbrEVGOYDTbeDcAloMACefPx/OvmDjUOH+/9XQhr0O4uWsTvb4tKt8fzSRuFRvZlttocsw33L37eXXhM3z+jF7+UFmfBVKa9fG+LvZ09bdHn83e9q42+PtbHfd730kNo25Kw6TkpXHG2M6MrmXT5XOqr2c7Vg1uzcf/XyWRbvOcCgmjUUTA+hhQnpQXeZoXDrTvziAq4MNK2f2omkNpSwW48QmiPkd7npfGfeiBM1Rxn3TXFg+GiavLV3YQ0pIOQ3Re2DfEpVa5Nsf7ngdPErwhze0hwfWqOX+n99Q0fgj/2NSKlIXbyc+fbA7M5aFMmv5QZbP6Flu3vS7209xMCaNDyYGVHglivhDWK2aSIq1J2MznyHFYM/sDgHQpnjxGAB++ocy7k1a3eAPv1YQJjT6UjHDHhKVyhs/RnI8IYPOXo48PrhI6ljsfuU7HrWw0jNSV3sb7urUnAWRQQxw2YbFj88TZhFANtbk5BvILSgk1/gc6OtCu+ZlG83gqEt08nT8c0KQn60i0X16q2IrFcTKvR05s37n2JUMOrf2rfBxahvasNdBHG0bYN/Qim3hSYQnZPJws25YpW+GpDC4rU+5+3s62fLdnD4s3RPFsfh0wuLS+eHY+eufXyso4e1ix/aIJNwcbPju0d50LkndqgqwtBDMG9Kafq2bMn9VGBM+3c/jg1rxxJDWldK/rq1EJGbw4OchODVqwMpZvcxaTq5S8rNhxz/ArSN0n15ym4BJaia0drryxz64Aezdle89+TjE7Fd+89hguJqi9nHtoCKxWw0t2wBZWcPYT8HBA35fqGa6934O1sVnsTfTv3Uz3hsfwPxVR3ji2yN8NLlbqb+lnyKS+N9vUUwJ8mF0QClGuDySI+CbcdCoKSd6f0XK+gSgHOnUoa/CpSi1IuLsC23uBMDf1R57GytCo9MY103FVMSkXuGtLSfZFpFEc0cbFk7owugunjcGngZ/BDZO0Hlixf6Gm5jetwUbwxKZljSeNQ1fJ/jrl1hYcH+xdtaWFvzz7val3vRn5xVyLD6dGUWzIA5+CZfPw7illb4JaevhDJgXD1Hb0Ya9juLpbMvh2HRaNmvEnCkTYckr6uJpgmEHsLW25Ikhra+/z8ot4EzyZU4nX+Zkkno+8MclhrZz461xnYrnNFcDXX2c2TK/Py9vimDx7rPsOZvCBxO64tOk/At5XeFU0mWmfBaCvU0DVs4MorljBcQ2qor9S5Svctr3YFHGjLftXcpQr3oAPr9DzUDjDihVRFDLo62Hqd+mTx+VbmXqxVwIGPoK2HvA1ufVysADq02S/LyniweXsnJ55fsTvLQxnLfGFVfRi029yjNrj9LJ05F/jGpvWp9uJvUcLB+j8q6nbiKokRcNN5/H3dGmbEEmCwtl2JaNhO8ehhlboXkXLCwEgbc5czD6EhnZ+SzZfYZl+6KxsrDg6WH+zOrvV7xGQFq0Wi7vO9+kGx9TCPB2YsXMXlzO6UZSaBjz4n5kyMQnES6q6l5DKwukhJc2hvPSxnCOxKbz5tiOxVZHDsemkV8o/0z7y7sCv7+vVmxa9K+SvtY3tGGvo7R2syf1Sh7LHuqJo4sdNGldqUpvjRta0dXHma4l5ZjWII0bWvHe+C4MbNOMFzccZ+TiPczo60uLZo3wdLLDw8kGdwebOjmTP3shi8mfBWNtZcHKWb1K9K/WGJmJsOd9aHc3tLi9/PZ+A1Se8boZaibWebzRkPcGxwrOgovSa7ZaCVg3U9083PMh3Na73N2m921B6pU8Ptx9liaNrXlu+J8Vu3LyC3ls5SEE8NHkbhUT/UmPUzcbshCm/gjOvtgB8wa3Mu1m2NoOJq2CpUNUsOCs3eDgQaCvCz+fOsXAd38mPTuf+7p58ezwNriVtnoT8j8QFtBjlvl/Qxn0bdVUvfB5F5b8TMdjb6kbqyJ8Mb0Hi3ed4YNdZ4g8n8knU7rfcDMeEmWsbnfNv35gKVy5CBO+qdK+1idEXdDoDgwMlAcP6rrjRbmSW0B+oeHPi8emuXByCzwfVesjPq+RkJ7Nc2uPsu9c6g3bLQS4O9jg4WSLp7MtHT0cmdm/Ra2OqD93MYtJ/wvGIGH1I0FmZSyYRNYFdePXrA00bV1++/WzIWIjzA25MajtVhOzH9ZOU8vyfgNh4AuqZkIZSCl5cUM43x6I5eW7218PMP37huOsCIll6dTAiumLX06GL+9UOf7Tv4fmXcw/xjWSwuGLEWqsH9rKsYsF3LNkL0F+Lrx0V/syS+aSkwnvtwf/4SpdrLrYu1i5ZiathjYjin28+2QyT64KQwjBogkB1wNzx3+6n5z8QjY/3g9yL8Oiziqu4sH11dfXOoAQ4pCUMrCkz/SMvY5SLCrduxcc+QZSz5p24a4FeDrZsnJWENl5hSRmZJOYnk1CmnqOT1fPIVGX2BSWSN9WTWnvUbuiXpMyctgWfp4tx5MIjbmEs501q2ZXkVG/nATRvyv/dvTvKnAN1Kyu64PKIDqUIBIDEBcKx1ZD/2f+WkYd1Cz9iTA4+LlKlftiOPgNgkEvKhXGEhBC8MaYjqRdyePV70/g0sgaKWFFSCyPDPCrmFG/egm+HqvGeerGyhl1APeOcP+XKsNg3Uw6T1xB6N+H0rSxdfk3rGErldsj6LHK9aE8gh5V15htf1M3VTelOA5u68YP8/rzyDeHmPFVKE8Mbs0jA/wIi01nWh+j2E/wJ0qIZtDfq7evdRw9Y68vXDwN/+0B9yyBbg/e6t7UGBcv59LzXzt5eqg/84b89W9oEtOz2RqexNbj5zloLPbRxs2eOzu5c193r+sZDyViKFT+yfyrxufsIq+vKrnNuAPKkF86p/axtlczWt++4NVTFdUI/Uzl9faeq3yyRdOADAb4fChkJMC8Q6ansN0K8q5AqNHAX01RKV4DXwDvHsXb5mSSmxLN4vU7yb4QjbSwItW1D+/PGYuVOUvwWRfhzE9Kiz3llMoE8BtYVX+RWqbe8iwEzYUR/yq/vaEQPuwOjZrBTPMEfSpE1K+w/B5lmAc8X2KT7LxCXtoYzrrD8bRxs+dU8mU+nxbIEN+G8EFnFWfxwKrq72stp6wZuzbs9QWDAd71g7ajYPSSW92bGmXMf/cipWTT4/1udVeKkX41jxOJmRyNz+CnE0kciVWKaG3d7RnZqTkjOzUvWwbzGoeWwQ9PK19uWdg4qgunb1+4rS+4dy6eInbpD9j9OoSvA7smMOBvSlrTyhrCvoWNc1Q0epeqia6udvKuKIO4b7HKi281VJXfTI/5U6wku5SKaU4+6oag1RAVS2Bz05K3lKrwyKmtcHqbKneKVMF8oxaWuCRdabYugJCP4a73bijuVCInt8CqSXDflyqvuyZYO12Nx9wD4Fyy7K6UkpUHYnllc4SqMf/PO3AMfldpFzyyB5p3rpm+1mK0YdcoVk5Q6TOPh97qntQoS3af4T8/nebAi0NuWWqYlJLzGTlEJGYSkZhBRGImJxIzVRU+I+2bOzCykzsjOzXHz5zl9ox4WNIT3DpA+3uggS00aKQCrxo0Uu+t7ZT2tbNv2RHsRUk4rOpzR+9Roh4DF8COl1Ww28M7zdKB/0uQm6XkVPd9qHTBbxAoue3669zGXuRlpWOf8JsqbfrHb0qlTFiq5fyWQ1Qswh+/wentkGGsVe/RFfzvVMbcvXP1xbIYClWGwZmfoPVwJQzTZmTJmQDLRqkbtflHa67caEYCLAlU+ecTV5TZNDwhg/i0q4zwa6h86y0HwYSva6aftRxt2DWKPe/Brtfg+T9MSgeqK5xMymTEoj28Pa4TE3v61Pj3h0ZfYu6Kw1y4rLTAhYAWTRvRwcOR9s0d6OChHk0qKjKzajKc3akC2Zx9q67joGakZ3cqg34hQm17eGfJy9m1BYNB/RNMNbwFeRAfqmqVn9sNiWGAVOlrfoNUUJr/cBWVX1PkZsEvbymBoIw4ddNxWx9od49KL3T0VFK/n/aHYa8pl0pNsud9VRVt8jpoPbT89jtfgd8XwaP7wK2CaYX1DG3YNYrovSontpSo1SrHUAgFOWBdQonPGkRKSb9//0y75g58Nq3E86DaSM3KZeTiPTS0smRm/xZ08HCgrbtDpSV3r3NqK3w7EYb8UwWzVReGQji+Vv0/SxOjqS9cSVFBqM27qNWQW4mUcD5MxUZE/qD8+gAe3VQg5IUT8PSJ4qqA1U1BHnzcW/Xvsf1gVcZNa9ZF5Vtvcyfc90XN9bGWo6PiNQqPriooKi6kZgz7lmeV3nOrYdBlglqmrEgxkEoihGBoO1dWH4wjJ7+wXPnQqsJgkDyz9ihpV/PZ8FiPcstsmk3eFdjyvPIX955Xtce+GQvL2uNTr24aNVWPvwJCqPPao6u6ubt4Gk4ajXzCQVVpr6aNOqh4jDvfUWp7a6aquAb3zspddHPA5d5F6oZx4As13886ijbs9QlrOzXLiAup/u9KDFOykN691Izi9FZo6AgdRitJS5/eNeqjHdLOja/2x7D3bApD2pmXvvTl3j+UNnbnUtK/SuGz36NU4ZrRHareqIOqUZ0RC9O3qAupRtPMH5o9o1ZvrqTe2sImrYZA3yfVzf3pbcaNQikLundWAXJNWqksjM4T6kwa7l8BbdjrG9694OAXUJivyhtWB1KqGsp2TWDyGrBurAKNjq2G4+vUie7oo9THukyskRO6l58LjRtasTPyglmGPTb1Kq/9cELVKMnqwLQ+vibtdzg2jXe2neLOju5MCSo5MrhSJJ9Qkq4BU1SEu0ZzM43K0KGvKYa9qiR/MxNVAZrzx9Rz/EGIMArQCMtSU+M0FUMb9vqGdy9VDOL8MfDqXj3fEbFeVZK6e/Gf6UEtB6nHXe8pzeqjq5Qe9J7/qBn80FdKF0SpAhpaWXK7f1N2n0zGYOh4Y3GMMvg6OBpLIejdqgkvb44gJ7+QRwa0LHOfjKv5zFt5BHdHG96+t3PVK94ZDPDj06rC2bDXqvbYGk1VI4QK5nP0vF7IBlAphknHwbIhuPjduv7VQWpZvoqm0nj3Us/VtRyfd1VFULt3gq5Tin9u3UjN1B9cD09HQr+n1I3Ah91VJG1BbvX0CxjS1o3kzFzCEzNMap+dV8jq0DhjWvPcAAAMZElEQVSGd3Tni+k9uLuLB29tPcminacpLehUSsnz646SnJnDkge6VU/t+LAV6sZp2Ot/jVmZRlMRbJ2VNoBPr1vdkzqHNuz1DYfmKl83Lrh6jr/vQ5V+M+Lf5edL27urmfrcEKXOtetV+G8vJapRDdkag9q6YiFgZ+QFk9pvCksgM6eAab19aWBpwaIJAdzX3YtFO8/w9raTJRr35ftj2B6RzII72xLgXQ1lbK+kKD1un94QMLnqj6/RaGo92rDXR7x7KWnRqjaeGfGqLnb7Meb5fV38YNJKVavb0lopZX0zDi6eqtLuuTSypvttzuyKTC63rZSSZfuiaetuTw9fFVVsaSF4597OTAny4dNfo3hlcwQGw59jGJ6QwZs/RjKkrSsP96smDfUd/1SFMkYtrH0CMRqNpkbQV4b6iHcvVTozPbZqj7vzFUBW3O/bcjA8uhdGvA3xh+DjPrDthSrt55B2bkQkZnI+I7vMdqHRaZxMusz0Pr43+MgtLASvj+7IrP4t+Gp/DC+sP06hQZKVW8DjKw/TpLE1/7m/S/VUkov+XS3D95kHru2q/vgajaZOoIPn6iPX/eylazmbTWyIEjC5/bnKHdOygaoS1el+2P2GKqYR/JGa1fsNVA/f/hVWzhvazpW3t55kZ+QFHiwjWv2r/dE42FgxOqB4rXAhBC+ObIdtA0sW7z5LTkEhBglxadmsmh2Ec6NqSD0ryFNa8E4+cLuOINZoNKWjDXt9xK2DSkGLC4bO9xf/XEq1rJ4Rr4QvyhOVMRhUqUZ7DxUMVxU0agp3L1Kz0zM7IOoXOLZWpeohwCMAWgxQhv62PmUrWxWhZbPG3NbEjl2RyaUa9qSMHLaHJ/FQX19srUuOExBC8PQdbbCxtuSdbcpl8Owd/vTwrQap3tzLSgo45RQ8sEbpEWg0Gk0paMNeH7GwBK9AiA2GlLPKYFw8qVSrUk5ByhlV9ALA0RsGvwSdxpfu0z36LSQegXFLq14+tklL9Qiao3LvEw4rIx/1i8rj3rsImvor/7yjV7mHUyp0bnwdHMPVvALsrIufAitDYiiUkgeDfMs93mMDW+FiZ83JpMs8OrCV+X9fWVxOgpBPIPQLyM1QddL9h1ftd2g0mjqH1oqvr/z8Fvz69o3b7D1U1apmbZSxtHWCvYuVcpx7J+U7bzn4xn1yL6tUNScfeHhH9VW0KoncLDi7AzY/ATZOMG2TSfmw+86l8MDSED59sDvDO9xYuCO3oJC+b++mi5cTn0+/RYVOLp5SJUaPrQFDAbS7G/rMrz7dAY1GU+vQWvGa4gQ+ZBSO8FZa401blyw/2X6syjPf9Rp8PVZVsxr22p/1kve8B1nJMPHbmjXqoDSnO4xVJUW/Hgtf3AlTN4Fr2zJ36+Hrgr2NFTtPJBcz7NvCk0jJymNqH18oLICU00pEw6E53Nav+iLRpVS56Xs/UPKbVrbQbSr0nqvFOzQajVnoGbvGNApyIfRz+O0dyE5X2s5dJ8M390LHe2HsJ7e2fxciYfkYKMxTy/IeAWU2n/ftEfafS+HAi0OVCl1hAaSc4sNv1uKZc5qxbhcRScehoEj0vIOnCurrMrFqotKlVC6QU1tV+c3zYWDrAj1nQ89Zf51CIxqN5i+HLtuqqTqy01WuevDHUJgLDRrBvEPVKgdrMpei4KvRkJMOk9eCT1CpTTeFJfD8qgNsH3oB39gNqmiN0YjnW9rRwDNA3Rw0D1BuiAsnlNb92V0gC1URiy4ToeN9YG9GUZnCfDUzP7UVTm2BtGi1vXmAUuoLmKyD4zQaTblU2rALIUYAHwCWwGdSyrdv+rwhsBzoDqQCE6SU0UKIYcDbgDWQBzwnpdxt3Kc7sAywBbYA86WUUgjhAqwGfIFoYLyUMq2s/mnDfgtIj1OBa969lETsX4WMeFg+WhWdmLhS6dOX0CZn/1Ku7P+cJuKyckW0HMKKOGdWxrnw7YLJONiVkgmQdQHC18OxVSpgUFgo90SrIWBlo8riWliptD0LS+P7BioW4ewOOPMT5GQofWy/AUo7238EOHhU77hoNJo6RaUMuxDCEjgNDAPigVBgkpTyRJE2jwGdpZRzhBATgbFSyglCiK5AspQyUQjREdgupfQ07nMAeAIIQRn2xVLKrUKId4BLUsq3hRALAGcp5d/K6qM27JobyLqgfO4pp+H+ZdD2LqMPO1hFmUd+D0gONAziO8u7eOfZuVy6mk/QW7sYH+jFG2M6mfY9F08rA39sjZLRLQ+7psqItxmhbgZurkut0Wg0JlLZ4LmewFkpZZTxYKuA0cCJIm1GA68YX38HLBFCCCnlkSJtIgBb4+zeBXCQUgYbj7kcGANsNR5roHGfr4BfgDINu0ZzA41dYdr3sOI+WP2gyoU/t1uVi7RxhN6PQY+ZHAs3sObHSOalZfPDsfPkFRiY2tvX9O9p5g9D/gmDXlLL/4X5Kor95kdhvpq5u7YrXz9fo9FoKokpht0TKDodiQduLsdzvY2UskAIkQE0AVKKtLkXOCylzBVCeBqPU/SY1yS+3KSU542vkwAzHJgajRE7FxUh/+0k5TJo1g5GLVJuA2Ou/ZB2V3jjx0h+OpHMN8Ex9PZrgr+bvfnfZWFRYSU8jUajqWpqJN1NCNEB+Ddwhzn7GX3uJfoKhBCzgdnGt1lCCHMqhjTlxpsOTcWpJWMZYnzMKPbJzH+r533Aqkdqsk/FqCVjWSvQY1k16HGsOqp6LEvVxDbFsCcA3kXeexm3ldQmXghhBTiigugQQngBG4CpUspzRdoXlQkresxkIURzKeV5IURzoMQam1LK/wH/M6H/xRBCHCzNN6ExDz2WVYcey6pDj2XVoMex6qjJsTRFbSMUaC2EaCGEsAYmAptvarMZmGZ8fR+w2zjbdgJ+BBZIKfdea2xcas8UQgQJVQZrKrCphGNNK7Jdo9FoNBpNOZRr2KWUBcDjwHYgElgjpYwQQrwmhLjH2OxzoIkQ4izwNLDAuP1xoBXwTyFEmPHhavzsMeAz4CxwDhU4Byo9bpgQ4gww1Pheo9FoNBqNCdQJgRpzEULMNi7layqJHsuqQ49l1aHHsmrQ41h11ORY1kvDrtFoNBpNXaWaKlpoNBqNRqO5FdQ7wy6EGCGEOCWEOGtUttOYiBDiCyHEBSFEeJFtLkKIHUKIM8Zn51vZx9qAEMJbCPGzEOKEECJCCDHfuF2PpZkIIWyEEAeEEEeNY/mqcXsLIUSI8TxfbQz81ZiAEMJSCHFECPGD8b0eywoghIgWQhw3xpYdNG6rkXO8Xhl2ozzuf4E7gfbAJCFE+1vbq1rFMmDETdsWALuklK2BXfwZOKkpnQLgGSlleyAImGv8HeqxNJ9cYLCUsgsQAIwQQgShdDMWSilbAWnAw7ewj7WN+ahA6Wvosaw4g6SUAUXS3GrkHK9Xhp0i8rhSyjzgmjyuxgSklL8Bl27aPBol/YvxeUyNdqoWIqU8L6U8bHx9GXUR9USPpdlIRZbxbQPjQwKDUfLWoMfSZIy6I3ehMpYwpiPrsaw6auQcr2+GvSR5XM9S2mpMQ0sAVwIhhC/QFSWLp8eyAhiXjsNQYlY7UOmz6cZUXdDnuTksAp4HDMb3TdBjWVEk8JMQ4pBRKRVq6ByvEUlZTf2gLAlgTXGEEI2BdcCTUspMNTlS6LE0HSllIRBgFMTaALS9xV2qlQghRgEXpJSHhBADb3V/6gD9pJQJRu2WHUKIk0U/rM5zvL7N2E2Rx9WYR7JR+peyJIA1NyKEaIAy6iuklOuNm/VYVgIpZTrwM9AbcDLKW4M+z02lL3CPECIa5aYcDHyAHssKIaVMMD5fQN1w9qSGzvH6ZthNkcfVmIeWADYTo9/ycyBSSvl+kY/0WJqJEKKZcaaOEMIWGIaKWfgZJW8NeixNQkr5gpTSS0rpi7o27pZSTkaPpdkIIRoJIeyvvUYVQAunhs7xeidQI4QYifIjWQJfSCnfvMVdqjUIIb4FBqKqFCUDLwMbgTWADxADjJdS3hxgpymCEKIfsAc4zp++zBdRfnY9lmYghOiMCkKyRE1U1kgpXxNC+KFmnS7AEWCKlDL31vW0dmFcin9WSjlKj6X5GMdsg/GtFbBSSvmmEKIJNXCO1zvDrtFoNBpNXaa+LcVrNBqNRlOn0YZdo9FoNJo6hDbsGo1Go9HUIbRh12g0Go2mDqENu0aj0Wg0dQht2DUajUajqUNow67RaDQaTR1CG3aNRqPRaOoQ/weQ5fyAZGJv/wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(nodes, activation=activation, input_shape=(X_train.shape[1],)))\n",
        "if layers == 1:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 2:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 3:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mse',\n",
        "              optimizer=keras.optimizers.Adam(lr=lr),\n",
        "              metrics=['mse'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=30,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, y_val))\n",
        "\n",
        "plt.plot(np.arange(1,31,1), np.array(history.history['val_mse']), np.arange(1,31,1), np.array(history.history['mse']))\n",
        "plt.legend(['val_mse','train_mse'])\n",
        "plt.rcParams['figure.figsize'] = [8,8]\n",
        "plt.ylim([.015, 0.04])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1563
        },
        "id": "gFWTT2vc4V91",
        "outputId": "c2d8371a-01da-42fa-e272-2c53894f9482"
      },
      "id": "gFWTT2vc4V91",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "10/10 [==============================] - 3s 90ms/step - loss: 0.4710 - mse: 0.4710 - val_loss: 0.0947 - val_mse: 0.0947\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.1278 - mse: 0.1278 - val_loss: 0.1122 - val_mse: 0.1122\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0687 - mse: 0.0687 - val_loss: 0.0694 - val_mse: 0.0694\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 31ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0223 - val_mse: 0.0223\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(nodes, activation=activation, input_shape=(X_train.shape[1],)))\n",
        "if layers == 1:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 2:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 3:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mse',\n",
        "              optimizer=keras.optimizers.Adam(lr=lr),\n",
        "              metrics=['mse'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=30,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, y_val))\n",
        "\n",
        "plt.plot(np.arange(1,31,1), np.array(history.history['val_mse']), np.arange(1,31,1), np.array(history.history['mse']))\n",
        "plt.legend(['val_mse','train_mse'])\n",
        "plt.rcParams['figure.figsize'] = [8,8]\n",
        "plt.ylim([.015, 0.04])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1563
        },
        "id": "5ugiNeXH4uum",
        "outputId": "265b20f8-ffc0-438c-831d-9c64e42a9a54"
      },
      "id": "5ugiNeXH4uum",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 109ms/step - loss: 0.1499 - mse: 0.1499 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0214 - val_mse: 0.0214\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHWCAYAAACIWdvNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iV5eHG8e+TnOydEAhksgMBZAQQBRcqw4GignvUvVpHrfZXW621tdWqVeveYosiCqKCiAqCyl4CsiFAwgqBhOz5/v44gUZIyEnyvskh3J/r4jrJOe94Toy5z7ONZVmIiIjI8cWnpQsgIiIiDacAFxEROQ4pwEVERI5DCnAREZHjkAJcRETkOKQAFxEROQ55FODGmJHGmPXGmE3GmIdqeT3AGPNh9esLjTEpR7yeZIwpMMb81tNrioiISN3qDXBjjC/wIjAK6AlcYYzpecRhNwIHLMvqAjwL/OOI158BZjTwmiIiIlIHT2rgg4BNlmVtsSyrDPgAGHPEMWOAd6u/ngwMN8YYAGPMRcBWYE0DrykiIiJ18CTA44EdNb7PrH6u1mMsy6oA8oAYY0wo8CDw50ZcU0REROrgcvj6jwLPWpZVUF0hbzBjzC3ALQAhISEDUlNT7Sud7SzYuQLC20NoXEsXRkREjnNLly7dZ1lWbG2veRLgWUBije8Tqp+r7ZhMY4wLiABygMHApcaYJ4FIoMoYUwIs9eCaAFiW9RrwGkB6erq1ZMkSD4rcQiwLHouGYbfBWQ+3dGlEROQ4Z4zZVtdrngT4YqCrMaYj7pC9HLjyiGOmAdcB84FLgW8t9y4pw2oU4lGgwLKsf1eHfH3XPP4YA65AqChp6ZKIiEgrV2+AW5ZVYYy5C5gJ+AJvWZa1xhjzGLDEsqxpwJvABGPMJmA/7kBu8DWb+F68gysAKkpbuhQiItLKedQHblnWdGD6Ec/9qcbXJcBl9Vzj0fqu2SqoBi4iIs3A6UFsJx5XAJQrwEWkdSsvLyczM5OSEv29s0NgYCAJCQn4+fl5fI4C3G6uINXARaTVy8zMJCwsjJSUFBo7y0jcLMsiJyeHzMxMOnbs6PF5WgvdbuoDF5ETQElJCTExMQpvGxhjiImJaXBrhgLcbuoDF5EThMLbPo35WSrA7aYauIiINAMFuN1cgVBR3NKlEBGRGkJDQ1u6CLZTgNvNL1A1cBERcZxGodtNfeAicoL582dr+HnnQVuv2bNDOI9ckFbn6w899BCJiYnceeedADz66KO4XC5mz57NgQMHKC8v5/HHH2fMmPo3upwzZw6PPPIIkZGRrFq1inHjxtG7d2+ee+45iouLmTp1Kp07d+ajjz7iz3/+M76+vkRERDB37lwqKyt56KGHmDNnDqWlpdx5553ceuuttv0cjkU1cLupD1xExHHjx49n0qRJh7+fNGkS1113HVOmTGHZsmXMnj2b+++/H/eq3vVbuXIlr7zyCmvXrmXChAls2LCBRYsWcdNNN/HCCy8A8NhjjzFz5kxWrlzJtGnTAHjzzTeJiIhg8eLFLF68mNdff52tW7fa/4ZroRq43VQDF5ETzLFqyk7p168fe/fuZefOnWRnZxMVFUVcXBz33nsvc+fOxcfHh6ysLPbs2UNcXP27Qw4cOJD27dsD0LlzZ84991wAevfuzezZswE49dRTuf766xk3bhxjx44F4KuvvuKnn35i8uTJAOTl5bFx48YGzeduLAW43bQSm4hIs7jsssuYPHkyu3fvZvz48fznP/8hOzubpUuX4ufnR0pKisdzqwMCAg5/7ePjc/h7Hx8fKioqAHjllVdYuHAhX3zxBQMGDGDp0qVYlsULL7zAiBEj7H+D9VATut0OrcTmYbONiIg0zvjx4/nggw+YPHkyl112GXl5ebRt2xY/Pz9mz57Ntm117sTZKJs3b2bw4ME89thjxMbGsmPHDkaMGMHLL79MeXk5ABs2bKCwsNDW+9ZFNXC7uQIACyrLweXf0qUREWm10tLSyM/PJz4+nvbt23PVVVdxwQUX0Lt3b9LT00lNTbX1fg888AAbN27EsiyGDx/OSSedRJ8+fcjIyKB///5YlkVsbCxTp0619b51MZ528HuD9PR0a8mSJS1djGP78d/w1R/goR0QGN7SpRERccTatWvp0aNHSxejVantZ2qMWWpZVnptx6sJ3W6u6n4UjUQXEREHqQndbq5A96NWYxMR8SqrVq3immuu+cVzAQEBLFy4sIVK1DQKcLv5BbkfVQMXEfEqvXv3ZsWKFS1dDNuoCd1uh5vQNZVMREScowC32+EmdNXARUTEOQpwu6kGLiIizUABbrfDNXAFuIiIOEcBbrdDAa7lVEVEHJObm8tLL73U4PNGjx5Nbm6uAyVqfgpwu6kGLiLiuLoC/NC65XWZPn06kZGRThWrWWkamd20kIuInGhmPAS7V9l7zbjeMOrvdb780EMPsXnzZvr27Yufnx+BgYFERUWxbt06NmzYwEUXXcSOHTsoKSnhN7/5DbfccgsAKSkpLFmyhIKCAkaNGsXQoUP58ccfiY+P59NPPyUoKKjW+51xxhn069ePefPmUVhYyHvvvccTTzzBqlWrGD9+PI8//jiFhYWMGzeOzMxMKisr+eMf/8j48eNZunQp9913HwUFBbRp04Z33nnn8M5nTaEAt5tq4CIijvv73//O6tWrWbFiBXPmzOG8885j9erVh7fxfOutt4iOjqa4uJiBAwdyySWXEBMT84trbNy4kYkTJ/L6668zbtw4Pv74Y66++uo67+nv78+SJUt47rnnGDNmDEuXLiU6OprOnTtz7733MmfOHDp06MAXX3wBuLcWLS8v5+677+bTTz8lNjaWDz/8kD/84Q+89dZbTf4ZKMDtphq4iJxojlFTbi6DBg36xR7czz//PFOmTAFgx44dbNy48agA79ixI3379gVgwIABZGRkHPMeF154IeBeECYtLe1wLbpTp07s2LGD3r17c//99/Pggw9y/vnnM2zYMFavXs3q1as555xzAKisrLSl9g0KcPtpKVURkWYXEhJy+Os5c+bw9ddfM3/+fIKDgznjjDNq3Re85h7gvr6+FBcf++92zT3Cj9w/vKKigm7durFs2TKmT5/Oww8/zPDhw7n44otJS0tj/vz5TX2LR9EgNrupBi4i4riwsDDy8/NrfS0vL4+oqCiCg4NZt24dCxYsaJYy7dy5k+DgYK6++moeeOABli1bRvfu3cnOzj4c4OXl5axZs8aW+6kGbjdj3LVw9YGLiDgmJiaGU089lV69ehEUFES7du0OvzZy5EheeeUVevToQffu3Tn55JObpUyrVq3igQcewMfHBz8/P15++WX8/f2ZPHkyv/71r8nLy6OiooJ77rmHtLS0Jt9P+4E74e9JcNIVMOofLV0SERFHaD9w+2k/cG+gGriIiDhMTehOcAVoJTYRkePQnXfeyQ8//PCL537zm99www03tFCJ6qYAd4IrSDVwEZHj0IsvvtjSRfCYmtCd4ArQKHQRafWOpzFU3q4xP0sFuBPUBy4irVxgYCA5OTkKcRtYlkVOTg6BgYENOk9N6E5QDVxEWrmEhAQyMzPJzs5u6aK0CoGBgSQkJDToHAW4E1yBULSvpUshIuIYPz+/XyxdKs1PTehO8AtUDVxERBylAHeC+sBFRMRhCnAnqA9cREQcpgB3gmrgIiLiMAW4E1zqAxcREWcpwJ3gCoRy7QcuIiLOUYA7wRUIViVUVrR0SUREpJVSgDvBFeB+VD+4iIg4RAHuBFf1cnjqBxcREYcowJ2gGriIiDhMAe4EvyD3owJcREQcogB3gmrgIiLiMAW4Ew73gSvARUTEGQpwJxyugWsQm4iIOEMB7gTVwEVExGEKcCccqoGXK8BFRMQZCnAnuDQKXUREnKUAd4L6wEVExGEKcCeoD1xERBymAHeCauAiIuIwBbgTDtfAtaWoiIg4QwHuBG1mIiIiDlOAO8HHB3z91QcuIiKOUYA7xRWoGriIiDhGAe4UV4Bq4CIi4hgFuFNcgVqJTUREHKMAd4orUDVwERFxjALcKeoDFxERBynAnaI+cBERcZAC3CmqgYuIiIMU4E5RDVxERBykAHeKX5ACXEREHKMAd4pq4CIi4iAFuFPUBy4iIg5SgDtFNXAREXGQAtwpqoGLiIiDFOBOcQVCufYDFxERZyjAneIKhKpyqKps6ZKIiEgrpAB3iivA/ahmdBERcYAC3CmuQPejBrKJiIgDFOBOUQ1cREQc5FGAG2NGGmPWG2M2GWMequX1AGPMh9WvLzTGpFQ/P8gYs6L630pjzMU1zskwxqyqfm2JXW/Ia/gFuR8rNJBNRETs56rvAGOML/AicA6QCSw2xkyzLOvnGofdCBywLKuLMeZy4B/AeGA1kG5ZVoUxpj2w0hjzmWVZFdXnnWlZ1j4735DXUA1cREQc5EkNfBCwybKsLZZllQEfAGOOOGYM8G7115OB4cYYY1lWUY2wDgQsOwp9XFAfuIiIOMiTAI8HdtT4PrP6uVqPqQ7sPCAGwBgz2BizBlgF3FYj0C3gK2PMUmPMLY1/C15KNXAREXFQvU3oTWVZ1kIgzRjTA3jXGDPDsqwSYKhlWVnGmLbALGPMOsuy5h55fnW43wKQlJTkdHHtoxq4iIg4yJMaeBaQWOP7hOrnaj3GGOMCIoCcmgdYlrUWKAB6VX+fVf24F5iCu6n+KJZlvWZZVrplWemxsbEeFNdLHKqBlyvARUTEfp4E+GKgqzGmozHGH7gcmHbEMdOA66q/vhT41rIsq/ocF4AxJhlIBTKMMSHGmLDq50OAc3EPeGs9XIdGoSvARUTEfvU2oVePIL8LmAn4Am9ZlrXGGPMYsMSyrGnAm8AEY8wmYD/ukAcYCjxkjCkHqoA7LMvaZ4zpBEwxxhwqw38ty/rS7jfXotQHLiIiDvKoD9yyrOnA9COe+1ONr0uAy2o5bwIwoZbntwAnNbSwxxX1gYuIiIO0EptTDge4auAiImI/BbhTDjehqwYuIiL2U4A7RU3oIiLiIAW4U3xd4ONSgIuIiCMU4E5yBaoPXEREHKEAd5IrQDVwERFxhALcSa5ABbiIiDhCAe4kV6CWUhUREUcowJ2kGriIiDhEAe4kV4AGsYmIiCMU4E5SDVxERByiAHeSauAiIuIQBbiT/IKgorilSyEiIq2QAtxJqoGLiIhDFOBOUh+4iIg4RAHuJNXARUTEIQpwJ6kGLiIiDlGAO0krsYmIiEMU4E5yBUJlKVhWS5dERERaGQW4k1wB7kf1g4uIiM0U4E5yBbof1Q8uIiI2U4A7STVwERFxiALcSYdr4FqNTURE7KUAd5LfoQBXDVxEROylAHeS+sBFRMQhCnAnqQ9cREQcogB3kmrgIiLiEAW4k1zqAxcREWcowJ10KMDLNQpdRETspQB3kmrgIiLiEAW4kw4PYlMfuIiI2EsB7iQNYhMREYcowJ2kaWQiIuIQBbiT/ILcj1pKVUREbKYAd5KPC4yPauAiImI7BbiTjHH3g6sPXEREbKYAd5orQDVwERGxnQLcaaqBi4iIAxTgTnMFQrkCXERE7KUAd5pq4CIi4gAFuNPUBy4iIg5QgDtNNXAREXGAAtxpqoGLiIgDFOBO8wvSSmwiImI7BbjTVAMXEREHKMCdpj5wERFxgALcaaqBi4iIAxTgTlMNXEREHHDCBnhRWQU79hc5fyNXoGrgIiJiuxM2wC97ZT4PfvyT8zdyBUJ5MViW8/cSEZETxgkb4Gd2b8vCrfvZX1jm7I1cAYAFleXO3kdERE4oJ2yAj+wVR2WVxayfdzt7I1eg+1H94CIiYqMTNsDTOoSTGB3EjNVOB3iA+1H94CIiYqMTNsCNMYzu1Z4fNu0jr9jB5m3VwEVExAEnbICDuxm9vNLim7V7nLuJX5D7UQEuIiI2OqED/KSESNpHBDrbjH64CV0BLiIi9jmhA9zHxzAiLY7vNmRTUFrhzE0ON6GrD1xEROxzQgc4wOje7SmrqGL2ur3O3EA1cBERccAJH+ADkqNoExrAl041o2sQm4iIOOCED3BfH8OItHbMXr+X4rJK+29wKMDLFeAiImKfEz7Awd2MXlRWyXcbsu2/uGrgIiLiAAU4MLhjNFHBfny5epf9F9dCLiIi4gAFOODy9eGcnu34Zu1eSitsbkZXDVxERBygAK82qld78ksr+GHTPnsvrBq4iIg4QAFe7ZQuMYQFupixyubR6IdXYiu297oiInJCU4BXC3D5cnaPdsxau4fyyir7Luzr735UDVxERGykAK9hZK84covKWbhlv30XNcbdD64+cBERsZECvIbTu8US7O/LdLtHo7sCVAMXERFbKcBrCPTz5czUtny1ZjeVVZZ9F1YNXEREbKYAP8KoXnHsKyhjSYaNzeiuQNXARUTEVgrwI5zZvS0BLh97txh1BUK5RqGLiIh9FOBHCAlwcXq3WL5cvZsqu5rR1QcuIiI2U4DXYlTvOHYfLGFFZq49F1QfuIiI2EwBXouzUtvh52uYscqm0eiqgYuIiM0U4LWICPJjaJc2zFi9G8uyoRndL0g1cBERsZUCvA6jerUn80Axa3YebPrFXAEKcBERsZUCvA7n9GyHr49hhh2LuqgPXEREbKYAr0NUiD9DOsUwY5UNzejqAxcREZt5FODGmJHGmPXGmE3GmIdqeT3AGPNh9esLjTEp1c8PMsasqP630hhzsafX9AYje8WxZV8hG/YUNO1CqoGLiIjN6g1wY4wv8CIwCugJXGGM6XnEYTcCByzL6gI8C/yj+vnVQLplWX2BkcCrxhiXh9dsceemtcMYmt6MrpXYRETEZp7UwAcBmyzL2mJZVhnwATDmiGPGAO9Wfz0ZGG6MMZZlFVmWVVH9fCBwqC3ak2u2uLZhgQxMjm76HuFaiU1ERGzmSYDHAztqfJ9Z/Vytx1QHdh4QA2CMGWyMWQOsAm6rft2Ta3qFUb3jWL8nny3ZTWhGdwWCVQmVFfUfKyIi4gHHB7FZlrXQsqw0YCDwe2NMYEPON8bcYoxZYoxZkp2d7Uwhj2FkrziApq2N7gpwP6ofXEREbOJJgGcBiTW+T6h+rtZjjDEuIALIqXmAZVlrgQKgl4fXPHTea5ZlpVuWlR4bG+tBce3VPiKIvomRfNmkAK/+zKJ+cBERsYknAb4Y6GqM6WiM8QcuB6Ydccw04Lrqry8FvrUsy6o+xwVgjEkGUoEMD6/pNUb3jmNVVh479hc17gKqgYuIiM3qDfDqPuu7gJnAWmCSZVlrjDGPGWMurD7sTSDGGLMJuA84NC1sKLDSGLMCmALcYVnWvrquaecbs9OoXu0BGl8L9wtyPyrARUTEJi5PDrIsazow/Yjn/lTj6xLgslrOmwBM8PSa3ioxOpi0DuHMWL2Lm0/r1PALqAYuIiI200psHhrVK45l23PZldeI6WCH+8AV4CIiYg8FuIdG9XY3o89sTDP64Rq4BrGJiIg9FOAe6hwbSrd2oY2bTqYauIiI2EwB3gAje7VnccZ+svMbWJM+FODlCnAREbGHArwBRveOo8qCr35uYC1cNXAREbGZArwBurcLo2ObEL5as6dhJ6oPXEREbKYAbwBjDKd0jmHptgNUVjVgj3DVwEVExGYK8AZKT4mioLSC9bvzPT9JNXAREbGZAryB0pOjAVi6bb/nJ2klNhERsZkCvIESooJoFx7Akm0HPD/JVyuxiYiIvRTgDWSMIT05miUZDQhwHx/w9VeAi4iIbRTgjTAgOYqs3OKGLavqClQfuIiI2EYB3gjpKVEADauFuwJUAxcREdsowBuhR/twgvx8WdqQfnBXkGrgIiJiGwV4I/j5+tA3MZIlDRmJ7gqA8kbsZCYiIlILBXgjDUyJ4uedBykorfDsBPWBi4iIjRTgjTQgJZoqC1Zsz/XsBFcAlBc5WygRETlhKMAbqV9SJMbgeTN6aDsoaOAa6iIiInVQgDdSeKAf3duFeT6QLTIRcneA1YA11EVEROqgAG+C9JQolm/P9Wxjk4hEKMuH4gaMXBcREamDArwJ0pOjKSitYN3ug/UfHJnkfszb4WyhRETkhKAAb4JDC7p41Iwemeh+zFWAi4hI0ynAmyA+Moi48EAWe7IiW4Rq4CIiYh8FeBMYYxiQEsXSDA9GogdHg18w5G53vmAiItLqKcCbKD05ip15JezMrWeVNWPc/eAKcBERsYECvInSk6MBPNsfPCJRTegiImILBXgT9WgfRrC/r2fN6JGJqoGLiIgtFOBN5PL1oV9SpGcD2SKT3PPASwucL5iIiLRqCnAbDEiOZt1uDzY2iaieSqZmdBERaSIFuA3Sk6OosmD59npq4YcWc9FccBERaSIFuA36JUXiY2BJfc3oh2rguducL5SIiLRqCnAbhAX60T0uvP4V2ULbga+/mtBFRKTJFOA2SU+OYvn2A1RUVtV9kI8PRCSoCV1ERJpMAW6T9JQoCssqWbc7/9gHRmgqmYiINJ0C3CbpKdULutQ3HzwySU3oIiLSZApwm8RHBtE+IrD+Fdkik6BgD5SXNE/BRESkVVKA22hAclT9A9kOzwXPdL5AIiLSainAbZSeHMWuvBKyjrWxyaF9wfPUDy4iIo2nALeRR/3gWsxFRERsoAC3UWpcGCH+vsde0CWsAxhfDWQTEZEmUYDbyL2xSdSxB7L5uiC8g6aSiYhIkyjAbTYgOYr1uw+SX1Je90GRSWpCFxGRJlGA2yw95dDGJrl1HxSRqCZ0ERFpEgW4zfolRbk3NjlWM3pkIhzMgspj1NJFRESOQQFus9AAF6lx4cceiR6RCFYVHNzZfAUTEZFWRQHugIEpUazYkVv3xiaHppKpGV1ERBpJAe6AASnRFJVVsnZXHRubaC64iIg0kQLcAenJUQAs2VZHM3p4vPtRU8lERKSRFOAO6BAZRIdjbWziFwihcVpOVUREGk0B7pABKdEsydiPZVm1HxCZqCZ0ERFpNAW4Q9KTo9hzsJTMA3VsbBKRqCZ0ERFpNAW4Q9JT3P3gdW4vemgueFUdI9VFRESOQQHukNS4cEIDXHUPZItMgsoyKNjTvAUTEZFWQQHuEF8fQ7+kyLp3JovQXHAREWk8BbiDBiRHsX5PPgdr29gkMtH9qH5wERFpBAW4g9KTo7EsWFZbP3iEAlxERBpPAe6gvkmR+Jg6BrIFhEJQtJrQRUSkURTgDgoNcNGzQ3jd/eCRmkomIiKNowB3WHpyNCt25FJe28YmEVrMRUREGkcB7rAByVEUl1eydtfBo1+MTHY3ode1WpuIiEgdFOAOO7SgS63N6JGJUF4ERcfYO1xERKQWCnCHtY8IIj4yqPYFXQ6PRN/WvIUSEZHjngK8GQxIjmJJxoGjNzaJ1GIuIiLSOArwZjAwJYq9+bVsbHJ4MRcFuIiINIwCvBkMSI4GOLoZPTAS/MM0lUxERBpMAd4MuseFERbgYtHWIwayGeNuRlcTuoiINJACvBn4+hjOTG3Lx0szWb79iBCP1FxwERFpOAV4M3lsTBrtIgK4/f1lZOeX/u+FiETIUxO6iIg0jAK8mUQG+/Pq1enkFpdx53+X/W9ltshEKMlz/xMREfGQArwZ9ewQzj8u6cOirfv52/S17icPTSVTM7qIiDSAq6ULcKIZ0zeelTvyeOuHrfRJiODi2BpzweN6tWzhRETkuKEaeAv4/ehUBneM5vefrGJdSYT7SU0lExGRBlCAtwA/Xx/+fWV/IoP8uWnyNixXoAJcREQaRAHeQmLDAnjlmgHszS9jF22w1AcuIiINoABvQX0TI3lsTBqbSqPYvX1jSxdHRESOIwrwFnb5oCQCY1PwK8jky9W7Wro4IiJynFCAe4H+fU6ijTnIHyYtYtPe/JYujoiIHAcU4F7AFZ0MQIrfAW6ZsJT8kvIWLpGIiHg7jwLcGDPSGLPeGLPJGPNQLa8HGGM+rH59oTEmpfr5c4wxS40xq6ofz6pxzpzqa66o/tfWrjd13Ilwbyv6+BnhbMsp4r5JK6mqsuo5SURETmT1Brgxxhd4ERgF9ASuMMb0POKwG4EDlmV1AZ4F/lH9/D7gAsuyegPXAROOOO8qy7L6Vv/b24T3cXyrXo2tR1Aufxjdg1k/7+GlOZtauFAiIuLNPKmBDwI2WZa1xbKsMuADYMwRx4wB3q3+ejIw3BhjLMtablnWzurn1wBBxpgAOwreqoTFgY8Lcndww6kpXNS3A0/P2sDs9SfuZxoRETk2TwI8Hqg5STmz+rlaj7EsqwLIA2KOOOYSYJllWTW24uLt6ubzPxpjTINK3pr4+EJ4POTtwBjDE2P7kBoXzm8mLmdbTmFLl05ERLxQswxiM8ak4W5Wv7XG01dVN60Pq/53TR3n3mKMWWKMWZKdne18YVtKZNLh1diC/H159eoBGGO4dcJSisoqWrhwIiLibTwJ8Cwgscb3CdXP1XqMMcYFRAA51d8nAFOAay3L2nzoBMuysqof84H/4m6qP4plWa9ZlpVuWVZ6bGysJ+/p+BSZ9IsdyZJignn+in6s35PPo9PWtGDBRETEG3kS4IuBrsaYjsYYf+ByYNoRx0zDPUgN4FLgW8uyLGNMJPAF8JBlWT8cOtgY4zLGtKn+2g84H1jdtLdynItIhPxdUFF2+KnTu8Vyy7BOTFqSyeos7RcuIiL/U2+AV/dp3wXMBNYCkyzLWmOMecwYc2H1YW8CMcaYTcB9wKGpZncBXYA/HTFdLACYaYz5CViBuwb/up1v7LgTmQhYcDDzF0/feVYXooL9+Nv0tViWppaJiIibR/uBW5Y1HZh+xHN/qvF1CXBZLec9Djxex2UHeF7ME0D1VDJyd0B0p8NPhwf68ZvhXXn0s5+Zsz6bM1NP3OnyIiLyP1qJzVtUL+ZC3tG7kl05OJmUmGCemLGWisqqZi6YiIh4IwW4twiPB8wvBrId4u/y4cGRqWzYU8DkpZlHnysiIiccBbi3cPlDWPvDU8mONLJXHAOSo3h61gYKSzWtTETkRKcA9yaRSbU2oQMYY/i/0alk55fy+rwtzVwwERHxNgpwbxKZWGcNHGBAcjSje8fx2twt7M0vacaCiYiIt1GAe5OIRDiYBVWVdR7yuxGplFdW8eysjRicB1IAACAASURBVM1YMBER8TYKcG8SmQRVFe4FXeqQ0iaEqwYn8+Hi7Wzck9+MhRMREW+iAPcmkdVTyWoZiV7Tr4d3JcTfxRMz1jVDoURExBspwL1JxKHFXOruBweIDvHnjjO78O26vfy4eV8zFExERLyNAtybRCS4H/OOHeAAN5yaQnxkEH+bvpaqKi2xKiJyolGAexP/YAiJrbcJHSDQz5ffjujG6qyDTFu5sxkKJyIi3kQB7m0iEuucC36kMSfF0ys+nKdmrqekvO6R6yIi0voowL1NPXPBa/LxMfzfqB5k5Rbzzo8ZzpZLRES8igLc20QmQV4meLh16Cld2nBm91henL2JA4Vl9Z8gIiKtggLc20QkQUUJFGZ7fMrvR/egsLSC57/V4i4iIicKBbi3OTwX3LNmdIBu7cIYPzCR9xdsY1tOoUMFExERb6IA9zYRDQ9wgHvP7oafrw9PfrnegUKJiIi3UYB7m0M1cA9Hoh/SNjyQm4d14otVu1i67YADBRMREW+iAPc2gRHufx7MBT/SLad1IjYsgL9NX4vl4SA4ERE5PinAvVFEUoOb0AFCAlzce3Y3lm47wMw1ux0omIiIeAsFuDeKTGpwE/oh49IT6No2lH98uZ7yyiqbCyYiIt5CAe6NIhPdTeiNaAZ3+frw+9GpbN1XyH8XNrwWLyIixwcFuDeKSISyfChu3GC0M7u3ZVBKNK/N3aKNTkREWikFuDdq5Ej0Q4wxXDMkmazcYuZt0najIiKtkQLcG0Ue2he8cQEOcG5aO6KC/ZioZnQRkVZJAe6NIqoDvJE1cIAAly+XDkjg67V7yM4vtalgIiLiLRTg3ig4GvyCGzWVrKbxA5OoqLKYvDTTpoKJiIi3UIB7I2PczehNDPAubUMZlBLNB4u3azCbiEgrowD3VhGJTWpCP+SKwYlsyyliwZYcGwol0nKqqiyue2sRz32tXfdEQAHuvSITm1wDBxjVqz3hgS4mLm76hwGRlvTJ8iy+25DN6/O2UFha0dLFEWlxCnBvFZHongdeWtCkywT6+TK2fwIzV+9mf2GZTYWT1mZnbjEHS8pbuhh1Ki6r5J8z19M+IpCC0gqmLM9q6SKJtDgFuLeKbPpI9EMuH5RIWWUVnyzTYDY52k+ZuZz9zHdc88ZCrx0r8fq8Lew+WMLzV/SjZ/tw3l+wTRv2SL2mLM9s1bszKsC9lQ1zwQ9JjQunX1IkExdt1x89+YUt2QVc//ZifH0MKzPz+HCJ93W17D1YwivfbWZkWhwDU6K5dkgy63bnszij9f5hlqZbvzufez9cyeWvzefjVjoTRwHurSKqV2PL3WbL5a4YmMTm7EKWtOJPo9Iwu/NKuObNRRjg0ztPZXDHaJ78ch25Rd7V1fLMrA2UV1bx0KhUAC7s24GwQBcTFtjz/4a0Tq98t5lgf18GJEdx/0creWbWhlZXgVGAe6vQduDrb0sTOsD5J7UnNMClldkEgNyiMq59ayG5RWW8c8MgOsWG8ucxaRwsqeCpmetbuniHrdt9kElLdnDNySmktAkBINjfxWUDEvly9S725pc4ev+qKqvV/dFvKXvzS7jng+V8tnKn4/fasb+IaSt3cuWgJN771WDGpSfw/DcbuefDFZRWVDp+/+aiAPdWPj4QkWBLEzq4/+iN6duBL1btIq/IewcrifOKyyq58d0lZOwr4vVr0+mdEAG4u1quHZLMfxdtZ1VmXguX0u1v09cRFujHr4d3+cXzV52cRHmlxYeLnGvyL6+sYtRz83h02hrH7nGi+GHTPkY/9z1TV+zkT5+uJt/hAZOvzt2MrzHcNKwT/i4f/nFJHx4Y0Z1PV+zk6jcWtpoBvQpwbxZhz1SyQ64YlERpRRVTV2gE74mqvLKKO/+7jGXbD/Cvy/tySpc2v3j93nO6ERMSwB8/Xd3iA9q+25DN3A3Z3H1WFyKD/X/xWufYUIZ2acN/F22nwqF97yct2cH6Pfn8d9F2duUVO3KP1q6isopnvlrP1W8uJDLYj6cvO4kDReW89X2GY/fce7CESUsyuWRAPHERgYB7g6c7z+zCC1f0Y2VmHmNf+oGt+wodK0NzUYB7s8gk25rQAXrFR9ArPlyD2U5QVVUWD378E9+u28tfxvRidO/2Rx0THujH70elsmJHbosuwVtZZfG3L9aSHBPMtUNSaj3mmiHJ7Mor4eu1e22/f0l5Jc9/s5Hu7cKwLHh97lbb79Ha7c4r4co3FvL8t5u4tH8C0+46lUsGJDAyLY7X523hgEO14De/30pFZRW3ntb5qNcuOKkDE28ezMGSCi5+6QcWbd3vSBmaiwLcm0UmQcEeKLevn++KQUms253Pih25tl1T7Dfr5z3MXr/X1g9af/9yHZ8sy+Les7tx9cnJdR43tn886clR/P3LdS3W3XKo9vvgyFT8XbX/mRqe2pYOEYG878BgtvcXbGPPwVIevTCNC/t2YOKi7a2m2bU5zF6/l9HPz2N1Vh7PjDuJpy47iWB/FwD3n9uNwrIKXv5us+33zSsq5/0F2zi/T4fDYyaONCA5mil3nEJ0iD9Xv7GQqcfxmgIKcG92aCT6Qft+wS48qQNBfr584GDfoTTNhAXbuPm9Jdzw9mLGv7rAlnmsr363mdfmbuHaIclH9ScfyRjDn8ekkVtUxjOzmn9AW0FpBU9/tYH05ChG9Yqr8ziXrw9XDk7i+0372JzdtAWPasovKefF2ZsY1rUNQzrHcPvpnSkur+SdHzNsu0drVV5ZxRMz1nLD24tpGxbAtLuGMrZ/wi+O6doujIv7xfPujxnszrN3EOK78zMoLKvk9jOOrn3XlBwTwpTbT6V/ciT3fLiC577eeFy2SirAvVmkvVPJAMIC/bjgpPZ89tNOxweSSMNNWLCNP05dzdk92vKXMWls2VfIJS//yK0TlrBpb+NC6qMlO3hixjrO79OeRy9IwxhT7zlpHSK4+uRkJizYxpqdzTug7dXvNrOvoJQ/nNej3rKOG5iIn6+xtRb+1vcZHCgq57fndgfcgXNuz3a8+2MGBVrCtU6ZB4oY9+p8Xv1uC1cOTmLqnafSpW1orcfee3Y3qiyLF761b137orIK3v5hK8NT29KjfXi9x0cE+/HerwZzSf8Env16A/dPWnncjVBXgHszGxdzqemKQUkUlVUyrRmmc4jnaob3i1f155ohKXz3wBncd043vt+4j3Of/Y7ff/ITew56Xmv5+uc9PPTJKoZ2acPT407Cx6f+8D7k/nO6ExXszyOfrmm22smuvGJen7eFC07qQL+kqHqPbxsWyMhe7Zm8NJOisqaH64HCMl6ft4URae04KTHy8PO3n9GZvOJyTcOsw1drdnPe89+zcU8BL1zRj79d3JtAP986j0+MDuaKQUl8uHgH23LsGUw2cdEODhSVc8eZx25hqsnf5cM/L+vD/ed045PlWVzz5iKvWwfhWBTg3iysAxhfWweyAfRNjCQ1LkzN6F7kyPAOcLn/+IUEuPj18K7M/d2ZXHdKCpOXZnL6U7N58st15BUfuwVlccZ+7vzvMtI6hPPKNQMOX9NTEcF+PDgylSXbDvDJsubpJ3xq5nqqLPjdiO4en3PtkGTySyr4dEXTP5C+MnczhWUV3H/uL+/fLymKIZ1ieOP7LcddLc1JpRWV/PmzNdwyYSlJ0cF8fvdQLjipg0fn3nVmF1y+hn/ZsLtcaUUlr8/dwuCO0QxIrv+DX03GGO4e3pXnLu/Liu25jH3pRzKOkxHqCnBv5uuC8A6QY+9gD2MMlw9MZFVWHquzvGO+74msrvCuKSY0gEcuSOOb+85gZFocL83ZzOlPzeaNeVsoKT86UNbuOsiv3llMfGQQb18/kNAAV6PKdumABPomRvLEjHWOb3ayOiuPT5ZlccOpKSRGB3t8XnpyFKlxYUyY37T10fccLOHdHzO4uG883dqFHfX6HWd2Zs/B0mb7MOPttuUUcunL83n7hwyuPyWFybcPqXPgWG3ahgdy/Skdmboii/W785tUlqnLs9h9sIQ7G1D7PtKYvvH85+bBHCgq4+KXfmBJhvePUFeAe7ukIbDmE5jxEFTY17Rzcb8EAlw+TFykJsGW5El415QUE8y/Lu/H53cPpU9CJI9/sZbhT3/Hx0szqayet71jfxHXvbWIYH9f3rtxEDGhAY0un4+P4S9jepFTWMqzszY0+jr1sSyLx7/4megQ/wb/ETbGcM2QZH7edZBl2xs/u+Lf326iotLinrO71fr60C5t6B0fwavfbT78sz4R7SsoZeKi7Zz//Pdsyynk1WsG8OiFaQ1u4QG47fROhPq7+OdXjR8sWVll8fKczfSKD2dY1zb1n3AMA1OimXLHqUQG+3PVGwv5cvXuJl3PaQpwbzfm3zDoVlj4Mrx1Luy3Zz5qRLAf5/Vuz6crdtrSdygN934Dw7umXvERvPerQfznpsFEh/hz/0crOe/5eXy2cifXvrWIkvJK3vvVYBKiPK/J1qV3QoR7Scr521i3+2CTr1ebb9buZcGW/dxzdlfCA/0afP5FfeMJDXAxYX5Go+6/PaeIiYu2M35gIkkxtf/MjDHccUZnMnKKmL5qV6PuczzKKypn5prdPDptDSOenUv641/z+09W0bltKF/8ehgj0uqeKVCfyGB/bjmtE7N+3sPy7Y2bbTF91S4ycoq484wuHg3QrE9KmxA+vv0UerQP5/b/LOW9+RlNvqZTFODezhUAo5+E8e/D/i3w6mmwZqotl758UBIFpRV8/tOJ88fIW7y/YBsPT13N8NSGh3dNp3Zpw6d3nsq/r+xHcXkld09czq68Yt66fiDd445uBm6s357bnbBAF39yYEBbeWUVf5uxlk6xIVwxKKlR1wgJcHFJ/3imr9rNvoLSBp//r2824OtjuPusrsc8bkRaHJ1iQ3hpzubjctqRJwpKK5i9fi9/m76WC174nr5/+YpbJyzlg8XbaRsewAMjujPljlP4+PZTGtTVUZcbhnYkJsS/UbVwy7J4ac5mOseGNOmDxJGiQ/yZePPJDE9tx58+XcPfZ6xr8ZUJa9O4jjFpfj0ugLg+MPkG+Og6yLgJzv0r+AU2+pIDU6LoHBvCxEXbGZeeaGNh5VhqhvdLVzc+vA/x8TGc36cD5/aMY+qKLDq2CSE9Jdqm0rpFhfjzuxGp/N+UVUxbuZMxfeNtu/bERdvZkl3I69em4+fb+DrFNUOSeXf+Nj5cvKNBzfAb9+QzdXkWNw3rdHjpzbr4+BhuO70zv5v8E3M2ZHNm97aNLq+3KCmvZOm2A8zfnMOPm/fxU2YeFVUW/r4+9E2K5DfDu3JK5zaclBjR5N/V2oQGuLjzzC489vnP/LBpH6d28bwZfM76bNbuOshTl/Zp0AwLTwT5+/LK1f3507Q1vPLdZvYcLOEfl/Spc2GhlqAAP55EJcMNX8I3f4b5/4Ydi+CydyDm2IsW1MUYwxWDknj8i7Ws351va41Namd3eNfk7/Jx9IPY+IGJfLB4O3/9Yi1npbYlrBFN3Uc6WFLOv77eyMmdojm7R9PCsEvbMIZ0iuG/C7dz2+md8fXwD/ozszYQ7O/ittM9+//oor7xPDtrAy/P3nxcB3hVlcVvJ6/k85W7KKuswtfH0CchgltO68QpndswIDmKIH/7A7s2Vw5O4o15W3hq5npO6RzjcVP4S3M2ER8ZxEX97PtAWZPL14e/XtSL+Mggnpq5nuz8Ul6+ur8tv/t28J6PEuIZlz+M+Ctc8YF7etmrp8GqyY2+3Nj+Cfj7ajBbc3AyvJuDr4/hsTG9yC4o5flv7FmA48XZmzhQVMbD5/W0pf/y2iHJZOUWM3udZ+uj/5SZy4zVu7lxaEeiQ/zrPwH3B6Wbh3ViUcb+42Kkcl3e+mErnyzLYmz/eN66Pp0VfzqHKXecyu9GpjK0a5tmC2+AQD9ffnN2V1bsyGXWz3s8OmfR1v0szjjAzcM6Nqnlpj6HNkJ56tI+LNiSw7hXFzRoLQYnKcCPV91Hwa3zoF0afHwjfPYbKG/4jknRIf6M6BXHlOVZtU5HEnsc7+F9SN/ESManJ/L2Dxls3NO0qT879hfx9vcZXNwvnl7xEbaU7+ye7WgXHsB7Hq7M9s+vNhAZ7MdNwzo26D6XD0okKtiPl+bYv553c9i4J58nZ67n7B7teGJsb85KbdfitcpL+ifQsU0IT3+1waNR/i/O3kRMiD/jBzZu3ERDXZaeyJvXD2RbTiFjX/qRTXub9vtvBwX48SwyEa7/Ak69B5a+A68Ph+yGT/W5YmAiecXlzFitwWxOaC3hfcjvRqYSEtD0AW1PzlyPjw880IBFW+rj5+vDFYOSmLshu97FOBZuyWHuhmzuOKNzg8Mr2N/FDad25Nt1e1m7y5mR+U4pr6zivkkrCfH35YmxvW1p+bCDy9eH+87pxvo9+XxWzyqRq7Py+G5DNr8a2rFZWwpO7xbLh7cMobSiiktent/iLTAK8OOdrx+c82e46mMo2A2vnQ4rJjboEid3iiE5JpiJWpnNVuWVVbw2d/PxEd6V5VC0HypKoZ5Qjg7x57fndmP+lpxGz2BYvv0An63cyc3DOtE+IqhR16jLFYOScPkce310y7L451fraRceUOd2pfW5bkgKIf6+vHyc1cJfmr2ZVVl5/PXi3sSGNX6NACec17s9PduH88ysDZQfY5/3l+dsJizAxTVD6t5Vzym9EyKYcscpxIT4c+UbC/myBSs+GsTWWnQ9G277Hj6+CabeBhnzYPRT4F//ykg+PobxAxN58sv1bM4uoHNs7RsQiGcqqyymrcziX19vZFtOEWf3aMeLV/Xz3vDetxHeHwu51eMgjK/798YvCPyCq78OBv9g96NfMFf5BRMWkUvOpx9THHojgZ1OobCskgOFZeQWlXOgqIwDRWXkFZdzoND9fW5RGQeKysktKmPb/iLahAZwq4cDxxqiXXggI9Li+GhpJvef273WGtqcDdkszjjA4xf1Ouaa3ccSEezHVScn88a8Ldx/bjeSYzxfhaylrMrM44VvNzKmb4da94NvaT4+hgdGdOeGdxYzackOrhp8dEBvyS5g+upd3H5650atGWCHxOhgJt9+Cje9u5jb/7OMRy9I47pTUpq9HArw1iS8A1w7Db77O8z9p/sP83WfeTTV7NIBCTzz1QY+WLSdP5zXsxkK2/pUVVnMWL2bZ7/ewKa9BfRoH84b16YzvEdbr2mmPMrO5fD+JWB84Jy/QGUZlBdBWZH78fDXhe7HwhwoL8SnrIgLqgqxKgvxmfAJL1VexDPlY6mk9jAMC3QRFexPVLAfkcH+dGwTwpWDkxu9xGt9rhmSzBerdvHZTzuPGplfVWXxz5nrSYoObvKo/RuHduSdHzJ4de4W/nZx7yZdy2kl5ZXcN2kFMaH+PHZhr5YuTp3O6B5LenIUz3+zkUv6Jxz1AeuV7zbj7+vDr4Y2bNyC3aJD/PnPTSfz6w+W88i0NezMK+bBEam2T2c7FgV4a+PrgrMehrY93XPGp90NY1+DegKkbVggZ/dox8fLsvjtiO7eW1v0QpZl8fXavTz91XrW7c6na9tQXrqqPyPT4pr1f+YG2zoXJl4BQdFw7dQGT0f0Bd7/bg3dlz/OnblTGBu9lSX9/4F/m5TDYR0V4k9EkJ+jo4RrM7hjNF3bhjJh/jYuG5Dwiw9QM1bvZs3Ogzwz7qQmz+ltFx7IJQMSmLwkk3uGd6VteOPXZXDas7M2sHFvAW/fMJCI4BYasGZZ9f4tMsZdCx//2gLem5/BLaf97/dyZ24xnyzL4qrBSbRpwhLBdnHPFR/AI9NW8+p3W9iTV8KTlzb998pT6gNvrXqNdQf5qkkw72mPTrl8UCL7C8s8nsZxvLAsi017C5iwYBt3/XcZ9324gg8WbWfrvsImDcKyLIs56/dy0Ys/cPN7Sygpr+Rf4/vy5T2nMbp3e+8O77Wfu2veEYlw48xGryVw9elpDLxnIlzyJu2LN3PB/HGMMAsZ1DGaru3CaBMa0OzhDf9bH31VVh4rM/+3YU9FZRXPzFpP17ahti1Gc9vpnaioquLN7+1Z5tgJizP289q8LVwxKKnl5q7vXg0v9If/jIODx+43HtwphtO6xfLSnM3k19hE5/V5WwC4+bROjha1IXyr9wt4YER3pq7YySPTVjfbvVUDb82G/dY9Kv3bv0CbrtBzzLEP7xpLQlQQj332M+GBfpzWLbaZCmovy7LYsb+Y+Vv28ePmHOZvzmFvvnt5zfYRgZRXVvHJcveOUm3DAhjUMZrBnWI4uWM0XdqGetTcPX9zDk9/tZ4l2w4QHxnEk5f2YWy/eFwtEFYNtvx9d8tMh/5w1UcQbMOqbb0vhfj+MPlGmHQtDLgeRjzh7jdvIRf3i+cfM9bx3vwM+ib2BWDK8iw2ZxfyytUDPF7opT7JMSGc16cD7y/Yxh1ndGm52m0dCksruH/SShKigvjDeT1aphDrZ7jH5/gFu1t+XjoZznsael1SZ438gXO7c8G/v+eNeVu595xu5FRvojKmb7wta/zb6dBc8YSoIPolNmw706ZQgLdmxsCFL8CBrfDJrRCZDB361nm4r4/h1WsG8JsPVnDtW4u45uRkfj86lWB/Z35NDjU9Zx0oIjYskDah/sSGBRAbFkBogKtB/cY7c4uZvzmH+VvcgZ2V654T3yY0gFM6xzCkcwxDqkfbA2zOLmTh1hwWbd3Pwi37D4+mjg7xZ1BKNIM7RTOoYzQ94sJ/UZNeum0/T3+1gR835xAXHsjjF/ViXHqiVy2veEw/vgBfPQydznSvrx9g44DF6E7wq5kw+3H44TnYvhAufQvatcyYirBAPy7uH8+kJZk8fF5PQgJ8+dfXG+mTEMGItHaeXWTvWgiOgdBj11pvP70zn63cyXvzM7h7+LHXU29uT8xYy44DRXxw88mOjTmok2W5f+dm/QnanwRXTHSPpZh6m3v9irWfwXnPQEjMUaf2TohgdO843pi3hetOSeHtHzIoraji9jO8p/Z9JDuXGPaEOZ4W5E9PT7eWLFnS0sU4/hTshdfPgqoKuHk2hB979GlJeSX/nLmeN3/YSnJ0ME+PO4kByfaurb1iRy5/+fxnlm6rfQeiQD8f2oS6wzw2NIA21Y+HAr5NaABZucXM37yP+ZtzyMgpAiAq2I+TO7kD+5TOMXSOrb9GbVkW2/cXsbA6zBduzSHzgPsDQHigi4Ep0QzsGM2CLTnMWZ9Nm9AA7jijM1cOTmr0COZmZ1nuJXi/fxbSLoaLX3VvlOOUTd/AlNug9CCM+Buk/6revk8nrN+dz4h/zeWhUakE+fnyyLQ1TLhxEMO61tO6VFkBc5+EuU+5A3z8fyBp8DFPueHtRazMzOOHB89q1rnJxzJ3QzbXvrWIm4Z25OHzm/mDVEUZfHGvu8Wn5xi46JX/tchUVsCPz8HsJyAoyl3R6D7yqEts2pvPuc/OZfzARD7/aRdDu7Th5asHNO/7aGHGmKWWZaXX+poC/ASxezW8eS7EdoPrp3vUtLlgSw6//WglO3OLufX0ztxzdtcmD27bmVvMk1+uY+qKnbQJDeCBEd0Y3qMdOQVl7CsoJTu/+l9BKfuqHw89t7+o7KgpymGBLgZ3/F8NOzUuzJa+56zcYhZtzakO9P1s3VdIVLAft57emWuHJDvWKuGIqkr4/F5Y9i4MuMHddOnTDAFTsNcd4pu/cW/Gc8Hz9jTXN9C4V+eTdaCY0ooqOseG8MEtJx/7Q13udvj4ZtixAHpd6h6pn7sdzn8W+l9T52mLM/Zz2SvzeeSCntxwasuOkAb3NqAj/jWX0EAXn989tHk/bBbmwKRrYNsPcNrv4Izfg08trVS7V7lbB/eugX7XuD/sBYb/4pDffrSSyUszAfjsrqH0TrBn1b7jhQJc3NZNhw+udH8avvTt2v+HOkJBaQWPf/4zHyzeQWpcGM+O70uP9uH1nnekwtIKXvluM6/NrR6EMqwTt53RuUFNehWVVewvLGNvdbDHhPiT1iHCtr7MY9lXUEqIv8tralYeqyh19z2uneYeE3HWw81bE66qggUvwtd/htB2cMkbkDyk+e4PfLZyJ3dPXA7A5NuGHHunttWfwGf3gFXlDuw+l0HxAfjoBtgyGwbfDuc+7p7tUYvLXvmRrAPFzHngzBbvVrn3wxVMW7mTKXecQp+EyOa78d51MHG8e6DamBfdP8NjqSiFOU+4u13CE+Cil6DjsMMv79hfxFlPz+HkTjFMuPHYrSCA+wPrth/dv/MbZroHava/Bnpc2KJjMhpLAS7/88Nz7v6o0x+EM//P49O+WbuHBz9eRV5xGfee041bT/Nst6fKKouPl2by1FfunXzG9O3A70amEh9p7+pbUovSAvjwKtgyx12zGXJny5UlaxlM/hXkboPTH4LTfts8rQBAWUUVpz81m7QO4bxx3cA6DiqEGQ/C8gkQn+7+oBFdoxZdWeH+/2bBi9DpDPcH4FpaE2av28sN7yzmqUv7cFkLbtH75epd3Pb+Mn49vCv3ndOt+W688Wv39FVXoLu/O6HW3Knd9oXuvvH9W+DkO2D4n9yLCQHLtrsHi7ara5peRZl7cNzaabDuCyja5y5DpzMge717HFBAhHuwZf9rjzkWyNsowOV/LAs+vQtWvA+XvOn+hfbQ/sIyHp66iumrdtM/KZKnx/WlY5u6V5/6cfM+Hv98LT/vOkj/pEgePr8n/ZOab4TmCa1oP/znUti5Asb8G/pe2dIlgpKD8MX97qmNyUNh7KsQkdAst95fWEaQn2/tLSi7VrpHz+dsgmH3uZt7fesYSb78fXd3RESCe0fA2F+u425ZFqOf/56yikpm3Xt6i0wl3FdQyohn59I+MpApd5zaPNP4LAsWvQZfPgRt09zhHdmIDzBlhTDrEVj8OrTpBhe/AvF19HmXF8Pmb+HnabBhBpTkgX8odBvh7rLpco57kGZVlbspf9l77oCvys3wygAAFJBJREFUKIG43tDvWnfrQJB3/01SgMsvVZTBe2MgayncML1Bn5Ity2Layp38cepqyist/m90KlefnPyLPsUt2QU8MWMds37eQ3xkEA+NSuX8Pu29dzWy1iYvCyZcDAcy3PvFp45u6RL90oqJ7iDHgqH3wil3H65pNSvLggUvw9ePuAeqjX0NOp5W/3nbF8KHV7sD5JI3jhp8NW3lTn49cTl/H9ub8QMTm/X33rIsbp2wlDnrs/n810Pp1i7M+ZtWlrtbL5a8Cd1Hw9jXmz67YfNs+PROyN8Nw+6H03/n/lBVmg8bv3KH9sZZ7hUCAyMh9Tx3aHc689grTxYfcG+/vOw92P0T+AZAzwvdtfLkoR51K9apshzyd4GPX70DhRtCAS5HK8yB1890/xG6ZXaDa0K780r43cc/MXdDNsO6tuHJS/sQ5OfL899s4r35GQT6+XLHmZ351akdj5+R2q3Bvk0w4SIozoUrP4CUoS1dotodyICv/uiuEUUkujfkSRvbfP3zBdkw9XbYNMsdOhf+u9apTHXKy3SPJ9n1E5z9iHtHwOqyV1ZZnPf8PNbtzqdXfDg3De3E6N7tm6VP/JNlmdw3aSW/H5XqyDrzRyk+AJOug63fuX8Gwx9pWgj+4tq57hr9yokQ1wfC49017spSCGkLPc53h3bKsLpbTI5l5wp3l8lPH0FpHkSlQL+roe9V7mWpa7Is93vN2+H+b5+XVePrTDiY5Q5vqwqG3AUj/mrLjwAU4FKXvevgzXPc88N/9WWDPzVblsV/Fm7nr1+sxc/X4ONjOFhczviBidx3Tnev2+moVdu3Cea/4K7dBoTB1R8fH/18W+fBl7+HPasgaQiMfAI69HP2noemuJXkuf/QDrypcR8cyopg2l2w+mPofZl7KlR1S0JJeSVTlmfxxrwtbM4upF14ANedksKVg5KIDPa3+Q257cwtZsS/5pIaF8YHtwxxfnBnzmb47zg4sA0ueA76XeXMfdZ+9v/t3XtwlfWdx/H3lwAKiNxVCCgRVFR0RUDF2tbB0mqr9VKquLXSaqur6+hOZzt1u1vXuu2sdrqdrtOurgpabS21VCvbtUuxWKstchWvqICgJtwJCgkGcvnuH98n5hhOkiMkJD/O5zVzhnN5cnjy8HA+5/ldvr9osenWI66Wj78ARpzefmMoat+PK/rnH4pFoKxbNL8fctiHA7p254d/rqRnXPgcWhpfQvsNh36lUSBp6Mnts28owKU1K5+Eh78Ix54XhT324tvz2i3VfPuxl+hR0o2bzxuzV6PUZS+9vRD+emcM3CnpCadcHk2O/Y/s7D0rXEN9NGnO/x7s3BpXQOfcAn0LLLZSqLrdMP+2KCwy5HiYOgMOP3Hf3tMdnv0R/PHf4gvTtIc/dPXW0OA8vXIzM55Zw7OrttCrRwlTxw/nqrPKWh0/8tF3w7ly5iKWvrWN39/08Y5fGW31U/Drr0SIXvaLjp9Z0JhTHd1Cs3V1jHN48VdRN6Pf8Cykhzfdb7z1Htx+rQ2tUIBL6567G/7vW9EENuW7nb030paGhhi085c7Y67ywf3htK/Dade0WTGsS6t5D57+ASzMisx84h9jNPK+Fpxxh42vRJ/q+uUw4eq48m7PfvfGUqE9+0SgjdhztPuK9duZ+ewaHl++jtqGBs4Zczhf+3gZp5cN3Ot+8oYGZ8P2Gh5dVs4P//AG37toLFec0YFrZG9ZCX+8Lbo+hhwf3TQDRnbc3ycKcGmDe4ysXXo/XHRX1xixLHuqrYEXZ8FffwJbV8ZV9qQbot+ugHXfk7F1Ncz95/iSMmBkzLsec37hV1/VW2LaWsXSuK1bFlf2vQZEX/fx53fMfm9aAb+cBtvXRZNyC/+PNu2o4ecL3uKh595i285axpYeytVnlfG5k4bl7Sd3dyqrd7N2azVvbq5mzZam29qt1dTUNgDwyWOH8MBXJ3bMoLkdG+BPt0dLSY9eMfBw0g3tW4pX8lKAS9vqa+Hnl8BbC+CCH8PQU+LDU/9BO9/722DxjLgyrd4UNaXPvBFOuKjFgiIHhNXzo39882sxUOnc2+GIZutY76qKaWCNQV2xNKqmQfRlDhkTi6yUjo/Ban2P6Nh93lkJv54ec5KP+xycfGlMa8pztZ+vn/zKSSMZMbA3azZHOL+5pZo1m6vYXlP3wc9172YcObA3ZYP7UDa4DyOzPyeOHNj+A+VqtkcXzYKfxlrxE66CT3wz7ZaexCjApTA7K2HmZ2DLG03P9RkCA8oizAdmfzY+7ntEp9S3Lhrvvg0L/iuuemqrYdQ58LGbYqpTsRz3+rpoGXrq+9HEfur0GCBUsRQqnofNK2LkL0SLxLAsrEvHxxedzvgCWl8bXQFLH4gvXD37xjSnk6ZGYZFmI6ab95M3Ku3fKwvo3pQNPoSjs6AuHdCr4+d21+2CJTPj93i/MlYNm/wvsWCN7FcKcClcbQ1sejWm+WxbE39WromRptvLmz4sAbr3ggFHNQX6YWNg+MS46tlPVbYOOO7w9gJYfB+88tsI6rFTo8my+dVnMdlZCU/fAYvuBa+HXgOzoM4Ce9ipcEgXW/62oT5GNb80O/qMa96L+eYnXBj/pkdO2mMQ1Jubq9hd38DIQX06Z/plQwO8PDuWIH73bSj7ZIyL6eiZAdIiBbi0j7rdMfdx25os1Nc23SrXxFUiRDWkYeOiQEzphAj19h5RfKCp2R4jXxfPiKvKg/pF/eYzrttv1cqS8F55XOEOGJlWK0Tdrpi+9vLsGPBWuxP6DoOxl8TV7bBxnfv7uMeiM/NujSl9R5wcwT1qcuftkwAKcNkf3KOGcfkSqFgC5YtjpaGGrO+u34icQJ8QzZudUX2rq9nwclSwevER2F0VYw8mfi0+1BNceEEKsLs6Qvyl2bDqSWiohYGj4t/8pKl7lGftcBXLohrdmj9HN8TkW2Jf9sMUKWmbAlw6R+37UamqYkkEe/kSeC8bYNStOxw+NsL8qDPjm35XrEn87jtRSOL1J6L7YNi4ptvAo/fuqqluF7z6eDSTv7MwFl0Y+wWYeHXLdZ/lwLSzMs6vl2dHURs8vuSecV00te9NhbFCuEd98IV3x9/fe1As+znhqx27Trx8ZApw6Tp2bMwJ9MWx1vLuqhgxPHwijP5U3Iae0nlXAJVvRmWmFXNisBTEAg09+0T95LqaeO7gfrGfpac2hXq/ES2H+ra1sOT+qPi0c2tcdU24KqYbdcI62dLF7NgQy5kuvjfOwb5D40vd+Ks+WpnX1uzaAS/MauqqObhf1A8488Y91uGWrkEBLl1XfV1M/1k5L+pSr4t1m+k9GEafEyUNR01uvw+wlmx6LQL71TnRBwgRzidcGOsIDx6d7W9tTGuqWBb7uu75KBLSUNu0341hXnpqdBWsfzGayVfOiy8qx50XH8xlZ6uZUvbU0BD/F567K9Yg735wlGo947q9rxy3aUW0+LwwK+uq+RuY+HV11SRgnwPczM4F/hMoAe5z99ubvX4Q8CAwHtgKXObua81sCnA70BPYDXzT3ednPzMeeADoBTwB3ORt7IwCvAhUbY75v6vmxaCf9ysBizAcPQWOmRLhuK+j3N2jj74xtLe8Hs+POD0C+/gLYoR9IWprYNMrEeYVWajnTm8COOQIGD89pkH1K923fZfisem1aOZ+YRbUvR/z4c+4Do49t+3/A/W18Nrv4mp77TOx8tbYS2KMRen4tAYBFrF9CnAzKwHeAKYA5cBi4HJ3fzVnm+uBk93978xsGnCxu19mZuOAje6+zszGAnPdvTT7mUXAjcBCIsDvdPfft7YvCvAi01AfKwatmheDfcqXAB5TiEZNzqardQMriQ+zbt2z+43PdY/nP3i9JK6AK5ZGH/S2tfH4qI/FlfaY89tvGcDd1fEFYd3yeM/jPttx/Zly4NtZGfUAFt0b0zkHjIym73FXRDN4ru3rYw760gegakMMTJtwNYz7cse3ZEm729cAnwTc6u6fyR7/E4C7/3vONnOzbRaYWXdgAzAk94raor7fVmAoMBB4yt3HZK9dDpzt7te2ti8K8CK3szK7On8ybtWb9+59unWP+a0nfD6qZXW1+cMiLamvg9f+J9YveOe5mLJ5yt/CadfGcpaL74UVv4vWn9GfiqvtY6aoLkPCWgvwQuowlgLv5DwuB05vaRt3rzOz94BBwJacbb4ALHP3XWZWmr1P7nuqXVFa13tgTLM5aWo0gTfUR1GPhvqYrub10X/o2eMPvV7f9Hy/4V1zxLtIW0q6w4kXx23d8xHkS+6HRffE670GwKTrY3CkqqYd8PZLIWUzOxG4A/j0XvzsNcA1AEcemdASidKxzLI64AdwLXCR1gwbB5f8N0y5LRa56T04+rhVX6FoFPLpVwGMyHk8PHsu3zblWRN6P6K5HDMbDjwGXOnuq3O2zy0vle89AXD3e4B7IJrQC9hfEZHi0ffwqJEvRaeQOSyLgWPMrMzMegLTgDnNtpkDTM/uTwXmu7ubWX/gf4Gb3f0vjRu7+3pgu5mdkfWNXwk8vo+/i4iISNFoM8DdvQ64AZgLrAAecfdXzOw2M/t8ttkMYJCZrQK+AdycPX8DMBq4xcyWZ7fGdeiuB+4DVgGrgVZHoIuIiEgTFXIRERHpolobha4yUCIiIglSgIuIiCRIAS4iIpIgBbiIiEiCFOAiIiIJUoCLiIgkSAEuIiKSIAW4iIhIghTgIiIiCVKAi4iIJEgBLiIikiAFuIiISIIU4CIiIglSgIuIiCRIAS4iIpIgBbiIiEiCFOAiIiIJUoCLiIgkSAEuIiKSIAW4iIhIghTgIiIiCVKAi4iIJEgBLiIikiAFuIiISIIU4CIiIglSgIuIiCRIAS4iIpIgBbiIiEiCFOAiIiIJUoCLiIgkSAEuIiKSIAW4iIhIghTgIiIiCVKAi4iIJEgBLiIikiAFuIiISIIU4CIiIglSgIuIiCRIAS4iIpIgBbiIiEiCFOAiIiIJUoCLiIgkSAEuIiKSIAW4iIhIghTgIiIiCVKAi4iIJEgBLiIikiAFuIiISIIU4CIiIglSgIuIiCRIAS4iIpIgBbiIiEiCFOAiIiIJUoCLiIgkSAEuIiKSIAW4iIhIghTgIiIiCVKAi4iIJEgBLiIikiAFuIiISIIU4CIiIglSgIuIiCRIAS4iIpIgBbiIiEiCFOAiIiIJUoCLiIgkSAEuIiKSIAW4iIhIghTgIiIiCVKAi4iIJEgBLiIikiAFuIiISIIU4CIiIglSgIuIiCRIAS4iIpIgBbiIiEiCFOAiIiIJUoCLiIgkqKAAN7Nzzex1M1tlZjfnef0gM/tV9vpCMxuZPT/IzJ4ysyoz+0mzn/lT9p7Ls9th7fELiYiIFIPubW1gZiXAT4EpQDmw2MzmuPurOZtdDWxz99FmNg24A7gMqAG+A4zNbs19yd2X7OPvICIiUnQKuQI/DVjl7m+6+25gFnBhs20uBH6W3Z8NnGNm5u7V7v4sEeQiIiLSTgoJ8FLgnZzH5dlzebdx9zrgPWBQAe99f9Z8/h0zswK2FxEREQpoQu9AX3L3CjPrC/wG+DLwYPONzOwa4JrsYZWZvZ7nvQYDWzpsT9Ol45Kfjkt+Oi756bjkp+OSX3sfl6NaeqGQAK8ARuQ8Hp49l2+bcjPrDvQDtrb2pu5ekf25w8weJprq9whwd78HuKe19zKzJe4+oY3fo+jouOSn45Kfjkt+Oi756bjktz+PSyFN6IuBY8yszMx6AtOAOc22mQNMz+5PBea7u7f0hmbW3cwGZ/d7AOcDL3/UnRcRESlWbV6Bu3udmd0AzAVKgJnu/oqZ3QYscfc5wAzgITNbBVQSIQ+Ama0FDgV6mtlFwKeBt4C5WXiXAE8C97brbyYiInIAK6gP3N2fAJ5o9twtOfdrgC+28LMjW3jb8YXtYkFabWIvYjou+em45Kfjkp+OS346Lvntt+NirbR0i4iISBelUqoiIiIJSjrA2yrxWszMbK2ZvZTNsy/aandmNtPMNpnZyznPDTSzeWa2MvtzQGfuY2do4bjcamYVOeWNP9uZ+7i/mdmIrPTzq2b2ipndlD1f1OdLK8el2M+Xg81skZm9kB2X72bPl2UlxVdlJcZ7dtg+pNqEnpV4fYOcEq/A5c1KvBatbPDgBHcv6nmaZvYJoAp40N3HZs/9AKh099uzL34D3P1bnbmf+1sLx+VWoMrdf9iZ+9ZZzGwoMNTdl2X1KZYCFwFfoYjPl1aOy6UU9/liQB93r8oGZD8L3AR8A3jU3WeZ2d3AC+5+V0fsQ8pX4IWUeJUi5+5/JmZG5Mot/fsz4sOoqLRwXIqau69392XZ/R3ACqLKZFGfL60cl6LmoSp72CO7OTCZKCkOHXy+pBzghZR4LWYO/MHMlmbV7KTJ4e6+Pru/ATi8M3emi7nBzF7MmtiLqqk4V7ai4jhgITpfPtDsuECRny9mVmJmy4FNwDxgNfBuVlIcOjiXUg5wad1Z7n4qcB7w91mTqTSTFRxKsx+p/d0FjAJOAdYD/9G5u9M5zOwQorzzP7j79tzXivl8yXNciv58cfd6dz+FqFB6GjBmf/79KQd4ISVei1ZOqdpNwGPEySVhY9av19i/t6mT96dLcPeN2QdSA1FYqejOmawv8zfAL9z90ezpoj9f8h0XnS9N3P1d4ClgEtA/KykOHZxLKQd4ISVei5KZ9ckGm2BmfYjqdypV2yS39O904PFO3JcuozGkMhdTZOdMNihpBrDC3X+U81JRny8tHRedLzbEzPpn93sRA6pXEEE+NdusQ8+XZEehA2TTFn5MU4nX73fyLnUJZnY0cdUNUW3v4WI9Nmb2S+BsYoWgjcC/Ar8FHgGOJMr6XuruRTWgq4XjcjbRHOrAWuDanL7fA56ZnQU8A7wENGRPf5vo7y3a86WV43I5xX2+nEwMUishLoYfcffbss/fWcBA4HngCnff1SH7kHKAi4iIFKuUm9BFRESKlgJcREQkQQpwERGRBCnARUREEqQAFxERSZACXEREJEEKcBERkQQpwEVERBL0/5gkZD7F28eFAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is doing well at generalizing with 10 epochs. I will do 10-fold cross-validation as a final measure to ensure that training for this number of epochs does not carry a high chance of poor generalization, and to ensure that the average MSE is below the target MSE."
      ],
      "metadata": {
        "id": "xEOVltnJX5UE"
      },
      "id": "xEOVltnJX5UE"
    },
    {
      "cell_type": "code",
      "source": [
        "X_cv = np.concatenate((X_train, X_val), axis=0)\n",
        "y_cv = np.concatenate((y_train, y_val), axis=0)\n",
        "cvscores = []\n",
        "\n",
        "for train, test in kfold.split(X_cv, y_cv):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(nodes, activation=activation, input_shape=(X_train.shape[1],)))\n",
        "    if layers == 1:\n",
        "      model.add(Dense(nodes, activation=activation))\n",
        "    elif layers == 2:\n",
        "      model.add(Dense(nodes, activation=activation))\n",
        "      model.add(Dense(nodes, activation=activation))\n",
        "    elif layers == 3:\n",
        "      model.add(Dense(nodes, activation=activation))\n",
        "      model.add(Dense(nodes, activation=activation))\n",
        "      model.add(Dense(nodes, activation=activation))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='mse',\n",
        "                  optimizer=keras.optimizers.Adam(lr=lr),\n",
        "                  metrics=['mse'])\n",
        "    # Train the model on the training data\n",
        "    model.fit(X_cv[train], y_cv[train], epochs=10, batch_size=batch_size, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation data\n",
        "    scores = model.evaluate(X_cv[test], y_cv[test], verbose=0)\n",
        "    \n",
        "    # Store the validation loss\n",
        "    cvscores.append(scores[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oXmuqV_uh1G",
        "outputId": "3aaf2fd3-85fc-403a-d03f-ce661312809c"
      },
      "id": "7oXmuqV_uh1G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(np.arange(1,11,1), cvscores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "oaeenlRzVsms",
        "outputId": "752c39d3-9f91-453f-e136-c712676477db"
      },
      "id": "oaeenlRzVsms",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc05324c4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(cvscores).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lmxOagEWM1L",
        "outputId": "4b035ad2-1b1f-4ee1-ea41-513a0d459ccf"
      },
      "id": "4lmxOagEWM1L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021796085685491563"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model seems to be good at generalizing, and has an MSE that is beating our benchmark. My work here is done!"
      ],
      "metadata": {
        "id": "YGbFpfIxWbeS"
      },
      "id": "YGbFpfIxWbeS"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(nodes, activation=activation, input_shape=(X_train.shape[1],)))\n",
        "if layers == 1:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 2:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "elif layers == 3:\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mse',\n",
        "              optimizer=keras.optimizers.Adam(lr=lr),\n",
        "              metrics=['mse'])\n",
        "# Train the model on the training data\n",
        "model.fit(X_cv, y_cv, epochs=10, batch_size=batch_size, verbose=0)\n",
        "\n",
        "\n",
        "test_mse = model.evaluate(X_test, y_test, verbose=0)[0]\n",
        "print(\"Test MSE:\", test_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4bGm1TlWuIT",
        "outputId": "5617d89e-ad80-4228-dcd6-8cad8f21c081"
      },
      "id": "-4bGm1TlWuIT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 0.021013429388403893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(model.predict(X_test), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "g7ksQkdsbL3x",
        "outputId": "9965d5e5-7580-404a-fec5-940fc459c4be"
      },
      "id": "g7ksQkdsbL3x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc05369f670>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}