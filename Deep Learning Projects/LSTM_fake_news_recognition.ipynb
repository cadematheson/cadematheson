{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dac2f348-3d31-4caa-93ee-aa64c7ef6b86",
      "metadata": {
        "id": "dac2f348-3d31-4caa-93ee-aa64c7ef6b86"
      },
      "source": [
        "# ICE 5: Text Classification (Sequential Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c3dcbeb-a227-4834-b239-3bc2f1a0ff18",
      "metadata": {
        "id": "5c3dcbeb-a227-4834-b239-3bc2f1a0ff18"
      },
      "source": [
        "With new tools for generating text, I've been thinking about the issues of inaccurate news and detecting this automatically. Given the scale of news these days, it would not be feasible to manually vet all news stories so the ability to automatically identify them would be critical. \n",
        "\n",
        "To this end, I found a dataset of real vs fake news but to make it a bit more difficult of a task, I've downsampled the dataset dramatically leaving you with 100 training observations. I've listed the tasks I'd like you to complete below with this dataset. \n",
        "\n",
        "For consistency, I also created a validation and test split, all of which can be found on Canvas under the datasets with the following names:\n",
        "\n",
        "* `FakeNews_Train.csv`\n",
        "* `FakeNews_Test.csv`\n",
        "* `FakeNews_Val.csv`\n",
        "\n",
        "## Tasks\n",
        "1. Train an LSTM (including the embedding layer) to predict real vs fake news.\n",
        "2. Train an LSTM using pre-trained GLoVE embeddings to predict real vs fake news.\n",
        "3. (Bonus) How little training data do you need to achieve an \"acceptable\" accuracy? This may require grabbing some more test data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fake news stories I created were from ChatGPT. In short, I attempted to give it specific scenerios, and assign it names to speak of."
      ],
      "metadata": {
        "id": "ICtTVPMvbulp"
      },
      "id": "ICtTVPMvbulp"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8564b292-210b-4b00-8314-e76be8022ed8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8564b292-210b-4b00-8314-e76be8022ed8",
        "outputId": "44146a0f-bc1e-4013-dd3e-22ef24348843"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  MARIA BARTIROMO Gets Into Heated Interview Wit...   \n",
              "1   WATCH: Watergate Reporter Carl Bernstein HAMM...   \n",
              "2   Biggest Leak EVER Exposes How The 1% Dodges M...   \n",
              "3  [VIDEO] EMBOLDENED BY OBAMA‚ÄôS LAWLESS AMERIC...   \n",
              "4  ELLEN Just Proved She‚Äôs A HUGE Hypocrite And...   \n",
              "\n",
              "                                                text       date  Label  \\\n",
              "0  The DNC Chair Tom Perez took his delusional an...   8-Nov-17  False   \n",
              "1  Legendary investigative reporter Carl Bernstei...  10-Jun-17  False   \n",
              "2  A secret cache of documents revealing the tax ...   4-Apr-16  False   \n",
              "3  Obama has encouraged this type of behavior wit...   3-Sep-15  False   \n",
              "4  Someone needs to educate Ellen DeGeneres on Pr...   5-May-17  False   \n",
              "\n",
              "   BinLabel  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92ef9fea-8d16-4a8a-b7b7-f71023dad206\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>Label</th>\n",
              "      <th>BinLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MARIA BARTIROMO Gets Into Heated Interview Wit...</td>\n",
              "      <td>The DNC Chair Tom Perez took his delusional an...</td>\n",
              "      <td>8-Nov-17</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WATCH: Watergate Reporter Carl Bernstein HAMM...</td>\n",
              "      <td>Legendary investigative reporter Carl Bernstei...</td>\n",
              "      <td>10-Jun-17</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Biggest Leak EVER Exposes How The 1% Dodges M...</td>\n",
              "      <td>A secret cache of documents revealing the tax ...</td>\n",
              "      <td>4-Apr-16</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[VIDEO] EMBOLDENED BY OBAMA‚ÄôS LAWLESS AMERIC...</td>\n",
              "      <td>Obama has encouraged this type of behavior wit...</td>\n",
              "      <td>3-Sep-15</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ELLEN Just Proved She‚Äôs A HUGE Hypocrite And...</td>\n",
              "      <td>Someone needs to educate Ellen DeGeneres on Pr...</td>\n",
              "      <td>5-May-17</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92ef9fea-8d16-4a8a-b7b7-f71023dad206')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92ef9fea-8d16-4a8a-b7b7-f71023dad206 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92ef9fea-8d16-4a8a-b7b7-f71023dad206');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('FakeNews_Train.csv')\n",
        "val = pd.read_csv('FakeNews_Val.csv')\n",
        "test = pd.read_csv('FakeNews_Test.csv')\n",
        "created_test = pd.read_csv('news_stories_created_test_set.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "LIvczGnL-d1I",
        "outputId": "f163627f-4f7e-4ad3-8ee1-1f36543a00b3"
      },
      "id": "LIvczGnL-d1I",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Obama has encouraged this type of behavior with his divisive rhetoric, as he proves himself to be a true disciple of the Reverend Wright s church of Black Liberation Theology (hate against whites) After a month that saw law enforcement officers from Texas to New Orleans being targeted and gunned down because they were cops, a new viral video features a self-described black supremacist calling for more deadly assaults on police.https://youtu.be/brX0XcmtVUY It s open season on killing white people and crackers,  King Noble says in a chilling Youtube rant.  The Black Lives Matter movement wasn t enough. Noble calls for more execution-style killings of police officers similar to the slaying of Texas sheriff s Deputy Darren Goforth. It s not safe no more to be white in America. Lurking behind any corner could be an angry black man ready to take yo ass out. It s a reality,  he said.  It s open season on killing whites and police. Via: Breitbart News'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape:\", train.shape, \"Val shape: \", val.shape, \"test shape:\", test.shape)\n",
        "train = pd.concat([train[['text','BinLabel']], test[['text','BinLabel']]], axis=0)\n",
        "val = val[['text','BinLabel']]\n",
        "test = created_test[['text','BinLabel']]\n",
        "\n",
        "train.shape"
      ],
      "metadata": {
        "id": "vH0JQl4A254j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92deb7e-2130-4120-fcf8-8e2b809e1808"
      },
      "id": "vH0JQl4A254j",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (100, 5) Val shape:  (1000, 5) test shape: (1000, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1100, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uh2xhsjg3Qtu",
        "outputId": "fe9b65a9-5c0a-4b23-e12f-f2e9706e8dcf"
      },
      "id": "uh2xhsjg3Qtu",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  BinLabel\n",
              "0  The DNC Chair Tom Perez took his delusional an...         0\n",
              "1  Legendary investigative reporter Carl Bernstei...         0\n",
              "2  A secret cache of documents revealing the tax ...         0\n",
              "3  Obama has encouraged this type of behavior wit...         0\n",
              "4  Someone needs to educate Ellen DeGeneres on Pr...         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45dbbdc9-e645-49cd-8a0e-beb468ba3abc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>BinLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The DNC Chair Tom Perez took his delusional an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Legendary investigative reporter Carl Bernstei...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A secret cache of documents revealing the tax ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Obama has encouraged this type of behavior wit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Someone needs to educate Ellen DeGeneres on Pr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45dbbdc9-e645-49cd-8a0e-beb468ba3abc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45dbbdc9-e645-49cd-8a0e-beb468ba3abc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45dbbdc9-e645-49cd-8a0e-beb468ba3abc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "Z-2_NgHB3R__"
      },
      "id": "Z-2_NgHB3R__",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 10000\n",
        "max_length = 650\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_words, oov_token = '<OOV>')\n",
        "tokenizer.fit_on_texts(train['text'])"
      ],
      "metadata": {
        "id": "avkjP-Uo3nXY"
      },
      "id": "avkjP-Uo3nXY",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(pd.concat((train['text'], test['text']), axis=0))\n",
        "X_val_seq = tokenizer.texts_to_sequences(val['text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test['text'])"
      ],
      "metadata": {
        "id": "OM50DFZr4rEH"
      },
      "id": "OM50DFZr4rEH",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded = pad_sequences(X_train_seq, maxlen = max_length, padding = 'post', truncating = 'post')\n",
        "X_val_padded = pad_sequences(X_val_seq, maxlen = max_length, padding = 'post', truncating = 'post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen = max_length, padding = 'post', truncating = 'post')"
      ],
      "metadata": {
        "id": "6iaD0EYn4yO_"
      },
      "id": "6iaD0EYn4yO_",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train_seq[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk-YrjmD6mdk",
        "outputId": "95f66960-ab15-4f07-bcfd-b136868ff40f"
      },
      "id": "Tk-YrjmD6mdk",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llrmrfWs6pRt",
        "outputId": "ee487de4-cb95-4d1d-a89e-2aa881872c7c"
      },
      "id": "llrmrfWs6pRt",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 1458, 1839, 1783, 3577,  278,   20, 6643,    6,  167, 6644,\n",
              "       4628,   10,  271,  280,   27,  815, 2916, 5409,  468,   77,   24,\n",
              "         15,   18,    5, 8797,    4, 2569,  732,   39,    2, 2374,    2,\n",
              "       7501,   28,  151,    7,  233,   99,   22,   46, 7502,   21,    2,\n",
              "       2467,  237,  392,   70, 1840, 1701,  361,  388,  219,    3,    5,\n",
              "       3356, 2468,  710,   18, 5409, 1252,    2, 1458,  530,   39,   20,\n",
              "         99,    9, 4629,    7,  202,    9,  496,  145, 5409,  802,    5,\n",
              "       7503,   60,   54, 1784,    2, 1176,   39,   74, 8798,    2,  964,\n",
              "       3577,  777,  174, 2916,   37,  951,    8,   60,    2,  244,  440,\n",
              "         19,   32,  125,  354,    2,  756,  105,  475,    8,   48,   38,\n",
              "         91,    3, 1096,   10,   83,  361,  145,   53, 3577, 5410,  825,\n",
              "          6, 5409,   14,    2,  334,  469,  436,   17,    1,    2,   87,\n",
              "        449,  174,    6, 4036,   18, 3577, 2667,    3, 1276,    2, 1785,\n",
              "        469,  284,    6, 5409,    1,   77,   10,  246,   13,   22, 2782,\n",
              "          3,  355,  126, 3357,    9, 4984, 5409, 1786,  565,  174,   29,\n",
              "       3577,   18,  732, 4309,  248, 1370, 7504,  803,  355,    5, 1224,\n",
              "        454,  126,   95,   35,  156,   61,  278,  267,    6,  778,   17,\n",
              "       4037,    6,   48,   49,  550,  115,   74,   54, 1158, 2916,   37,\n",
              "        184,   42,  156,   56,   27,   12,    5, 7505,   45,    5, 5411,\n",
              "          5,   48,  839,  231, 3577,    1,   54,  145,  224, 3577,   39,\n",
              "        268,    2, 1458,  125,   26,  726,   40, 4630,   69,    3,    2,\n",
              "        296,   11,   31,  272,    3,   50,   13, 2917, 2916,   48,  154,\n",
              "          7,    5, 5965,    1,  122,   95, 3577,  933,    3,  726,    2,\n",
              "       1652,  174,    3,  202,    9,   93,  965, 1653,   90,   19, 1521,\n",
              "          8,  314, 8799,    2,  244, 2570,  652,  572,    4,    2,  299,\n",
              "         37, 2072,   42, 1056,    5, 2570, 5409, 4985,  174,  233,   99,\n",
              "         22,   46, 7502,   21,    2, 2467,  237,  392,   70, 1840, 1701,\n",
              "        497,   47,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "buffer_size = 10000\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_padded, pd.concat((train['BinLabel'], test['BinLabel']), axis=0)))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_padded, val['BinLabel']))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_padded, test['BinLabel']))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "gst-2nDZ_yYT"
      },
      "id": "gst-2nDZ_yYT",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t,f in val_dataset:\n",
        "  print(t.shape)\n",
        "  print(t)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KoPsdSLDSSh",
        "outputId": "436e2a3b-c98b-4eac-c487-ff255a6a17e3"
      },
      "id": "9KoPsdSLDSSh",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 650)\n",
            "tf.Tensor(\n",
            "[[ 320 5609 3726 ...    0    0    0]\n",
            " [  56   48  154 ...    0    0    0]\n",
            " [  13  224  231 ...    0    0    0]\n",
            " ...\n",
            " [  68    5  641 ...    0    0    0]\n",
            " [   2   34   30 ...    0    0    0]\n",
            " [1048  762 1010 ...    0    0    0]], shape=(32, 650), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "-z7YGLQhFG6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb93f16e-e917-4253-efcb-b9de0c9a8378"
      },
      "id": "-z7YGLQhFG6V",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-20 01:20:55--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-20 01:20:55--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-20 01:20:56--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.09MB/s    in 2m 40s  \n",
            "\n",
            "2023-04-20 01:23:36 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path_to_glove_file = \"/content/glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAvCisHlxmQp",
        "outputId": "499b96a1-78a8-4bab-cfc1-757018c27229"
      },
      "id": "eAvCisHlxmQp",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(tokenizer.word_index) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g9cBNnNyFg1",
        "outputId": "b7294481-db13-4ec3-f168-0f2ddbe3c5f2"
      },
      "id": "-g9cBNnNyFg1",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 21438 words (3279 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "metadata": {
        "id": "W9KHi67dyNFb"
      },
      "id": "W9KHi67dyNFb",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype = \"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss = \"binary_crossentropy\",\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-zBlkttyZLt",
        "outputId": "98650460-9bd7-4aba-a300-a1011bdec362"
      },
      "id": "V-zBlkttyZLt",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         2471900   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 64)               34048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,506,013\n",
            "Trainable params: 34,113\n",
            "Non-trainable params: 2,471,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, validation_data = val_dataset, epochs = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-yRsJJc0CgE",
        "outputId": "6ea134f4-84d9-47d6-9e4a-3797a10eea52"
      },
      "id": "g-yRsJJc0CgE",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 0.0732 - accuracy: 0.9778 - val_loss: 0.0385 - val_accuracy: 0.9910\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.0599 - accuracy: 0.9822 - val_loss: 0.0389 - val_accuracy: 0.9950\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 0.0517 - accuracy: 0.9849 - val_loss: 0.0337 - val_accuracy: 0.9920\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 2s 63ms/step - loss: 0.0486 - accuracy: 0.9867 - val_loss: 0.0405 - val_accuracy: 0.9920\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 2s 60ms/step - loss: 0.0424 - accuracy: 0.9893 - val_loss: 0.0303 - val_accuracy: 0.9920\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0423 - accuracy: 0.9911 - val_loss: 0.0411 - val_accuracy: 0.9880\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 0.0331 - accuracy: 0.9920 - val_loss: 0.0208 - val_accuracy: 0.9930\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 0.0155 - val_accuracy: 0.9990\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0881 - val_accuracy: 0.9800\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.0234 - val_accuracy: 0.9940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3af8c6da30>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_padded, test['BinLabel'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRgpDUxf1VkL",
        "outputId": "bf9c0364-f615-41e0-cd56-e1168b75efa9"
      },
      "id": "DRgpDUxf1VkL",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6153 - accuracy: 0.7500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6152816414833069, 0.75]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_padded)\n",
        "y_pred = np.round(y_pred)\n",
        "\n",
        "y_test_labels = test['BinLabel']\n",
        "for i in range(len(y_test_labels)):\n",
        "    print(f\"Actual: {y_test_labels[i]}, Predicted: {y_pred[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npRwi7Q7mSM7",
        "outputId": "63a2e731-51a4-4a7a-ed8d-3648e87c2e00"
      },
      "id": "npRwi7Q7mSM7",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [0.]\n",
            "Actual: 1, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the incorrectly labeled stories"
      ],
      "metadata": {
        "id": "EbEE--WYe0tI"
      },
      "id": "EbEE--WYe0tI"
    },
    {
      "cell_type": "code",
      "source": [
        "created_test['text'][9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "jVxa1lEBd8ok",
        "outputId": "9452e186-70e2-4369-b849-adcea171dbef"
      },
      "id": "jVxa1lEBd8ok",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'War has broken out in Israel. The sound of bombs and gunfire echoes through the streets. People run for cover as buildings crumble and smoke fills the air. The conflict seems to have no end in sight. Families are torn apart, lives are lost, and the future is uncertain. The fighting is intense and both sides seem determined to win. The conflict has sparked protests around the world, with people taking to the streets to demand an end to the violence. But as the days go by, it becomes clear that the situation is only getting worse. The international community has tried to intervene, but so far their efforts have been in vain. The United Nations has called for a ceasefire, but it has been ignored. The conflict has even spilled over into neighboring countries, further destabilizing an already volatile region. The impact of the war is felt everywhere. Schools are closed, businesses are shut down, and hospitals are overwhelmed with casualties. Families huddle in bomb shelters, praying for safety and a quick end to the conflict. As the days turn into weeks, it becomes clear that the war will have a lasting impact on the region. The destruction is massive, the death toll is rising, and the wounds may take generations to heal. The world watches in horror as the conflict drags on, hoping for a resolution that will bring peace to the region. But for now, the war in Israel rages on.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "created_test['text'][11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "q9RajWmzeOSY",
        "outputId": "7668bf9f-922b-4f99-edcf-426b79ee2e1d"
      },
      "id": "q9RajWmzeOSY",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"President Trump has just tweeted his intention to tackle the issue of federal student debt relief. In a series of early morning tweets, he stated that he wants to work with Congress to find a solution that will provide relief to millions of Americans burdened with student loan debt. The issue of student debt has become a major political issue in recent years, with many young people struggling to pay off their loans and build a stable financial future. Trump's tweet suggests that he recognizes the seriousness of the issue and wants to take action to address it. The details of his proposed solution are not yet clear, but his tweets indicate that he is open to a range of options, including loan forgiveness, lower interest rates, and expanded repayment plans. He also emphasized the need for accountability, saying that any solution should be designed to prevent future generations from being burdened with the same level of debt. The response to Trump's tweet has been mixed. Supporters have praised him for taking on an issue that has been ignored by previous administrations, while critics have expressed skepticism about his motives and questioned whether he is truly committed to solving the problem. Despite the mixed reactions, the fact that the President is publicly acknowledging the issue of federal student debt relief is a significant development. With millions of Americans struggling to make ends meet due to student debt, finding a solution to this problem could have a major impact on the financial well-being of the country as a whole.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "created_test['text'][15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "P0T_DNrOebms",
        "outputId": "8c651d0b-e5cc-48ec-a9bb-584f47e26b3d"
      },
      "id": "P0T_DNrOebms",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A new gun law has been passed, which is set to have a significant impact on gun owners across the country. The law, which has been hotly debated in Congress for months, will impose tighter restrictions on the sale and ownership of firearms. Under the new law, background checks will be mandatory for all gun sales, including private sales and transfers. The law also bans the sale of high-capacity magazines and assault weapons, which have been used in many recent mass shootings. Supporters of the law argue that it is necessary to prevent gun violence and protect public safety. They point to the fact that the US has one of the highest rates of gun violence in the world, with mass shootings and other gun-related crimes becoming increasingly common. Opponents of the law, however, argue that it infringes on the Second Amendment rights of law-abiding gun owners. They argue that the vast majority of gun owners are responsible and pose no threat to public safety, and that the law unfairly penalizes them. The passing of the law has been met with mixed reactions from the public. Some have praised the move as a step towards greater gun control and public safety, while others have expressed anger and frustration at what they see as an infringement on their constitutional rights. The impact of the law on gun violence and public safety remains to be seen. While supporters hope that it will lead to a reduction in gun-related crimes, opponents fear that it will do little to prevent violent crime and may even make the situation worse by driving gun ownership underground.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "created_test['text'][16]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "lpS8CNuNebjs",
        "outputId": "20fb7052-dd90-4a07-8ee7-9ed302fcaa37"
      },
      "id": "lpS8CNuNebjs",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The COVID-19 pandemic is once again wreaking havoc across Europe, with more than 10 million people succumbing to the virus over a six-month period. The fatality rate stands at a concerning 2.3%, causing widespread concern and alarm. The resurgence of the virus has been attributed to a number of factors, including the emergence of new, more contagious variants of the virus, the relaxation of lockdown measures, and a general complacency towards the threat posed by the virus. Governments across the region have been scrambling to contain the outbreak, with many reintroducing lockdown measures and imposing new restrictions on travel and gatherings. However, these measures have been met with resistance from some members of the public, who are frustrated with the ongoing disruption to their lives. The situation has been made even more challenging by the slow rollout of vaccines across the region. While some countries have made significant progress in vaccinating their populations, others are struggling to keep up, leading to concerns that the virus may continue to spread for some time to come. The impact of the pandemic on the region's economy has been severe, with many businesses forced to close and millions of people losing their jobs. Governments have been offering financial support to those affected, but the long-term economic consequences of the pandemic are still uncertain. As the pandemic continues to ravage Europe, many are calling for increased international cooperation and a renewed commitment to fighting the virus. It remains to be seen whether these efforts will be enough to contain the outbreak and prevent further fatalities.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "created_test['text'][18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "rDb0i8Thebg6",
        "outputId": "64310c80-cb00-4d4b-dccb-3c49ee59affa"
      },
      "id": "rDb0i8Thebg6",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Kamala Harris is a lawyer and politician who served as the Attorney General of California from 2011 to 2017, and later as a United States Senator from California from 2017 to 2021. In 2020, she was chosen by Joe Biden as his running mate in the United States Presidential Election. She made history as the first woman of color to be chosen as a vice-presidential nominee by a major political party. Throughout her career, Kamala Harris has been a strong advocate for criminal justice reform, environmental protection, and healthcare access. She has also been a vocal critic of Donald Trump and his policies, particularly on issues related to immigration and civil rights. In recent years, Kamala Harris has also faced criticism from some conservatives for her handling of criminal cases as Attorney General of California and for her association with Hunter Biden. However, she has defended her record and emphasized her commitment to upholding the rule of law and ensuring justice for all. As Vice President, Kamala Harris has continued to champion policies related to social justice and economic equity. She has also played a key role in the administration's response to the COVID-19 pandemic, including efforts to increase vaccine access and support for small businesses. Overall, Kamala Harris's political career has been marked by a strong commitment to public service and a desire to create positive change in her community and the world at large.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "created_test['text'][20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "FCwocbVDd8hD",
        "outputId": "be2d36ad-1fcb-4c2f-e14d-f80a57f09356"
      },
      "id": "FCwocbVDd8hD",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are several potential candidates who are considering running for President in 2024. One of them is Senator Cory Booker from New Jersey. He has a strong track record of advocating for civil rights, criminal justice reform, and economic equality. Senator Booker has been a leading voice in Congress on issues related to social justice and equity. He has championed legislation to address police brutality and systemic racism, and has been a vocal supporter of policies to promote economic opportunity and job growth. In addition to his policy positions, Senator Booker is known for his ability to connect with voters and inspire change. He has a powerful personal story, having grown up in poverty and risen to become a Rhodes Scholar and successful politician. If he were to run for President in 2024, Senator Booker would bring a unique perspective and a proven record of leadership to the race. He has demonstrated a strong commitment to public service and a willingness to fight for what is right, even in the face of opposition. Overall, Senator Booker has the potential to be a strong candidate for President in 2024, and could bring a much-needed focus on issues related to social justice, economic opportunity, and political reform to the national conversation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am unable to find the reason the model miscategorized these articles over the others."
      ],
      "metadata": {
        "id": "zE_GxDBxe5C4"
      },
      "id": "zE_GxDBxe5C4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model performed moderately well on my test set, but it struggled to do as well on the test set as it had on the train and validation sets. I think this might have something to do with my test set being created differently. Capturing more of the patterns in the data may help it bridge that gap.\n",
        "\n",
        "I feel that the model will perform better with more complexity. I will attempt another model with another layer."
      ],
      "metadata": {
        "id": "CKqEsMgsRXWp"
      },
      "id": "CKqEsMgsRXWp"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype = \"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(embedded)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "large_model = keras.Model(inputs, outputs)\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "large_model.compile(optimizer=\"rmsprop\",\n",
        "              loss = \"binary_crossentropy\",\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "callback_list = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3),\n",
        "    ModelCheckpoint(filepath='weights.{epoch:02d}-{val_loss:.2f}.h5',\n",
        "    monitor='val_loss', verbose=1, save_best_only=True)\n",
        "]\n",
        "\n",
        "large_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADJiTj3IWqwh",
        "outputId": "10b85bef-5163-4b57-cf61-a033f16fa4ce"
      },
      "id": "ADJiTj3IWqwh",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         2471900   \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirecti  (None, 64)               34048     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,506,013\n",
            "Trainable params: 34,113\n",
            "Non-trainable params: 2,471,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "large_model.fit(train_dataset, validation_data = val_dataset, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pky0W7Y4Wqtw",
        "outputId": "d1a32714-e73c-462f-d666-bd914d6d07ee"
      },
      "id": "pky0W7Y4Wqtw",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 6s 67ms/step - loss: 0.3816 - accuracy: 0.8932 - val_loss: 0.2303 - val_accuracy: 0.9310\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 3s 71ms/step - loss: 0.1993 - accuracy: 0.9395 - val_loss: 0.1447 - val_accuracy: 0.9620\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 0.1409 - accuracy: 0.9617 - val_loss: 0.0999 - val_accuracy: 0.9820\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.1031 - accuracy: 0.9724 - val_loss: 0.0828 - val_accuracy: 0.9860\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0844 - accuracy: 0.9804 - val_loss: 0.0538 - val_accuracy: 0.9880\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 0.0769 - accuracy: 0.9822 - val_loss: 0.0860 - val_accuracy: 0.9820\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.0619 - accuracy: 0.9849 - val_loss: 0.0319 - val_accuracy: 0.9910\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 0.0599 - accuracy: 0.9840 - val_loss: 0.0447 - val_accuracy: 0.9900\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 2s 62ms/step - loss: 0.0529 - accuracy: 0.9867 - val_loss: 0.0277 - val_accuracy: 0.9920\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.0475 - accuracy: 0.9867 - val_loss: 0.0212 - val_accuracy: 0.9970\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0424 - accuracy: 0.9902 - val_loss: 0.0315 - val_accuracy: 0.9920\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.0397 - accuracy: 0.9920 - val_loss: 0.0362 - val_accuracy: 0.9920\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.0309 - accuracy: 0.9929 - val_loss: 0.0195 - val_accuracy: 0.9960\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.1473 - val_accuracy: 0.9560\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.0310 - accuracy: 0.9929 - val_loss: 0.0213 - val_accuracy: 0.9960\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 0.0422 - val_accuracy: 0.9900\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0215 - accuracy: 0.9956 - val_loss: 0.0216 - val_accuracy: 0.9960\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0250 - accuracy: 0.9938 - val_loss: 0.0220 - val_accuracy: 0.9960\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 0.0172 - val_accuracy: 0.9950\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0174 - val_accuracy: 0.9950\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.0163 - accuracy: 0.9929 - val_loss: 0.0187 - val_accuracy: 0.9950\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.0118 - val_accuracy: 0.9990\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.0150 - val_accuracy: 0.9950\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.0267 - val_accuracy: 0.9910\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0147 - val_accuracy: 0.9950\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0520 - val_accuracy: 0.9890\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.0208 - val_accuracy: 0.9950\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 2s 65ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0223 - val_accuracy: 0.9940\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 0.0581 - val_accuracy: 0.9810\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.0113 - val_accuracy: 0.9970\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.1029 - val_accuracy: 0.9700\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0164 - val_accuracy: 0.9950\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0096 - val_accuracy: 0.9990\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9940\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 2s 62ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0109 - val_accuracy: 0.9970\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0138 - val_accuracy: 0.9970\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9940\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 6.3578e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9990\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 0.0169 - val_accuracy: 0.9950\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9950\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 2s 68ms/step - loss: 6.8155e-04 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9960\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9970\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 7.7197e-04 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9960\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 0.0300 - val_accuracy: 0.9900\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 6.2276e-04 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9960\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 3.2999e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9940\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 3.7886e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9930\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 1.7705e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9960\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 2s 62ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0194 - val_accuracy: 0.9950\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 2.2254e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9970\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 2.0017e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9940\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 0.0015 - accuracy: 0.9991 - val_loss: 0.0927 - val_accuracy: 0.9810\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 8.8801e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9990\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 8.0292e-04 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9990\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 2s 58ms/step - loss: 1.7437e-04 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9980\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 1.3759e-04 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9930\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0415 - val_accuracy: 0.9910\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.5837e-04 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9920\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.1670e-04 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9900\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 8.7246e-05 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9950\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 9.5257e-05 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9990\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 1.0029e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9960\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 2s 61ms/step - loss: 9.2207e-05 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9990\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 1.9426e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9970\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 7.4942e-05 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9950\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 4.4169e-05 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9950\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 5.7424e-05 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9960\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.0014 - accuracy: 0.9991 - val_loss: 0.0143 - val_accuracy: 0.9980\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 2s 65ms/step - loss: 1.0304e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9960\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 8.3628e-05 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9940\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 5.6341e-05 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9920\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 6.5484e-05 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9930\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 6.1125e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9970\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 6.3290e-05 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9960\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 2s 63ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 0.0114 - val_accuracy: 0.9990\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 5.6895e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9980\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 4.9446e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9970\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 4.8228e-05 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9980\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 5.9514e-05 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9930\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 3.5089e-05 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9910\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 3.7187e-05 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9910\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 2s 63ms/step - loss: 5.8923e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9990\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0694 - val_accuracy: 0.9900\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 3.8007e-05 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9900\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 4.5236e-05 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9880\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 4.6206e-05 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9910\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 3.1064e-05 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9920\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.0401 - val_accuracy: 0.9930\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 2s 61ms/step - loss: 3.5962e-05 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9930\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 3.2751e-05 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9940\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 2.9102e-05 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9940\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 3.5275e-05 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9960\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1443 - val_accuracy: 0.9790\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0392 - val_accuracy: 0.9950\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 7.0048e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9950\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 2s 62ms/step - loss: 4.2794e-05 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9940\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 3.9658e-05 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9950\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 2.9818e-05 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9940\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 3.0740e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a482a2df0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "large_model.evaluate(X_test_padded, test['BinLabel'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NilQW79ZZv9-",
        "outputId": "64e0a44d-bf71-4026-c4b6-88d23b2ae387"
      },
      "id": "NilQW79ZZv9-",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 0.0452 - accuracy: 0.9583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.045223940163850784, 0.9583333134651184]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The larger model performed wonderfully on the created test set."
      ],
      "metadata": {
        "id": "XD4nVHKJdaSI"
      },
      "id": "XD4nVHKJdaSI"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = large_model.predict(X_test_padded)\n",
        "y_pred = np.round(y_pred)\n",
        "\n",
        "y_test_labels = test['BinLabel']\n",
        "for i in range(len(y_test_labels)):\n",
        "    print(f\"Actual: {y_test_labels[i]}, Predicted: {y_pred[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nU5fu2hW9mh",
        "outputId": "4a92eae7-cd69-49d0-abf5-0690c63dcfdc"
      },
      "id": "4nU5fu2hW9mh",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 640ms/step\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 1, Predicted: [1.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n",
            "Actual: 0, Predicted: [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the incorrectly labeled article."
      ],
      "metadata": {
        "id": "5QKiZBQPbEJE"
      },
      "id": "5QKiZBQPbEJE"
    },
    {
      "cell_type": "code",
      "source": [
        "created_test['text'][5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "XyMzQGeCaB_z",
        "outputId": "6cc2590b-f57d-4b83-819b-ad1ae24eed31"
      },
      "id": "XyMzQGeCaB_z",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"During a recent debate, conservative commentator Ben Shapiro surprised many by expressing his support for a woman's right to choose. Shapiro, known for his conservative views on issues such as gun rights and taxation, made a passionate argument in favor of pro-choice policies, citing individual freedom and limited government as his main reasons. Shapiro's comments came during a heated discussion on abortion and reproductive rights, where he argued that the government should not be in the business of dictating what a woman can or cannot do with her body. He acknowledged that the issue of abortion is complex and emotionally charged, but maintained that individual freedom and personal choice should be the guiding principles in this debate. Shapiro's comments were met with surprise and some confusion by his fellow debaters, who questioned how his views on abortion fit into his broader conservative philosophy. Shapiro responded by reiterating his belief in limited government and individual freedom, and argued that a woman's right to choose is consistent with these values. The debate sparked a heated discussion on social media, with many applauding Shapiro's willingness to break with traditional conservative views on abortion. Others, however, criticized him for what they saw as a betrayal of conservative values. Regardless of the response, Shapiro's comments have opened up a new and unexpected chapter in the ongoing debate over abortion and reproductive rights. It remains to be seen how other conservatives will respond to his views, and what impact they will have on the wider political conversation.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I cannot tell what articles it did better or worse on, because this story was predicted correctly by the smaller model, so it was more chance than a lack of ability that it was incorrectly labeled in the large model."
      ],
      "metadata": {
        "id": "QxWmr6Bedjo0"
      },
      "id": "QxWmr6Bedjo0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}